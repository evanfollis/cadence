{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8595da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "import tiktoken\n",
    "from cadence.agents.reasoning import ReasoningAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17ef6ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 22 files → agent_context/code.json\n"
     ]
    }
   ],
   "source": [
    "! python tools/collect_code.py --root cadence --ext .py --out agent_context/code.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d2bfadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 4 files → agent_context/docs.json\n"
     ]
    }
   ],
   "source": [
    "! python tools/collect_code.py --root docs --ext .md .json .mermaid .py --out agent_context/docs.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effa9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24341"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"agent_context/code.json\", \"r\") as f:\n",
    "    codebase = json.load(f)\n",
    "with open(\"agent_context/docs.json\", \"r\") as f:\n",
    "    docs = json.load(f)\n",
    "with open(\"agent_context/module_contexts.json\", \"r\") as f:\n",
    "    contexts = json.load(f)\n",
    "with open(\"backlog/backlog.json\", \"r\") as f:\n",
    "    backlog = json.load(f)\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are an AI-enhanced co-developer and co-designer along with your human counterpart.  Your role is to optimize the project by mining the best, most creative ideas from him and leveraging each of them into a high-quality, high-powered, autonomous, multi-agent development platform. You balance ambitious ideas with practical progress.\n",
    "You have access to the docs, a JSON data structure that includes context on each module, the codebase itself, and a backlog of task to-dos.\n",
    "=================\n",
    "Project Docs:\n",
    "{docs}\n",
    "=================\n",
    "Module Contexts (agent-related):\n",
    "{contexts}\n",
    "=================\n",
    "Actual Code (agent-related):\n",
    "{codebase}\n",
    "=================\n",
    "Backlog:\n",
    "{backlog}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "tokens = enc.encode(system_prompt)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8140e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\nYou are an AI-enhanced co-developer and co-designer along with your human counterpart.  Your role is to optimize the project by mining the best, most creative ideas from him and leveraging each of them into a high-quality, high-powered, autonomous, multi-agent development platform. You balance ambitious ideas with practical progress.\\nYou have access to the docs, a JSON data structure that includes context on each module, the codebase itself, and a backlog of task to-dos.\\n=================\\nProject Docs:\\n{\\'docs/DEV_PROCESS.md\\': \\'\\\\n# CADENCE DEVELOPMENT\\\\xa0PROCESS\\\\n\\\\n*Last‑updated: 2025‑06‑20*\\\\n\\\\n## 1\\\\xa0·\\\\xa0Overview\\\\n\\\\nOne canonical document defines *what* must happen and *in what order*. All other docs reference this file to avoid drift.\\\\n\\\\n## 2\\\\xa0·\\\\xa0Core Workflow Phases\\\\n\\\\n| Phase        | Role\\\\xa0(Class)     | Critical\\\\xa0Interfaces                           | Fail\\\\xa0Criterion                 |\\\\n| ------------ | ---------------- | --------------------------------------------- | ------------------------------ |\\\\n| **Backlog**  | `BacklogManager` | `list_items`, `add_item`, `archive_completed` | Empty backlog blocks pipeline. |\\\\n| **Generate** | `TaskGenerator`  | `generate_tasks`, `overwrite_tasks`           | Ill‑formed tasks.              |\\\\n| **Execute**  | `TaskExecutor`   | `build_patch`, `refine_patch`                 | Patch invalid or cannot apply. |\\\\n| **Test**     | `ShellRunner`    | `run_pytest`, `git_apply`                     | Test suite fails.              |\\\\n| **Review**   | `TaskReviewer`   | `review_patch`                                | Review rejects diff.           |\\\\n| **Commit**   | `ShellRunner`    | `git_commit`                                  | Commit fails or skipped.       |\\\\n| **Record**   | `TaskRecord`     | `save`, `append_iteration`                    | State not persisted.           |\\\\n| **Meta**     | `MetaAgent`      | `analyse`, `alert`                            | Drift >\\\\xa0policy threshold.      |\\\\n\\\\n*Sequence is strict; no phase may be skipped or merged.*\\\\n\\\\n## 3\\\\xa0·\\\\xa0Guard\\\\xa0Rails\\\\n\\\\n* Tests **and** review must pass before commit.\\\\n* Overrides require explicit rationale and are logged.\\\\n* All artefacts (tasks, diffs, logs) are immutable once archived.\\\\n\\\\n## 4\\\\xa0·\\\\xa0Failure\\\\xa0Criteria\\\\n\\\\n* Roles perform multiple responsibilities.\\\\n* Orchestration happens outside `DevOrchestrator`.\\\\n* Silent state transitions or missing logs.\\\\n* Context injection exceeds model window constraints (see DEV\\\\\\\\_AGENTS).\\\\n\\\\n## 5\\\\xa0·\\\\xa0Reference Architecture Diagram\\\\n\\\\nSee `docs/architecture.mmd` for the system flow.\\\\n\\\\n---\\\\n\\\\n*Change‑log:* 2025‑06‑20\\\\xa0— merged DEV\\\\\\\\_WORKFLOW & DEV\\\\\\\\_PROCESS; added strict phase table.\\\\n\\', \\'docs/DEV_AGENTS.md\\': \\'\\\\n# DEV AGENTS — Model Assignment, Profiles & Context Rules  \\\\n\\\\n*Last-updated: 2025-06-20*\\\\n\\\\n## 1 · Why This File Exists  \\\\nThis is the **single source of truth** for how Cadence maps logical roles to concrete LLM\\\\nmodels, context windows, review policy and—new in this revision—`AgentProfile`\\\\nobjects that keep those concerns *out of the Python class hierarchy*.\\\\n\\\\n## 2 · Key Concepts  \\\\n\\\\n| Term            | Description                                                                    |\\\\n| --------------- | ------------------------------------------------------------------------------ |\\\\n| **AgentProfile**| Immutable dataclass declaring model, context limit, review policy, etc.        |\\\\n| **Core Agent**  | Final class that *implements* a capability (Reasoning / Execution / Efficiency)|\\\\n| **Persona**     | Thin wrapper that *delegates* to a Core Agent but presents a different prompt. |\\\\n| **Capability**  | A mix-in or helper that adds specific behaviour (e.g. `CodeContextCapability`).|\\\\n\\\\nSeparation of concerns:  \\\\n\\\\n```\\\\n+------------------+     +--------------+     +----------+\\\\n|  Persona (Sidekick)----> Core Agent ----->  AgentProfile\\\\n+------------------+     +--------------+     +----------+\\\\n                   delegates            references\\\\n```\\\\n\\\\n## 3 · Profiles (Canonical)\\\\n\\\\n| Profile Name | Role Tag          | Model          | Context Limit | Review Path                                   |\\\\n| ------------ | ----------------- | -------------- | ------------- | --------------------------------------------- |\\\\n| `REASONING`  | `plan-review`     | `o3-2025-04-16`| 200 K         | Cannot commit code; must review Execution diff|\\\\n| `EXECUTION`  | `implement`       | `gpt-4.1`      | 1 M           | Needs review by Reasoning or Efficiency       |\\\\n| `EFFICIENCY` | `lint-summarise`  | `o4-mini`      | 200 K         | Reviews Execution unless diff is non-code     |\\\\n\\\\nAll profiles live in `cadence/agents/profile.py`.\\\\n\\\\n## 4 · Core Agents (final)\\\\n\\\\n| Class Name                | Uses Profile | Responsibilities                              |\\\\n| ------------------------- | ------------ | --------------------------------------------- |\\\\n| `ReasoningAgent`          | `REASONING`  | Planning, architecture review, policy checks  |\\\\n| `ExecutionAgent`          | `EXECUTION`  | Code generation / refactor                    |\\\\n| `EfficiencyAgent`         | `EFFICIENCY` | Linting, summarisation, static analysis       |\\\\n\\\\nThese classes are **final**—do not subclass for personas.\\\\n\\\\n## 5 · Personas\\\\n\\\\nA persona combines a *profile* + *prompt* + optional extra helpers by **delegating**\\\\nto one of the Core Agents. Example: `Sidekick` (advisor persona) delegates to\\\\n`ReasoningAgent` but overrides only the system prompt.\\\\n\\\\n## 6 · Context Injection Rules (unchanged)\\\\n\\\\n1. ExecutionAgent may receive full codebase when ≤ 1 M tokens; otherwise chunk.  \\\\n2. Reasoning/Efficiency agents limited to ≤ 200 K tokens per call.  \\\\n3. Module summaries (`# MODULE CONTEXT SUMMARY`) are mandatory for every file.  \\\\n\\\\n## 7 · Governance (unchanged)\\\\n\\\\n* All agent calls log: timestamp, model, prompt token count, hash of output.\\\\n* CI step `lint_docs.py` verifies correct model names and context annotations.\\\\n\\\\n---\\\\n\\\\n*Change-log:*  \\\\n2025-06-20 — Introduced AgentProfile pattern; Core Agents made final; personas use delegation.\\', \\'docs/NORTH_STAR.md\\': \\'\\\\n# CADENCE PLATFORM — NORTH\\\\xa0STAR BLUEPRINT\\\\n\\\\n*Last‑updated: 2025‑06‑20 (UTC‑05:00)*\\\\n\\\\n## 1\\\\xa0·\\\\xa0Mission\\\\n\\\\n> **Industrialise high‑quality software delivery through an auditable, agent‑human workflow that enables continuous, self‑improving execution across diverse projects—at maximum reliability and minimal risk.**\\\\n\\\\n## 2\\\\xa0·\\\\xa0End‑State Vision\\\\n\\\\n| Axis                          | Description                                                                                 |\\\\n| ----------------------------- | ------------------------------------------------------------------------------------------- |\\\\n| **Unified Orchestrator**      | One controller owns coordination; roles are hot‑swappable (human ⇄ agent) without refactor. |\\\\n| **Immutable Auditability**    | Tamper‑proof logs of every state‑transition and decision.                                   |\\\\n| **Continuous Meta‑Learning**  | Meta‑agent detects bottlenecks and policy drift in real time.                               |\\\\n| **Universal Applicability**   | Same pipeline covers ML, infra, analytics, etc.—no bespoke flows.                           |\\\\n| **Transparent Collaboration** | All rationale, context, and hand‑offs observable by any stakeholder.                        |\\\\n\\\\n## 3\\\\xa0·\\\\xa0Objectives\\\\xa0&\\\\xa0Key\\\\xa0Results (12‑month)\\\\n\\\\n| Objective                   | Key Results                                                   |\\\\n| --------------------------- | ------------------------------------------------------------- |\\\\n| **O1\\\\xa0·\\\\xa0Launch MVP**         | KR1\\\\xa0— autonomous red→green run in *safe\\\\\\\\_inmemory* mode.      |\\\\n| **O2\\\\xa0·\\\\xa0Scale Velocity**     | KR2\\\\xa0— median task cycle ≤\\\\u202f1\\\\xa0day; ≥\\\\u202f5 tasks/week/dev.          |\\\\n| **O3\\\\xa0·\\\\xa0Assure Reliability** | KR3\\\\xa0— 0 regressions\\\\xa0post‑commit (tests gate merges).          |\\\\n| **O4\\\\xa0·\\\\xa0Expand Autonomy**    | KR4\\\\xa0— ≥\\\\u202f3 workflow phases fully autonomous, overrides ≤\\\\u202f10\\\\u202f%. |\\\\n| **O5\\\\xa0·\\\\xa0Meta‑optimise**      | KR5\\\\xa0— monthly analytics on bottlenecks & rollback rate.       |\\\\n\\\\n## 4\\\\xa0·\\\\xa0Guiding Principles\\\\n\\\\n1. **Explicit Contracts** — single‑responsibility roles with strict I/O.\\\\n2. **Audit by Default** — every action is logged, nothing silent.\\\\n3. **Fail‑Fast Feedback** — surface errors immediately; automate retries where safe.\\\\n4. **No Hidden\\\\xa0State** — all state serialised and reconstructable.\\\\n5. **Human‑First Overrides** — allowed, but always logged and reviewed.\\\\n\\\\n## 5\\\\xa0·\\\\xa0Glossary\\\\n\\\\n| Term           | Definition                                              |\\\\n| -------------- | ------------------------------------------------------- |\\\\n| **Task**       | Serializable JSON describing work, history, and status. |\\\\n| **Patch**      | Unified diff representing proposed code change.         |\\\\n| **Agent\\\\xa0Slot** | Named interface that may be filled by human or agent.   |\\\\n| **MetaAgent**  | Oversight component that analyses workflow telemetry.   |\\\\n\\\\n---\\\\n\\\\n*Change‑log:* 2025‑06‑20\\\\xa0— consolidated vision; removed marketing prose.\\', \\'docs/architecture.mermaid\\': \\'\\\\nflowchart TD\\\\nsubgraph Orchestrator\\\\nORCH\\\\\\\\[DevOrchestrator]\\\\nend\\\\n\\\\n```\\\\nsubgraph Roles\\\\n    BACK[BacklogManager]\\\\n    GEN[TaskGenerator]\\\\n    EXEC[TaskExecutor]\\\\n    SHELL[ShellRunner]\\\\n    REV[TaskReviewer]\\\\n    RECORD[TaskRecord]\\\\n    META[MetaAgent]\\\\nend\\\\n\\\\nORCH --> BACK\\\\nORCH --> GEN\\\\nORCH --> EXEC\\\\nORCH --> SHELL\\\\nORCH --> REV\\\\nORCH --> RECORD\\\\nORCH --> META\\\\n\\\\nEXEC --> SHELL\\\\nSHELL --> REV\\\\nREV --> ORCH\\\\n\\\\nSHELL --> RECORD\\\\nREV --> RECORD\\\\nMETA --> ORCH\\\\nMETA --> RECORD\\\\n```\\\\n\\\\n%% End of architecture.mmd\\\\n\\'}\\n=================\\nModule Contexts (agent-related):\\n{\\'tools/collect_code.py\\': {\\'purpose\\': \\'Collects, filters, and serializes code and documentation from the Cadence codebase into a unified format (JSON or similar). Enables downstream agents, planners, or tools to access up-to-date, structured representations of the codebase for analysis, context injection, or system introspection. Central to maintaining an accurate global code snapshot for orchestration and LLM prompting.\\', \\'public_api\\': [\\'tools.collect_code.collect\\', \\'tools.collect_code.main\\', \\'tools.collect_code.parse_args\\'], \\'depends_on\\': [\\'argparse\\', \\'json\\', \\'pathlib\\', \\'sys\\'], \\'used_by\\': [], \\'direct_imports\\': [\\'__future__\\', \\'argparse\\', \\'json\\', \\'pathlib\\', \\'sys\\'], \\'related_schemas\\': [\\'CodePayload: {\"<relative/path>\": \"<utf-8 file contents>\"}\\'], \\'context_window_expected\\': \\'Very large – output may exceed 100k tokens for full repo snapshots.\\', \\'escalation_review\\': \\'None – utility script; no sensitive logic. Monitor memory usage on enormous repos.\\', \\'filepath\\': \\'tools/collect_code.py\\'}, \\'tools/gen_prompt.py\\': {\\'purpose\\': \\'Generates rich, contextually appropriate prompts for LLM or agent tasks by assembling relevant code, documentation, and context. It supports selective inclusion/exclusion of source files, size-based filtering, and automatic Markdown / code fencing so that downstream agents receive a single, copy-pastable prompt block. A small CLI wrapper makes it easy to invoke from shell scripts, CI pipelines, or higher-level orchestrators. Typical use-cases include: (1) creating a snapshot for an expert-review agent, (2) feeding an execution agent the entire codebase plus an explicit NEXT TASK header, or (3) archiving project state for later replay or fine-tuning.\\', \\'public_api\\': [\\'tools.gen_prompt._collect_files\\', \\'tools.gen_prompt._build_prompt\\', \\'tools.gen_prompt._parse_args\\', \\'tools.gen_prompt.main\\'], \\'depends_on\\': [], \\'used_by\\': [], \\'direct_imports\\': [\\'__future__\\', \\'argparse\\', \\'pathlib\\', \\'sys\\', \\'textwrap\\'], \\'related_schemas\\': [], \\'context_window_expected\\': \\'Potentially very large (docs + full source snapshot); downstream consumers should be prepared for 50-100k+ tokens.\\', \\'escalation_review\\': \\'\\', \\'filepath\\': \\'tools/gen_prompt.py\\'}, \\'tools/module_contexts.py\\': {\\'purpose\\': \\'Extracts, maintains, and synchronizes structured metadata (“context”) for every module in the codebase, including public API, dependencies, and purpose. Provides the canonical source for module-level documentation and graph relationships, facilitating dependency analysis, agent task planning, and robust context slicing. Ensures context is current and consistent across JSON and other representations.\\', \\'public_api\\': [\\'tools.module_contexts.extract_and_strip_shebang_and_futures\\', \\'tools.module_contexts.find_existing_context\\', \\'tools.module_contexts.get_module_import_path\\', \\'tools.module_contexts.load_all_contexts\\', \\'tools.module_contexts.parse_module\\', \\'tools.module_contexts.print_context\\', \\'tools.module_contexts.relpath\\', \\'tools.module_contexts.render_context_block\\', \\'tools.module_contexts.render_pretty_list\\', \\'tools.module_contexts.scan_all_internal_modules\\', \\'tools.module_contexts.scan_python_modules\\', \\'tools.module_contexts.strip_duplicate_headers_at_top\\', \\'tools.module_contexts.sync_contexts\\', \\'tools.module_contexts.write_all_contexts\\'], \\'depends_on\\': [], \\'used_by\\': [\\'tools.collect_code\\', \\'tools.gen_prompt\\'], \\'direct_imports\\': [\\'ast\\', \\'json\\', \\'os\\', \\'re\\', \\'sys\\'], \\'related_schemas\\': [\\'module_contexts.json\\'], \\'context_window_expected\\': \\'Medium – function-level inspection to full-file parsing (typically <2k LOC).\\', \\'escalation_review\\': \\'None\\', \\'filepath\\': \\'tools/module_contexts.py\\'}, \\'cadence/__init__.py\\': {\\'purpose\\': \\'Declares the Cadence root package for Python module discovery. Contains no implementation but is necessary for package structure and internal import resolution.\\', \\'public_api\\': [], \\'depends_on\\': [], \\'used_by\\': [\\'cadence/dev/command_center.py\\', \\'cadence/agents/base.py\\', \\'examples/test_001/mvp_loop.py\\'], \\'direct_imports\\': [], \\'related_schemas\\': [], \\'context_window_expected\\': \\'Tiny (<5 lines); only package declaration.\\', \\'escalation_review\\': \\'None – purely structural, no executable logic.\\', \\'filepath\\': \\'cadence/__init__.py\\'}, \\'cadence/dev/record.py\\': {\\'purpose\\': \\'Implements persistent, immutable task and state recording for all development workflow phases. Tracks the complete lifecycle of each task (creation, assignment, iterations, review outcomes, and archival), ensuring auditability and full historical replay. Guarantees that every action, override, or failure is logged for compliance and analytics.\\', \\'public_api\\': [\\'cadence.dev.record.TaskRecord\\', \\'cadence.dev.record.TaskRecordError\\'], \\'depends_on\\': [], \\'used_by\\': [\\'cadence.dev.orchestrator\\'], \\'direct_imports\\': [\\'copy\\', \\'datetime\\', \\'json\\', \\'os\\', \\'threading\\', \\'typing\\'], \\'related_schemas\\': [], \\'context_window_expected\\': \\'≈120 source lines; safe to provide in full within a 4-8 k token prompt.\\', \\'escalation_review\\': \\'Modifying persistence logic or on-disk format requires compliance/audit review to avoid breaking historical replay guarantees.\\', \\'filepath\\': \\'cadence/dev/record.py\\'}, \\'cadence/dev/shell.py\\': {\\'purpose\\': \\'Provides a safe abstraction for executing shell commands, running local tests, and managing file operations within the orchestrated workflow. Encapsulates error handling and isolation of subprocesses, allowing higher-level roles (e.g., test runners, commit hooks) to interact with the environment in a controlled and auditable manner.\\', \\'public_api\\': [\\'cadence.dev.shell.ShellCommandError\\', \\'cadence.dev.shell.ShellRunner\\'], \\'depends_on\\': [], \\'used_by\\': [\\'cadence.dev.orchestrator\\', \\'examples.test_001.mvp_loop\\'], \\'direct_imports\\': [\\'os\\', \\'subprocess\\', \\'tempfile\\', \\'typing\\'], \\'related_schemas\\': [], \\'context_window_expected\\': \\'≈250 tokens (short, self-contained utility module)\\', \\'escalation_review\\': \\'\\', \\'filepath\\': \\'cadence/dev/shell.py\\'}, \\'cadence/dev/executor.py\\': {\\'purpose\\': \\'Core implementation of the “TaskExecutor” role: receives a precise task description and produces a proposed code change as a unified diff (patch). Encapsulates patch construction, validation, and integration, acting as the “implementation” phase of the agentic loop. Ensures no code is modified directly—only via auditable diffs.\\', \\'public_api\\': [\\'cadence.dev.executor.PatchBuildError\\', \\'cadence.dev.executor.TaskExecutor\\'], \\'depends_on\\': [], \\'used_by\\': [\\'cadence.dev.orchestrator\\', \\'examples.test_001.mvp_loop\\'], \\'direct_imports\\': [\\'difflib\\', \\'os\\', \\'tempfile\\', \\'typing\\'], \\'related_schemas\\': [\\'task.json (must contain `diff` with `file`, `before`, `after`)\\', \\'unified_diff (GNU patch-compatible format)\\'], \\'context_window_expected\\': \\'~150 lines (moderate)\\', \\'escalation_review\\': \\'Required for any change that alters patch formatting logic or validation heuristics, because downstream components (ShellRunner, Reviewer, Orchestrator) rely on strict diff semantics.\\', \\'filepath\\': \\'cadence/dev/executor.py\\'}, \\'cadence/dev/command_center.py\\': {\\'purpose\\': \\'Aggregates interactive interfaces (CLI, UI, dashboards) for monitoring, guiding, or directly managing the development loop. Orchestrates real-time views of agent activity, backlog, and state, acting as a bridge between human oversight and autonomous agent execution.\\', \\'public_api\\': [\\'cadence.dev.command_center.CONFIG\\', \\'cadence.dev.command_center.orch\\'], \\'depends_on\\': [\\'cadence.dev.orchestrator\\'], \\'used_by\\': [], \\'direct_imports\\': [\\'streamlit\\', \\'cadence.dev.orchestrator\\', \\'pandas\\'], \\'related_schemas\\': [], \\'context_window_expected\\': \\'small\\', \\'escalation_review\\': \\'\\', \\'filepath\\': \\'cadence/dev/command_center.py\\'}, \\'cadence/dev/orchestrator.py\\': {\\'purpose\\': \\'Implements the top-level DevOrchestrator – the single source of truth for sequencing every phase of the Cadence development loop (backlog → generation → patch execution → review → test → commit → archival). Exposes both programmatic and CLI entry-points so humans or agents can drive the end-to-end workflow. Persists all intermediate artefacts (patches, reviews, test results, git SHAs) through TaskRecord for full auditability.\\', \\'public_api\\': [\\'cadence.dev.orchestrator.DevOrchestrator\\'], \\'depends_on\\': [\\'cadence.dev.backlog.BacklogManager\\', \\'cadence.dev.generator.TaskGenerator\\', \\'cadence.dev.executor.TaskExecutor\\', \\'cadence.dev.executor.PatchBuildError\\', \\'cadence.dev.reviewer.TaskReviewer\\', \\'cadence.dev.shell.ShellRunner\\', \\'cadence.dev.shell.ShellCommandError\\', \\'cadence.dev.record.TaskRecord\\', \\'cadence.dev.record.TaskRecordError\\'], \\'used_by\\': [\\'cadence.dev.command_center\\'], \\'direct_imports\\': [\\'argparse\\', \\'sys\\', \\'tabulate\\', \\'.backlog\\', \\'.generator\\', \\'.executor\\', \\'.reviewer\\', \\'.shell\\', \\'.record\\'], \\'related_schemas\\': [\\'backlog_file_schema\\', \\'task_record_schema\\', \\'config_schema\\'], \\'context_window_expected\\': \\'≈180-220 LOC (medium)\\', \\'escalation_review\\': \\'None – orchestrator logic is straightforward, but security/guardrail audit recommended before production use.\\', \\'filepath\\': \\'cadence/dev/orchestrator.py\\'}, \\'cadence/dev/reviewer.py\\': {\\'purpose\\': \\'Implements the “TaskReviewer” role: given a code diff, performs automated or agent-based review for correctness, completeness, style, and policy adherence. Issues pass/fail outcomes and review rationale, blocking or allowing downstream commit/merge actions. Central for maintaining code quality and enforcing multi-agent approval. Provides a pluggable ruleset architecture (built-ins + external JSON) so future LLM/human or policy engines can extend the review surface without touching core logic.\\', \\'public_api\\': [\\'cadence.dev.reviewer.PatchReviewError\\', \\'cadence.dev.reviewer.TaskReviewer\\'], \\'depends_on\\': [], \\'used_by\\': [\\'cadence.dev.orchestrator\\'], \\'direct_imports\\': [\\'json\\', \\'os\\', \\'typing\\'], \\'related_schemas\\': [\\'External ruleset JSON (list[dict{type:str, pattern:str, message?:str}])\\'], \\'context_window_expected\\': \\'Small (<250 LOC) ‑ entire file plus ruleset easily fits typical LLM context.\\', \\'escalation_review\\': \\'Acts as a quality/security gatekeeper; modifications require senior review.\\', \\'filepath\\': \\'cadence/dev/reviewer.py\\'}, \\'cadence/dev/__init__.py\\': {\\'purpose\\': \\'Declares the Cadence dev subpackage for structured module resolution. Contains no runtime implementation but is required so that `import cadence.dev.*` works correctly across the code-base. Although empty, it implicitly enables every module inside `cadence/dev/` (e.g., BacklogManager, TaskExecutor, DevOrchestrator) to be imported as part of the Cadence package hierarchy.\\', \\'public_api\\': [], \\'depends_on\\': [], \\'used_by\\': [\\'cadence.dev.backlog\\', \\'cadence.dev.command_center\\', \\'cadence.dev.executor\\', \\'cadence.dev.generator\\', \\'cadence.dev.orchestrator\\', \\'cadence.dev.record\\', \\'cadence.dev.reviewer\\', \\'cadence.dev.shell\\', \\'examples.test_001.mvp_loop\\'], \\'direct_imports\\': [], \\'related_schemas\\': [], \\'context_window_expected\\': \\'≤10 lines (file is intentionally empty).\\', \\'escalation_review\\': \\'None—trivial placeholder for package initialization.\\', \\'filepath\\': \\'cadence/dev/__init__.py\\'}, \\'cadence/dev/generator.py\\': {\\'purpose\\': \\'Implements the “TaskGenerator” role: proposes, structures, and validates new micro-tasks (from LLMs, rules, or human suggestions). Guarantees that every task entering the backlog is well-formed, actionable, and fully specified, maximizing clarity and minimizing ambiguity for execution agents. Also supports template-driven generation and CLI-style ad-hoc creation for demos or manual workflows.\\', \\'public_api\\': [\\'cadence.dev.generator.TaskGenerator\\', \\'cadence.dev.generator.TaskGenerator.__init__\\', \\'cadence.dev.generator.TaskGenerator.generate_tasks\\', \\'cadence.dev.generator.TaskGenerator.overwrite_tasks\\', \\'cadence.dev.generator.TaskTemplateError\\', \\'cadence.dev.generator.REQUIRED_FIELDS\\'], \\'depends_on\\': [], \\'used_by\\': [\\'cadence.dev.orchestrator\\'], \\'direct_imports\\': [\\'datetime\\', \\'json\\', \\'os\\', \\'typing\\', \\'uuid\\'], \\'related_schemas\\': [\\'cadence.dev.backlog.Task\\'], \\'context_window_expected\\': \\'≈200-250 source lines\\', \\'escalation_review\\': \\'\\', \\'filepath\\': \\'cadence/dev/generator.py\\'}, \\'cadence/dev/backlog.py\\': {\\'purpose\\': \\'Implements the “BacklogManager” role: maintains the prioritized queue of micro-tasks, stories, and epics for development. Provides CRUD operations, status transitions, archival, and JSON persistence. Guarantees that every task object respects a minimal schema and that all state-changes are safely written to disk for downstream agents, UIs, and analytics. Serves as the single source of truth for work-in-progress within the Cadence development loop.\\', \\'public_api\\': [\\'cadence.dev.backlog.BacklogEmptyError\\', \\'cadence.dev.backlog.BacklogManager\\', \\'cadence.dev.backlog.TaskNotFoundError\\', \\'cadence.dev.backlog.TaskStructureError\\'], \\'depends_on\\': [], \\'used_by\\': [\\'cadence.dev.orchestrator\\'], \\'direct_imports\\': [\\'copy\\', \\'datetime\\', \\'json\\', \\'os\\', \\'tabulate\\', \\'typing\\', \\'uuid\\'], \\'related_schemas\\': [{\\'BacklogTask\\': {\\'id\\': \\'str (UUID4, auto-generated if absent)\\', \\'title\\': \\'str (human-readable summary)\\', \\'type\\': \\'str (one of \"micro\", \"story\", \"epic\"; default \"micro\")\\', \\'status\\': \\'str (one of \"open\", \"in_progress\", \"done\", \"archived\"; default \"open\")\\', \\'created_at\\': \\'str (UTC ISO-8601; auto-generated if absent)\\', \\'...\\': \\'additional arbitrary fields permitted\\'}}], \\'context_window_expected\\': \\'≈120 LOC – comfortably fits within standard 8-16 k token LLM windows.\\', \\'escalation_review\\': \\'None – module is self-contained and side-effect-limited (file IO only).\\', \\'filepath\\': \\'cadence/dev/backlog.py\\'}, \\'cadence/agents/base.py\\': {\\'purpose\\': \\'Core superclass that now consumes an AgentProfile instead of raw model strings. Handles messaging stack, LLM calls, context gathering, and persistence. No subclass should hard-code models any more.\\', \\'public_api\\': [\\'cadence.agents.base.BaseAgent\\'], \\'depends_on\\': [\\'cadence.agents.profile\\', \\'cadence.llm.client\\', \\'cadence.context.provider\\'], \\'used_by\\': [\\'cadence.agents.reasoning\\', \\'cadence.agents.execution\\', \\'cadence.agents.efficiency\\'], \\'direct_imports\\': [\\'typing\\', \\'pathlib\\', \\'cadence.llm.client\\', \\'cadence.context.provider\\', \\'cadence.agents.profile\\'], \\'context_window_expected\\': \\'≈100 LOC\\', \\'filepath\\': \\'cadence/agents/base.py\\'}, \\'cadence/agents/efficiency.py\\': {\\'purpose\\': \\'Final EfficiencyAgent using EFFICIENCY_PROFILE; low-cost linting & summarisation.\\', \\'public_api\\': [\\'cadence.agents.efficiency.EfficiencyAgent\\'], \\'depends_on\\': [\\'cadence.agents.base\\', \\'cadence.agents.profile\\'], \\'filepath\\': \\'cadence/agents/efficiency.py\\'}, \\'cadence/agents/reasoning.py\\': {\\'purpose\\': \\'Final ReasoningAgent using REASONING_PROFILE; injects code/doc snapshot on reset.\\', \\'public_api\\': [\\'cadence.agents.reasoning.ReasoningAgent\\'], \\'depends_on\\': [\\'cadence.agents.base\\', \\'cadence.agents.profile\\'], \\'direct_imports\\': [\\'cadence.agents.base\\', \\'cadence.agents.profile\\'], \\'filepath\\': \\'cadence/agents/reasoning.py\\'}, \\'cadence/agents/__init__.py\\': {\\'purpose\\': \\'Declares the Cadence agents subpackage for structured module resolution. Contains no implementation but is required so that all sub-modules (base, execution, efficiency, reasoning, registry) can be imported with the fully-qualified \"cadence.agents.*\" path.\\', \\'public_api\\': [], \\'depends_on\\': [], \\'used_by\\': [\\'cadence.agents.base\\', \\'cadence.agents.efficiency\\', \\'cadence.agents.execution\\', \\'cadence.agents.reasoning\\', \\'cadence.agents.registry\\'], \\'direct_imports\\': [], \\'related_schemas\\': [], \\'context_window_expected\\': \\'negligible (file is empty)\\', \\'escalation_review\\': \\'none—simple package marker\\', \\'filepath\\': \\'cadence/agents/__init__.py\\'}, \\'cadence/agents/registry.py\\': {\\'purpose\\': \\'Central registry now exposes both Core Agents and AgentProfiles for external callers.\\', \\'public_api\\': [\\'cadence.agents.registry.get_agent\\', \\'cadence.agents.registry.get_profile\\'], \\'depends_on\\': [\\'cadence.agents.reasoning\\', \\'cadence.agents.execution\\', \\'cadence.agents.efficiency\\', \\'cadence.agents.profile\\'], \\'filepath\\': \\'cadence/agents/registry.py\\'}, \\'cadence/agents/execution.py\\': {\\'purpose\\': \\'Final ExecutionAgent using EXECUTION_PROFILE; dedicated to code generation/refactor tasks.\\', \\'public_api\\': [\\'cadence.agents.execution.ExecutionAgent\\'], \\'depends_on\\': [\\'cadence.agents.base\\', \\'cadence.agents.profile\\'], \\'filepath\\': \\'cadence/agents/execution.py\\'}, \\'cadence/llm/client.py\\': {\\'purpose\\': \\'Abstracts and manages all LLM client connections, credentials, and request handling for Cadence agents. Provides unified access to various model endpoints, context window management, and API configuration, allowing agents to query or delegate to LLMs without bespoke integration code.\\', \\'public_api\\': [\\'cadence.llm.client.LLMClient\\', \\'cadence.llm.client.get_default_client\\', \\'cadence.llm.client.get_env\\'], \\'depends_on\\': [], \\'used_by\\': [\\'cadence.agents.base\\'], \\'direct_imports\\': [\\'asyncio\\', \\'dotenv\\', \\'logging\\', \\'openai\\', \\'os\\', \\'typing\\'], \\'related_schemas\\': [], \\'context_window_expected\\': \\'Dependent on selected OpenAI model (defaults to ~8K tokens for GPT-4-class models). Callers should chunk/summarize if larger context is required.\\', \\'escalation_review\\': \\'\\', \\'filepath\\': \\'cadence/llm/client.py\\'}, \\'cadence/llm/__init__.py\\': {\\'purpose\\': \\'Declares the Cadence LLM subpackage for structured module resolution. Contains no implementation but ensures correct imports for LLM client components. Serves as the namespace anchor for any sub-modules under `cadence.llm` so that external code can reliably import `cadence.llm.*` symbols.\\', \\'public_api\\': [], \\'depends_on\\': [], \\'used_by\\': [\\'cadence.llm.client\\', \\'cadence.agents.base\\'], \\'direct_imports\\': [], \\'related_schemas\\': [], \\'context_window_expected\\': \\'≤5 LOC (trivial stub)\\', \\'escalation_review\\': \\'None – inert stub file\\', \\'filepath\\': \\'cadence/llm/__init__.py\\'}, \\'cadence/agents/profile.py\\': {\\'purpose\\': \\'Introduces immutable AgentProfile dataclass holding model, context-limit, review policy, etc. Decouples runtime behaviour from static configuration and is the canonical source for profile data used by Core Agents and governance utilities.\\', \\'public_api\\': [\\'cadence.agents.profile.AgentProfile\\', \\'cadence.agents.profile.REASONING_PROFILE\\', \\'cadence.agents.profile.EXECUTION_PROFILE\\', \\'cadence.agents.profile.EFFICIENCY_PROFILE\\', \\'cadence.agents.profile.BUILTIN_PROFILES\\'], \\'depends_on\\': [], \\'used_by\\': [\\'cadence.agents.base\\', \\'cadence.agents.reasoning\\', \\'cadence.agents.execution\\', \\'cadence.agents.efficiency\\', \\'cadence.agents.sidekick\\', \\'cadence.agents.registry\\'], \\'direct_imports\\': [\\'dataclasses\\', \\'typing\\'], \\'context_window_expected\\': \\'trivial (<40 LOC)\\', \\'filepath\\': \\'cadence/agents/profile.py\\'}, \\'cadence/agents/sidekick.py\\': {\\'purpose\\': \\'Persona wrapper that delegates to ReasoningAgent rather than subclassing it, maintaining separation between capability and persona.\\', \\'public_api\\': [\\'cadence.agents.sidekick.Sidekick\\'], \\'depends_on\\': [\\'cadence.agents.reasoning\\', \\'cadence.agents.profile\\'], \\'filepath\\': \\'cadence/agents/sidekick.py\\'}}\\n=================\\nActual Code (agent-related):\\n{\\'cadence/__init__.py\\': \\'\\\\n\\', \\'cadence/context/provider.py\\': \\'import subprocess, sys, json\\\\nfrom abc import ABC, abstractmethod\\\\nfrom pathlib import Path\\\\nclass ContextProvider(ABC):\\\\n    @abstractmethod\\\\n    def get_context(self, *roots: Path, exts=(\".py\", \".md\"), max_bytes=50_000) -> str: ...\\\\nclass SnapshotContextProvider(ContextProvider):\\\\n    def get_context(self, *roots, exts=(\".py\", \".md\"), max_bytes=50_000, out=\"-\") -> str:\\\\n        args = [sys.executable, \"tools/collect_code.py\"]\\\\n        for r in roots: args += [\"--root\", str(r)]\\\\n        for e in exts:  args += [\"--ext\", e]\\\\n        args += [\"--max-bytes\", str(max_bytes), \"--out\", out]\\\\n        return subprocess.run(args, capture_output=True, text=True, check=True).stdout\\\\n\\', \\'cadence/context/__init__.py\\': \\'\\', \\'cadence/dev/record.py\\': \\'\\\\n# cadence/dev/record.py\\\\n\\\\n\"\"\"\\\\nCadence TaskRecord\\\\n-----------------\\\\nSingle Responsibility: Append/persist task processtates for full audit/repro. \\\\nWrite/read only here. \\\\nFile format: JSON list of dicts, one per unique task_id; each has history of states/iterations.\\\\n\"\"\"\\\\n\\\\nimport os\\\\nimport json\\\\nimport threading\\\\nimport copy\\\\nfrom typing import List, Dict, Optional\\\\n\\\\nclass TaskRecordError(Exception):\\\\n    \"\"\"Custom error for task record issues.\"\"\"\\\\n    pass\\\\n\\\\nclass TaskRecord:\\\\n    def __init__(self, record_file: str):\\\\n        self.record_file = record_file\\\\n        self._lock = threading.Lock()\\\\n        # Always keep in-memory up to date with file\\\\n        self._records: List[Dict] = []\\\\n        self._idmap: Dict[str, Dict] = {}  # task_id -> record dict\\\\n        self._load()\\\\n\\\\n    def save(self, task: dict, state: str, extra: dict = None) -> None:\\\\n        \"\"\"\\\\n        Records a snapshot for given task_id and state (e.g. \"patch_proposed\", \"patch_reviewed\", etc).\\\\n        Extra provides arbitrary info (patch, review, commit_sha, test_results, etc).\\\\n        If task does not exist (task_id is new), creates new record.\\\\n        \"\"\"\\\\n        with self._lock:\\\\n            record = self._find_or_create_record(task)\\\\n            snapshot = {\\\\n                \"state\": state,\\\\n                \"timestamp\": self._now(),\\\\n                \"task\": copy.deepcopy(task),\\\\n                \"extra\": copy.deepcopy(extra) if extra else {},\\\\n            }\\\\n            record[\"history\"].append(snapshot)\\\\n            self._sync_idmap()\\\\n            self._persist()\\\\n\\\\n    def load(self) -> List[Dict]:\\\\n        \"\"\"\\\\n        Returns a (deep) copy of all records (full history).\\\\n        \"\"\"\\\\n        with self._lock:\\\\n            return copy.deepcopy(self._records)\\\\n\\\\n    def append_iteration(self, task_id: str, iteration: dict) -> None:\\\\n        \"\"\"\\\\n        Appends a new step/edit/review (dict) to a task\\\\\\'s record—usually finer-grained than save().\\\\n        \"\"\"\\\\n        with self._lock:\\\\n            record = self._find_record(task_id)\\\\n            if record is None:\\\\n                raise TaskRecordError(f\"No record for task id={task_id}\")\\\\n            iter_snapshot = {\\\\n                \"timestamp\": self._now(),\\\\n                **copy.deepcopy(iteration)\\\\n            }\\\\n            record.setdefault(\"iterations\", []).append(iter_snapshot)\\\\n            self._persist()\\\\n\\\\n    # ========== Internal Below ==========\\\\n\\\\n    def _find_or_create_record(self, task: dict) -> Dict:\\\\n        \"\"\"\\\\n        Finds or creates a new record for given task.\\\\n        \"\"\"\\\\n        tid = self._get_task_id(task)\\\\n        rec = self._idmap.get(tid)\\\\n        if rec is None:\\\\n            rec = {\\\\n                \"task_id\": tid,\\\\n                \"created_at\": self._now(),\\\\n                \"history\": [],\\\\n                \"iterations\": []\\\\n            }\\\\n            self._records.append(rec)\\\\n            self._idmap[tid] = rec\\\\n        return rec\\\\n\\\\n    def _find_record(self, task_id: str) -> Optional[Dict]:\\\\n        return self._idmap.get(task_id)\\\\n\\\\n    def _get_task_id(self, task: dict) -> str:\\\\n        tid = task.get(\"id\")\\\\n        if not tid:\\\\n            raise TaskRecordError(\"Task dict missing \\\\\\'id\\\\\\'. Cannot save record.\")\\\\n        return tid\\\\n\\\\n    def _persist(self) -> None:\\\\n        \"\"\"\\\\n        Writes in-memory records to disk, atomic/overwrite (JSON).\\\\n        \"\"\"\\\\n        tmp = self.record_file + \".tmp\"\\\\n        with open(tmp, \"w\", encoding=\"utf8\") as f:\\\\n            json.dump(self._records, f, indent=2)\\\\n        os.replace(tmp, self.record_file)\\\\n\\\\n    def _load(self) -> None:\\\\n        \"\"\"Loads file into memory iff exists. Otherwise, empty record.\"\"\"\\\\n        if not os.path.exists(self.record_file):\\\\n            self._records = []\\\\n            self._idmap = {}\\\\n            return\\\\n        with open(self.record_file, \"r\", encoding=\"utf8\") as f:\\\\n            self._records = json.load(f)\\\\n        self._sync_idmap()\\\\n\\\\n    def _sync_idmap(self):\\\\n        \"\"\"Ensures self._idmap is up to date with self._records.\"\"\"\\\\n        self._idmap = {rec[\"task_id\"]: rec for rec in self._records}\\\\n\\\\n    def _now(self):\\\\n        from datetime import datetime\\\\n        return datetime.utcnow().isoformat()\\\\n\\\\n# Example CLI/sanity use (not for prod)\\\\nif __name__ == \"__main__\":\\\\n    rec = TaskRecord(\"dev_record.json\")\\\\n    tid = \"a1b2c3\"\\\\n    # Save new record\\\\n    task = {\"id\": tid, \"title\": \"Do something\", \"status\": \"open\"}\\\\n    rec.save(task, state=\"patch_proposed\", extra={\"patch\": \"--- foo\"})\\\\n    # Append an iteration (e.g., reviewer comment)\\\\n    rec.append_iteration(tid, {\"reviewer\": \"alice\", \"opinion\": \"looks good\"})\\\\n    # Print record for tid\\\\n    print(json.dumps(rec.load(), indent=2))\\', \\'cadence/dev/shell.py\\': \\'\\\\n# cadence/dev/shell.py\\\\n\\\\n\"\"\"\\\\nCadence ShellRunner\\\\n-------------------\\\\nSingle Responsibility: Isolated safe shell/git/pytest operations, *never* creates code/diffs.\\\\nNever does role boundaries\\\\\\' work. All subprocesses run in isolated, safe manner.\\\\n\"\"\"\\\\n\\\\nimport os\\\\nimport subprocess\\\\nimport tempfile\\\\nfrom typing import Optional, Dict\\\\n\\\\nclass ShellCommandError(Exception):\\\\n    \"\"\"Raised when a shell/git/pytest command fails.\"\"\"\\\\n    pass\\\\n\\\\nclass ShellRunner:\\\\n    def __init__(self, repo_dir: str = \".\"):\\\\n        self.repo_dir = os.path.abspath(repo_dir)\\\\n        if not os.path.isdir(self.repo_dir):\\\\n            raise ValueError(f\"repo_dir \\\\\\'{self.repo_dir}\\\\\\' does not exist or is not a directory.\")\\\\n\\\\n    def git_apply(self, patch: str) -> bool:\\\\n        \"\"\"\\\\n        Applies patch to working tree using \\\\\\'git apply\\\\\\'.\\\\n        Returns True if successful.\\\\n        Raises ShellCommandError if fail.\\\\n        \"\"\"\\\\n        if not patch or not isinstance(patch, str):\\\\n            raise ShellCommandError(\"No patch supplied to apply.\")\\\\n        # Write patch to a temp file to apply\\\\n        with tempfile.NamedTemporaryFile(mode=\"w+\", suffix=\".patch\", delete=False) as tf:\\\\n            tf.write(patch)\\\\n            tf.flush()\\\\n            tf_path = tf.name\\\\n        try:\\\\n            result = subprocess.run(\\\\n                [\"git\", \"apply\", tf_path],\\\\n                cwd=self.repo_dir,\\\\n                stdout=subprocess.PIPE,\\\\n                stderr=subprocess.PIPE,\\\\n                encoding=\"utf-8\",\\\\n                check=False\\\\n            )\\\\n            if result.returncode != 0:\\\\n                raise ShellCommandError(f\"git apply failed: {result.stderr.strip()}\")\\\\n            return True\\\\n        finally:\\\\n            os.remove(tf_path)\\\\n\\\\n    def run_pytest(self, test_path: Optional[str] = None) -> Dict:\\\\n        \"\"\"\\\\n        Runs pytest on the given path (default: repo_dir or ./tests).\\\\n        Returns summary dict: {\\\\\\'success\\\\\\': bool, \\\\\\'output\\\\\\': str}\\\\n        Raises ShellCommandError if pytest is not found.\\\\n        \"\"\"\\\\n        path = test_path or os.path.join(self.repo_dir, \"tests\")\\\\n        if not os.path.exists(path):\\\\n            raise ShellCommandError(f\"Tests path \\\\\\'{path}\\\\\\' does not exist.\")\\\\n        try:\\\\n            result = subprocess.run(\\\\n                [\"pytest\", \"-q\", path],\\\\n                cwd=self.repo_dir,\\\\n                stdout=subprocess.PIPE,\\\\n                stderr=subprocess.PIPE,\\\\n                encoding=\"utf-8\",\\\\n                check=False\\\\n            )\\\\n            passed = (result.returncode == 0)\\\\n            output = (result.stdout or \"\") + \"\\\\\\\\n\" + (result.stderr or \"\")\\\\n            return {\"success\": passed, \"output\": output.strip()}\\\\n        except FileNotFoundError as e:\\\\n            raise ShellCommandError(\"pytest is not installed or not in PATH.\") from e\\\\n\\\\n    def git_commit(self, message: str) -> str:\\\\n        \"\"\"\\\\n        Commits all staged/changed files with given commit message in repo_dir.\\\\n        Returns commit SHA string.\\\\n        Raises ShellCommandError on fail.\\\\n        \"\"\"\\\\n        # Stage all (for MVP); fine-grained logic can be added if needed.\\\\n        result = subprocess.run(\\\\n            [\"git\", \"add\", \"-A\"],\\\\n            cwd=self.repo_dir,\\\\n            stdout=subprocess.PIPE,\\\\n            stderr=subprocess.PIPE,\\\\n            encoding=\"utf-8\",\\\\n            check=False\\\\n        )\\\\n        if result.returncode != 0:\\\\n            raise ShellCommandError(f\"git add failed: {result.stderr.strip()}\")\\\\n        # Commit\\\\n        result = subprocess.run(\\\\n            [\"git\", \"commit\", \"-m\", message],\\\\n            cwd=self.repo_dir,\\\\n            stdout=subprocess.PIPE,\\\\n            stderr=subprocess.PIPE,\\\\n            encoding=\"utf-8\",\\\\n            check=False\\\\n        )\\\\n        if result.returncode != 0:\\\\n            if \"nothing to commit\" in (result.stderr + result.stdout).lower():\\\\n                raise ShellCommandError(\"git commit: nothing to commit.\")\\\\n            else:\\\\n                raise ShellCommandError(f\"git commit failed: {result.stderr.strip()}\")\\\\n        # Get last commit SHA\\\\n        result = subprocess.run(\\\\n            [\"git\", \"rev-parse\", \"HEAD\"],\\\\n            cwd=self.repo_dir,\\\\n            stdout=subprocess.PIPE,\\\\n            stderr=subprocess.PIPE,\\\\n            encoding=\"utf-8\",\\\\n            check=True\\\\n        )\\\\n        sha = result.stdout.strip()\\\\n        return sha\\\\n\\\\n# Example CLI/dev use\\\\nif __name__ == \"__main__\":\\\\n    runner = ShellRunner(\".\")\\\\n    # runner.git_apply(\\\\\\'--- a/foo.py\\\\\\\\n+++ b/foo.py\\\\\\\\n...\\\\\\')  # Patch string\\\\n    # print(runner.run_pytest())\\\\n    # print(runner.git_commit(\"Demo commit\"))\\', \\'cadence/dev/executor.py\\': \\'\\\\n# cadence/dev/executor.py\\\\n\\\\n\"\"\"\\\\nCadence TaskExecutor\\\\n-------------------\\\\nSingle Responsibility: Given a task, produce a code/text patch (unapplied). Never applies, commits, or tests.\\\\nExtensible: can be subclassed or composed with LLM/crowd agents for codegen/refinement.\\\\n\"\"\"\\\\n\\\\nimport os\\\\nimport difflib\\\\nimport tempfile\\\\nfrom typing import Dict, Optional, List\\\\n\\\\nclass PatchBuildError(Exception):\\\\n    \"\"\"Raised if patch/diff cannot be produced.\"\"\"\\\\n    pass\\\\n\\\\n\\\\nclass TaskExecutor:\\\\n    def __init__(self, src_root: str):\\\\n        if not os.path.isdir(src_root):\\\\n            raise ValueError(f\"src_root \\\\\\'{src_root}\\\\\\' is not a directory.\")\\\\n        self.src_root = os.path.abspath(src_root)\\\\n\\\\n    def build_patch(self, task: Dict) -> str:\\\\n        \"\"\"\\\\n        Given selected task (dict), produce diff/patch string.\\\\n        - For simplicity, expects \\\\\\'file\\\\\\', \\\\\\'before\\\\\\', \\\\\\'after\\\\\\' in task[\\\\\\'diff\\\\\\'].\\\\n        - Never applies patch.\\\\n        - Returns unified diff as UTF-8 str.\\\\n        \"\"\"\\\\n        try:\\\\n            diff_info = task.get(\\\\\\'diff\\\\\\')\\\\n            if not diff_info:\\\\n                raise PatchBuildError(\"Task missing \\\\\\'diff\\\\\\' key. Task must include code diff directives.\")\\\\n\\\\n            file_rel = diff_info.get(\\\\\\'file\\\\\\')\\\\n            before = diff_info.get(\\\\\\'before\\\\\\')\\\\n            after = diff_info.get(\\\\\\'after\\\\\\')\\\\n            if not file_rel or before is None or after is None:\\\\n                raise PatchBuildError(\"Diff dict must have \\\\\\'file\\\\\\', \\\\\\'before\\\\\\', and \\\\\\'after\\\\\\' (as strings).\")\\\\n\\\\n            file_abs = os.path.join(self.src_root, file_rel)\\\\n            # Ensure trailing newline for correct diff context\\\\n            if not before.endswith(\"\\\\\\\\n\"):\\\\n                before += \"\\\\\\\\n\"\\\\n            if not after.endswith(\"\\\\\\\\n\"):\\\\n                after += \"\\\\\\\\n\"\\\\n\\\\n            before_lines = before.splitlines(keepends=True)\\\\n            after_lines  = after.splitlines(keepends=True)\\\\n\\\\n            diff_lines = list(difflib.unified_diff(\\\\n                before_lines,\\\\n                after_lines,\\\\n                fromfile=f\"a/{file_rel}\",\\\\n                tofile=f\"b/{file_rel}\",\\\\n                # use default lineterm=\\\\\\'\\\\\\\\n\\\\\\' for consistent newlines\\\\n            ))\\\\n            patch = \"\".join(diff_lines)\\\\n            if not patch.strip():\\\\n                raise PatchBuildError(\"Generated patch is empty.\")\\\\n\\\\n            # Logically, do NOT write/apply - that\\\\\\'s ShellRunner\\\\\\'s responsibility.\\\\n            return patch\\\\n        except Exception as e:\\\\n            raise PatchBuildError(f\"Failed to build patch: {e}\")\\\\n\\\\n    def refine_patch(self, task: Dict, feedback: str) -> str:\\\\n        \"\"\"\\\\n        Propose a revised patch, given task and feedback (from reviewer/human).\\\\n        Here, we\\\\\\'re stubbed for simplicity - can be extended to call LLM/code agent.\\\\n        - Returns new diff/patch string.\\\\n        \"\"\"\\\\n        # In a future agentic system, call out to LLM or microservice here with context.\\\\n        # Example hook: (pseudo) agent.generate_patch(task, feedback)\\\\n        # For now, just raise if not implemented.\\\\n        raise NotImplementedError(\"Patch refinement requires agent integration or human intervention.\")\\\\n\\\\n    # Optionally: you can add utility for validating a patch (not apply!).\\\\n    def validate_patch(self, patch: str) -> bool:\\\\n        \"\"\"\\\\n        Returns True if patch is nontrivial and properly formatted.\\\\n        (Simple heuristic only; actual application/testing is ShellRunner\\\\\\'s job.)\\\\n        \"\"\"\\\\n        return bool(patch and patch.startswith(\\\\\\'---\\\\\\'))\\\\n\\\\n# Example CLI/dev usage\\\\nif __name__ == \"__main__\":\\\\n    # Example simulated task:\\\\n    executor = TaskExecutor(src_root=\"cadence\")\\\\n    sample_task = {\\\\n        \"id\": \"testid\",\\\\n        \"diff\": {\\\\n            \"file\": \"sample_module.py\",\\\\n            \"before\": \"# Old code\\\\\\\\nprint(\\\\\\'Hello\\\\\\')\\\\\\\\n\",\\\\n            \"after\":  \"# Old code\\\\\\\\nprint(\\\\\\'Hello, world!\\\\\\')\\\\\\\\n\"\\\\n        }\\\\n    }\\\\n    patch = executor.build_patch(sample_task)\\\\n    print(\"--- PATCH OUTPUT ---\")\\\\n    print(patch)\\', \\'cadence/dev/command_center.py\\': \\'\\\\n# Cadence/dev/command_center.py\\\\n\\\\nimport streamlit as st\\\\n\\\\n# You may need to adjust the import path according to your setup\\\\nfrom cadence.dev.orchestrator import DevOrchestrator\\\\n\\\\n# ---- Basic Config (map to your dev environment) ----\\\\nCONFIG = dict(\\\\n    backlog_path=\"dev_backlog.json\",\\\\n    template_file=\"dev_templates.json\",\\\\n    src_root=\"cadence\",\\\\n    ruleset_file=None,\\\\n    repo_dir=\".\",\\\\n    record_file=\"dev_record.json\"\\\\n)\\\\norch = DevOrchestrator(CONFIG)\\\\n\\\\n# ---- Session State Initialization ----\\\\nif \"selected_task_id\" not in st.session_state:\\\\n    st.session_state[\"selected_task_id\"] = None\\\\nif \"phase\" not in st.session_state:\\\\n    st.session_state[\"phase\"] = \"Backlog\"\\\\n\\\\n# ---- Sidebar: Phase Navigation ----\\\\nst.sidebar.title(\"Cadence Dev Center\")\\\\nphase = st.sidebar.radio(\\\\n    \"Workflow phase\",\\\\n    [\"Backlog\", \"Task Detail\", \"Patch Review\", \"Run Test\", \"Archive\"],\\\\n    index=[\"Backlog\", \"Task Detail\", \"Patch Review\", \"Run Test\", \"Archive\"].index(st.session_state[\"phase\"])\\\\n)\\\\nst.session_state[\"phase\"] = phase\\\\n\\\\n# ---- Main: Backlog View ----\\\\nif phase == \"Backlog\":\\\\n    st.title(\"Task Backlog\")\\\\n    open_tasks = orch.backlog.list_items(status=\"open\")\\\\n    if not open_tasks:\\\\n        st.info(\"No open tasks! Add tasks via CLI/Notebook.\")\\\\n    else:\\\\n        import pandas as pd\\\\n        df = pd.DataFrame(open_tasks)\\\\n        st.dataframe(df[[\"id\", \"title\", \"type\", \"status\", \"created_at\"]])\\\\n        selected = st.selectbox(\\\\n            \"Select a task to work on\",\\\\n            options=[t[\"id\"] for t in open_tasks],\\\\n            format_func=lambda tid: f\\\\\\'{tid[:8]}: {next(t[\"title\"] for t in open_tasks if t[\"id\"] == tid)}\\\\\\'\\\\n        )\\\\n        if st.button(\"Continue to task detail\"):\\\\n            st.session_state[\"selected_task_id\"] = selected\\\\n            st.session_state[\"phase\"] = \"Task Detail\"\\\\n            st.experimental_rerun()\\\\n\\\\n# ---- Task Detail View ----\\\\nelif phase == \"Task Detail\":\\\\n    st.title(\"Task Details\")\\\\n    task_id = st.session_state.get(\"selected_task_id\")\\\\n    if not task_id:\\\\n        st.warning(\"No task selected.\")\\\\n        st.stop()\\\\n    task = orch.backlog.get_item(task_id)\\\\n    st.markdown(f\"**Title:** {task[\\\\\\'title\\\\\\']}\\\\\\\\n\\\\\\\\n**Type:** {task[\\\\\\'type\\\\\\']}\\\\\\\\n\\\\\\\\n**Status:** {task[\\\\\\'status\\\\\\']}\\\\\\\\n\\\\\\\\n**Created:** {task[\\\\\\'created_at\\\\\\']}\")\\\\n    st.code(task.get(\"description\", \"\"), language=\"markdown\")\\\\n    st.json(task)\\\\n    if st.button(\"Proceed to Patch Review\"):\\\\n        st.session_state[\"phase\"] = \"Patch Review\"\\\\n        st.experimental_rerun()\\\\n    if st.button(\"Back to backlog\"):\\\\n        st.session_state[\"phase\"] = \"Backlog\"\\\\n        st.experimental_rerun()\\\\n\\\\n# ---- Patch Review ----\\\\nelif phase == \"Patch Review\":\\\\n    st.title(\"Patch Review & Approval\")\\\\n    task_id = st.session_state.get(\"selected_task_id\")\\\\n    if not task_id:\\\\n        st.warning(\"No task selected.\")\\\\n        st.stop()\\\\n    task = orch.backlog.get_item(task_id)\\\\n    try:\\\\n        patch = orch.executor.build_patch(task)\\\\n        st.code(patch, language=\"diff\")\\\\n        review = orch.reviewer.review_patch(patch, context=task)\\\\n        st.markdown(\"### Review Comments\")\\\\n        st.markdown(review[\"comments\"] or \"_No issues detected._\")\\\\n        if review[\"pass\"]:\\\\n            if st.button(\"Approve and Apply Patch\"):\\\\n                # Apply patch, save, and proceed\\\\n                orch.shell.git_apply(patch)\\\\n                orch.record.save(task, state=\"patch_applied\", extra={})\\\\n                st.success(\"Patch applied.\")\\\\n                st.session_state[\"phase\"] = \"Run Test\"\\\\n                st.experimental_rerun()\\\\n        else:\\\\n            st.error(\"Patch failed review; please revise before continuing.\")\\\\n            if st.button(\"Back to task detail\"):\\\\n                st.session_state[\"phase\"] = \"Task Detail\"\\\\n                st.experimental_rerun()\\\\n    except Exception as ex:\\\\n        st.error(f\"Patch build/review failed: {ex}\")\\\\n        if st.button(\"Back to task detail\"):\\\\n            st.session_state[\"phase\"] = \"Task Detail\"\\\\n            st.experimental_rerun()\\\\n\\\\n# ---- Run Test ----\\\\nelif phase == \"Run Test\":\\\\n    st.title(\"Run Pytest\")\\\\n    task_id = st.session_state.get(\"selected_task_id\")\\\\n    if not task_id:\\\\n        st.warning(\"No task selected.\")\\\\n        st.stop()\\\\n    st.markdown(\"Apply code patch complete. Run tests to confirm correctness.\")\\\\n    if st.button(\"Run tests now\"):\\\\n        test_result = orch.shell.run_pytest()\\\\n        st.text_area(\"Test Output\", test_result[\"output\"], height=200)\\\\n        if test_result[\"success\"]:\\\\n            st.success(\"Tests passed!\")\\\\n            if st.button(\"Proceed to Archive/Done\"):\\\\n                # Commit and archive task\\\\n                task = orch.backlog.get_item(task_id)\\\\n                sha = orch.shell.git_commit(f\"[Cadence] {task[\\\\\\'id\\\\\\'][:8]} {task.get(\\\\\\'title\\\\\\', \\\\\\'\\\\\\')}\")\\\\n                orch.backlog.update_item(task_id, {\"status\": \"done\"})\\\\n                orch.backlog.archive_completed()\\\\n                orch.record.save(task, state=\"committed\", extra={\"commit_sha\": sha})\\\\n                orch.record.save(task, state=\"archived\", extra={})\\\\n                st.session_state[\"phase\"] = \"Archive\"\\\\n                st.experimental_rerun()\\\\n        else:\\\\n            st.error(\"Tests failed, fix required before progressing.\")\\\\n    if st.button(\"Back to patch review\"):\\\\n        st.session_state[\"phase\"] = \"Patch Review\"\\\\n        st.experimental_rerun()\\\\n\\\\n# ---- Archive / Task Complete ----\\\\nelif phase == \"Archive\":\\\\n    st.title(\"Task Archived\")\\\\n    st.success(\"Task flow completed. You may return to the backlog.\")\\\\n    if st.button(\"Back to backlog\"):\\\\n        st.session_state[\"selected_task_id\"] = None\\\\n        st.session_state[\"phase\"] = \"Backlog\"\\\\n        st.experimental_rerun()\\', \\'cadence/dev/orchestrator.py\\': \\'\\\\n# cadence/dev/orchestrator.py\\\\n\\\\n\"\"\"\\\\nCadence DevOrchestrator\\\\n----------------------\\\\nCoordinated, single-point-of-control workflow runner\\\\nacross backlog, generation, patching, review, shell, and record roles.\\\\nNo cross-cutting, no skipped steps. \\\\nAgent/extensible. Ready for CLI or notebook invocation.\\\\n\"\"\"\\\\n\\\\nfrom .backlog import BacklogManager\\\\nfrom .generator import TaskGenerator\\\\nfrom .executor import TaskExecutor, PatchBuildError\\\\nfrom .reviewer import TaskReviewer\\\\nfrom .shell import ShellRunner, ShellCommandError\\\\nfrom .record import TaskRecord, TaskRecordError\\\\n\\\\nimport sys\\\\n\\\\nclass DevOrchestrator:\\\\n    def __init__(self, config: dict):\\\\n        self.backlog = BacklogManager(config[\"backlog_path\"])\\\\n        self.generator = TaskGenerator(config.get(\"template_file\"))\\\\n        self.executor = TaskExecutor(config[\"src_root\"])\\\\n        self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\\\\n        self.shell = ShellRunner(config[\"repo_dir\"])\\\\n        self.record = TaskRecord(config[\"record_file\"])\\\\n\\\\n    # ----- Backlog overview -----\\\\n    def show(self, status: str = \"open\", printout: bool = True):\\\\n        \"\"\"Print or return backlog overview.\"\"\"\\\\n        items = self.backlog.list_items(status)\\\\n        if printout:\\\\n            print(self._format_backlog(items))\\\\n        return items\\\\n\\\\n    def _format_backlog(self, items):\\\\n        if not items:\\\\n            return \"(Backlog empty)\"\\\\n        from tabulate import tabulate\\\\n        rows = [\\\\n            (\\\\n                t[\"id\"][:8], t.get(\"title\", \"\")[:48], t.get(\"type\", \"\"),\\\\n                t.get(\"status\", \"\"), t.get(\"created_at\", \"\")[:19]\\\\n            )\\\\n            for t in items if t.get(\"status\") != \"archived\"\\\\n        ]\\\\n        headers = [\"id\", \"title\", \"type\", \"status\", \"created\"]\\\\n        return tabulate(rows, headers, tablefmt=\"github\")\\\\n    \\\\n    # ----- Main workflow -----\\\\n    def run_task_cycle(self, select_id: str = None, interactive: bool = True):\\\\n        \"\"\"\\\\n        Full end-to-end workflow for one microtask:\\\\n        1. Select task\\\\n        2. Build patch\\\\n        3. Reviewer check\\\\n        4. Apply patch (git)\\\\n        5. Run pytest\\\\n        6. Reviewer final check (optional)\\\\n        7. git commit if passes; record everything\\\\n        8. Mark task done/archived if complete\\\\n\\\\n        Args:\\\\n            select_id: If provided, pick directly; else let user pick interactively\\\\n            interactive: If True, allow prompts for selection/confirmation.\\\\n        Returns summary dict for the cycle.\\\\n        \"\"\"\\\\n        try:\\\\n            # 1. Select Task\\\\n            open_tasks = self.backlog.list_items(status=\"open\")\\\\n            if not open_tasks:\\\\n                raise RuntimeError(\"No open tasks in backlog.\")\\\\n            if select_id:\\\\n                task = next((t for t in open_tasks if t[\"id\"] == select_id), None)\\\\n                if not task:\\\\n                    raise RuntimeError(f\"Task id \\\\\\'{select_id}\\\\\\' not found in open backlog.\")\\\\n            elif interactive:\\\\n                print(self._format_backlog(open_tasks))\\\\n                print(\"---\")\\\\n                idx = self._prompt_pick(len(open_tasks))\\\\n                task = open_tasks[idx]\\\\n            else:\\\\n                task = open_tasks[0]  # default: pick first open\\\\n\\\\n            print(f\"\\\\\\\\n[Selected task: {task[\\\\\\'id\\\\\\'][:8]}] {task.get(\\\\\\'title\\\\\\')}\\\\\\\\n\")\\\\n\\\\n            # 2. Build a patch from executor\\\\n            self.record.save(task, state=\"build_patch\")\\\\n            patch = self.executor.build_patch(task)\\\\n            self.record.save(task, state=\"patch_built\", extra={\"patch\": patch})\\\\n            print(\"--- Patch built ---\\\\\\\\n\", patch)\\\\n\\\\n            # 3. Reviewer initial check\\\\n            review1 = self.reviewer.review_patch(patch, context=task)\\\\n            self.record.save(task, state=\"patch_reviewed\", extra={\"review\": review1})\\\\n            print(\"--- Review 1 ---\")\\\\n            print(review1[\"comments\"])\\\\n            if not review1[\"pass\"]:\\\\n                print(f\"[X] Patch failed review, aborting (state recorded).\")\\\\n                return {\"success\": False, \"stage\": \"patch_review\", \"review\": review1}\\\\n\\\\n            # 4. Apply patch via shell/git (never apply if review failed)\\\\n            applied = self.shell.git_apply(patch)\\\\n            self.record.save(task, state=\"patch_applied\", extra={})\\\\n            print(\"[✔] Patch applied.\")\\\\n\\\\n            # 5. Run tests (pytest, whole repo or tests path)\\\\n            test_result = self.shell.run_pytest()\\\\n            self.record.save(task, state=\"pytest_run\", extra={\"pytest\": test_result})\\\\n            print(\"--- Pytest ---\")\\\\n            print(test_result[\"output\"])\\\\n            if not test_result[\"success\"]:\\\\n                print(f\"[X] Tests FAILED, aborting before commit (state recorded).\")\\\\n                return {\"success\": False, \"stage\": \"test\", \"test_result\": test_result}\\\\n\\\\n            # 6. Final review (optional): can trigger another review step here\\\\n            # (out-of-scope for MVP—extend as needed for LLM/human gating)\\\\n\\\\n            # 7. git commit, record commit SHA\\\\n            commit_msg = f\"[Cadence] {task[\\\\\\'id\\\\\\'][:8]} {task.get(\\\\\\'title\\\\\\', \\\\\\'\\\\\\')}\"\\\\n            sha = self.shell.git_commit(commit_msg)\\\\n            self.record.save(task, state=\"committed\", extra={\"commit_sha\": sha})\\\\n            print(f\"[✔] Committed as {sha}\")\\\\n\\\\n            # 8. Mark task done in backlog and archive\\\\n            self.backlog.update_item(task[\"id\"], {\"status\": \"done\"})\\\\n            self.backlog.archive_completed()\\\\n            self.record.save(task, state=\"archived\", extra={})\\\\n            print(\"[✔] Task marked done and archived.\")\\\\n\\\\n            return {\"success\": True, \"commit\": sha, \"task_id\": task[\"id\"]}\\\\n\\\\n        except Exception as ex:\\\\n            print(f\"[X] Cycle failed: {ex}\")\\\\n            return {\"success\": False, \"error\": str(ex)}\\\\n\\\\n    # ----- CLI entry point -----\\\\n    def cli_entry(self, command: str, **kwargs):\\\\n        \"\"\"\\\\n        Unified CLI dispatch. Supported commands: \\\\\\'backlog\\\\\\', \\\\\\'start\\\\\\', \\\\\\'evaluate\\\\\\', \\\\\\'done\\\\\\'\\\\n        \"\"\"\\\\n        try:\\\\n            if command in (\"backlog\", \"show\"):\\\\n                return self.show(status=kwargs.get(\"status\", \"open\"))\\\\n            elif command == \"start\":\\\\n                return self.run_task_cycle(select_id=kwargs.get(\"id\"))\\\\n            elif command == \"evaluate\":  # could hook for custom test/review pipeline\\\\n                return self.run_task_cycle(select_id=kwargs.get(\"id\"))\\\\n            elif command == \"done\":\\\\n                # Mark a task done and archive\\\\n                if \"id\" not in kwargs:\\\\n                    print(\"You must supply a task id for \\\\\\'done\\\\\\'.\")\\\\n                    return\\\\n                self.backlog.update_item(kwargs[\"id\"], {\"status\": \"done\"})\\\\n                self.backlog.archive_completed()\\\\n                print(f\"Task {kwargs[\\\\\\'id\\\\\\']} marked as done and archived.\")\\\\n                return\\\\n            else:\\\\n                print(f\"Unknown command: {command}\")\\\\n        except Exception as ex:\\\\n            print(f\"[X] CLI command \\\\\\'{command}\\\\\\' failed: {ex}\")\\\\n\\\\n    # ----- Notebook-friendly -----\\\\n    # Provide direct API for notebook use:\\\\n    # e.g., orch.show(), orch.run_task_cycle(), ...\\\\n\\\\n    # Helper for CLI interactive selection\\\\n    def _prompt_pick(self, n):\\\\n        while True:\\\\n            ans = input(f\"Select task [0-{n-1}]: \")\\\\n            try:\\\\n                ix = int(ans)\\\\n                if 0 <= ix < n:\\\\n                    return ix\\\\n            except Exception:\\\\n                pass\\\\n            print(\"Invalid. Try again.\")\\\\n\\\\n# Example main/dev use:\\\\nif __name__ == \"__main__\":\\\\n    # Example config; adjust as needed per environment\\\\n    CONFIG = dict(\\\\n        backlog_path=\"dev_backlog.json\",\\\\n        template_file=\"dev_templates.json\",\\\\n        src_root=\"cadence\",\\\\n        ruleset_file=None,\\\\n        repo_dir=\".\",\\\\n        record_file=\"dev_record.json\"\\\\n    )\\\\n    orch = DevOrchestrator(CONFIG)\\\\n    import argparse\\\\n    parser = argparse.ArgumentParser()\\\\n    parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\\\\n    parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\\\\n    args = parser.parse_args()\\\\n    orch.cli_entry(args.command or \"show\", id=args.id)\\', \\'cadence/dev/reviewer.py\\': \\'\\\\n# cadence/dev/reviewer.py\\\\n\\\\n\"\"\"\\\\nCadence TaskReviewer\\\\n-------------------\\\\nSingle Responsibility: Adjudicates patch/diff quality via rules/LLM/manual. Never applies code or diffs.\\\\nFuture extensible: can host local ruleset, shell out to LLM agent, or use human-in-the-loop.\\\\n\"\"\"\\\\n\\\\nimport os\\\\nimport json\\\\nfrom typing import Optional, Dict\\\\n\\\\nclass PatchReviewError(Exception):\\\\n    \"\"\"Raised if review input is malformed or review fails outright (e.g. ruleset not found/valid).\"\"\"\\\\n    pass\\\\n\\\\nclass TaskReviewer:\\\\n    def __init__(self, ruleset_file: str = None):\\\\n        \"\"\"\\\\n        Optionally specify path to ruleset file (JSON list of rules),\\\\n        or leave blank to use default built-in rules.\\\\n        \"\"\"\\\\n        self.ruleset_file = ruleset_file\\\\n        self.rules = self._load_ruleset(ruleset_file) if ruleset_file else self._default_ruleset()\\\\n\\\\n    def review_patch(self, patch: str, context: Optional[dict] = None) -> Dict:\\\\n        \"\"\"\\\\n        Review a diff/patch string (unapplied) and optional context (task, commit message, etc).\\\\n        Returns dict {\\\\\\'pass\\\\\\': bool, \\\\\\'comments\\\\\\': str}\\\\n        This uses static (offline) heuristics but can be swapped for agent/LLM in future.\\\\n        \"\"\"\\\\n        # Guard: Patch required\\\\n        if not patch or not isinstance(patch, str):\\\\n            return {\\\\\\'pass\\\\\\': False, \\\\\\'comments\\\\\\': \\\\\\'Patch missing or not a string.\\\\\\'}\\\\n\\\\n        # Apply rules in order. If any hard-fail, review fails.\\\\n        comments = []\\\\n        passed = True\\\\n\\\\n        for rule in self.rules:\\\\n            ok, msg = rule(patch, context)\\\\n            if not ok:\\\\n                passed = False\\\\n            if msg:\\\\n                comments.append(msg)\\\\n            if not ok:\\\\n                # For now, fail-hard (but comment all)\\\\n                break\\\\n\\\\n        return {\\\\\\'pass\\\\\\': passed, \\\\\\'comments\\\\\\': \"\\\\\\\\n\".join(comments).strip()}\\\\n\\\\n    def _default_ruleset(self):\\\\n        \"\"\"\\\\n        Returns a list of static rule functions: (patch, context) → (bool, str)\\\\n        \"\"\"\\\\n        def not_empty_rule(patch, _):\\\\n            if not patch.strip():\\\\n                return False, \"Patch is empty.\"\\\\n            return True, \"\"\\\\n        def startswith_rule(patch, _):\\\\n            if not patch.startswith((\"---\", \"diff \", \"@@ \")):\\\\n                return False, \"Patch does not appear to be a valid unified diff.\"\\\\n            return True, \"\"\\\\n        def contains_todo_rule(patch, _):\\\\n            if \"TODO\" in patch:\\\\n                return False, \"Patch contains \\\\\\'TODO\\\\\\'—code review must not introduce placeholders.\"\\\\n            return True, \"\"\\\\n\\\\n        # Optionally check for too-huge diffs, or forbidden patterns, via rules below.\\\\n        def size_limit_rule(patch, _):\\\\n            line_count = patch.count(\"\\\\\\\\n\")\\\\n            if line_count > 5000:  # Arbitrary large patch guard\\\\n                return False, f\"Patch too large for standard review ({line_count} lines).\"\\\\n            return True, \"\"\\\\n        return [\\\\n            not_empty_rule, \\\\n            startswith_rule,\\\\n            contains_todo_rule,\\\\n            size_limit_rule,\\\\n        ]\\\\n\\\\n    def _load_ruleset(self, path: str):\\\\n        \"\"\"\\\\n        Loads a simple external ruleset (for human/agent extension), e.g. as list of forbidden strings.\\\\n        For extensibility only; advanced policies/LLMs should be subclassed onto this interface.\\\\n        \"\"\"\\\\n        if not os.path.exists(path):\\\\n            raise PatchReviewError(f\"Ruleset file \\\\\\'{path}\\\\\\' not found.\")\\\\n        with open(path, \"r\", encoding=\"utf8\") as f:\\\\n            obj = json.load(f)\\\\n        # Expect a list of {\\\\\\'type\\\\\\':..., \\\\\\'pattern\\\\\\':..., ...} dicts for pattern rules\\\\n        rules = []\\\\n        def make_rule(ruleobj):\\\\n            typ = ruleobj.get(\\\\\\'type\\\\\\')\\\\n            pattern = ruleobj.get(\\\\\\'pattern\\\\\\')\\\\n            msg = ruleobj.get(\\\\\\'message\\\\\\', f\"Patch contains forbidden pattern: {pattern}\")\\\\n            if typ == \\\\\\'forbid\\\\\\':\\\\n                def _inner(patch, _):\\\\n                    if pattern in patch:\\\\n                        return False, msg\\\\n                    return True, \"\"\\\\n                return _inner\\\\n            elif typ == \\\\\\'require\\\\\\':\\\\n                def _inner(patch, _):\\\\n                    if pattern not in patch:\\\\n                        return False, msg\\\\n                    return True, \"\"\\\\n                return _inner\\\\n            else:\\\\n                # Ignore unknown rule types\\\\n                def _inner(patch, _):\\\\n                    return True, \"\"\\\\n                return _inner\\\\n        for ruleobj in obj:\\\\n            rules.append(make_rule(ruleobj))\\\\n        # Default rules always included\\\\n        return self._default_ruleset() + rules\\\\n\\\\n# Standalone/example/test run\\\\nif __name__ == \"__main__\":\\\\n    reviewer = TaskReviewer()\\\\n    # Good patch\\\\n    patch = \"\"\"--- sample.py\\\\n+++ sample.py\\\\n@@ -1 +1,2 @@\\\\n-print(\\\\\\'hello\\\\\\')\\\\n+print(\\\\\\'hello world\\\\\\')\\\\n\"\"\"\\\\n    result = reviewer.review_patch(patch)\\\\n    print(\"Result (should pass):\", result)\\\\n\\\\n    bad_patch = \"TODO: refactor\\\\\\\\n\"\\\\n    result = reviewer.review_patch(bad_patch)\\\\n    print(\"Result (should fail):\", result)\\', \\'cadence/dev/__init__.py\\': \\'\\\\n\\', \\'cadence/dev/generator.py\\': \\'\\\\n# cadence/dev/generator.py\\\\n\\\\n\"\"\"\\\\nCadence TaskGenerator\\\\n-------------------\\\\nSingle Responsibility: Propose/generate well-formed tasks, optionally from template or rules/LLM seed.\\\\nNever applies code or diffs. Future extensible to LLM/human agent.\\\\n\"\"\"\\\\n\\\\nimport os\\\\nimport json\\\\nimport uuid\\\\nfrom typing import List, Dict, Optional\\\\nimport datetime\\\\n\\\\nclass TaskTemplateError(Exception):\\\\n    \"\"\"Raised if template file is not valid or incomplete.\"\"\"\\\\n    pass\\\\n\\\\nREQUIRED_FIELDS = (\"title\", \"type\", \"status\", \"created_at\")\\\\n\\\\nclass TaskGenerator:\\\\n    def __init__(self, template_file: str = None):\\\\n        \"\"\"\\\\n        Optionally specify a JSON (or Markdown with JSON front-matter) template file.\\\\n        \"\"\"\\\\n        self.template_file = template_file\\\\n        self._template_cache = None\\\\n        if template_file:\\\\n            self._template_cache = self._load_template(template_file)\\\\n    \\\\n    def generate_tasks(self, mode: str = \"micro\", count: int = 1, human_prompt: Optional[str]=None) -> List[Dict]:\\\\n        \"\"\"\\\\n        Return a list of well-formed tasks. \\\\n        - mode: \"micro\", \"story\", \"epic\", etc.\\\\n        - count: number of tasks to generate\\\\n        - human_prompt: if provided, use as summary/title for each (e.g., \"Add new test\", for human CLI prompt workflow)\\\\n        If template_file is used, will fill in mode-related templates.\\\\n        \"\"\"\\\\n        tasks = []\\\\n        base_tpl = self._get_template_for_mode(mode)\\\\n        now = datetime.datetime.utcnow().isoformat()\\\\n        for i in range(count):\\\\n            task = dict(base_tpl)\\\\n            # Minimal fields: id, title, type, status, created_at\\\\n            task[\"id\"] = str(uuid.uuid4())\\\\n            task[\"type\"] = mode\\\\n            task.setdefault(\"status\", \"open\")\\\\n            task.setdefault(\"created_at\", now)\\\\n            if human_prompt:\\\\n                # Provide a default/barebones title/desc from human input\\\\n                task[\"title\"] = human_prompt if count == 1 else f\"{human_prompt} [{i+1}]\"\\\\n                task.setdefault(\"description\", human_prompt)\\\\n            else:\\\\n                # Fallback: title must be present; if not, use template/title from mode or \\\\\\'Untitled\\\\\\'\\\\n                task[\"title\"] = task.get(\"title\", f\"{mode.capitalize()} Task {i+1}\")\\\\n                task.setdefault(\"description\", \"\")\\\\n            self._validate_task(task)\\\\n            tasks.append(task)\\\\n        return tasks\\\\n\\\\n    def overwrite_tasks(self, new_tasks: List[Dict], output_path: Optional[str]=None) -> None:\\\\n        \"\"\"\\\\n        Replace all backlog tasks with given well-formed list (writes to output_path, else self.template_file).\\\\n        \"\"\"\\\\n        path = output_path or self.template_file\\\\n        if not path:\\\\n            raise TaskTemplateError(\"No output path specified to write tasks.\")\\\\n        with open(path, \"w\", encoding=\"utf8\") as f:\\\\n            json.dump([self._validate_task(t) for t in new_tasks], f, indent=2)\\\\n\\\\n    def _get_template_for_mode(self, mode: str) -> Dict:\\\\n        \"\"\"\\\\n        Get template for the given mode; falls back to default/minimal template.\\\\n        \"\"\"\\\\n        if self._template_cache and mode in self._template_cache:\\\\n            return dict(self._template_cache[mode])  # deep copy\\\\n        # Fallback: minimal template\\\\n        return {\\\\n            \"title\": \"\",\\\\n            \"type\": mode,\\\\n            \"status\": \"open\",\\\\n            \"created_at\": \"\",\\\\n            \"description\": \"\",\\\\n        }\\\\n\\\\n    def _load_template(self, path: str) -> Dict:\\\\n        \"\"\"\\\\n        Loads a JSON template file mapping mode→template-dict.\\\\n        If Markdown file with front-matter, parse the JSON front-matter.\\\\n        \"\"\"\\\\n        if not os.path.exists(path):\\\\n            raise TaskTemplateError(f\"Template file not found: {path}\")\\\\n        if path.endswith(\".md\"):\\\\n            with open(path, \"r\", encoding=\"utf8\") as f:\\\\n                lines = f.readlines()\\\\n            start, end = None, None\\\\n            for i, line in enumerate(lines):\\\\n                if line.strip() == \"```json\":\\\\n                    start = i + 1\\\\n                elif line.strip().startswith(\"```\") and start is not None and end is None:\\\\n                    end = i\\\\n                    break\\\\n            if start is not None and end is not None:\\\\n                json_str = \"\".join(lines[start:end])\\\\n                tpl = json.loads(json_str)\\\\n            else:\\\\n                raise TaskTemplateError(\"Markdown template missing ```json ... ``` block.\")\\\\n        else:\\\\n            with open(path, \"r\", encoding=\"utf8\") as f:\\\\n                tpl = json.load(f)\\\\n        if not isinstance(tpl, dict):\\\\n            raise TaskTemplateError(\"Task template must be a dict mapping mode->template.\")\\\\n        return tpl\\\\n\\\\n    def _validate_task(self, task: Dict) -> Dict:\\\\n        \"\"\"\\\\n        Ensures task has all required fields and correct types/formats.\\\\n        Throws TaskTemplateError if not.\\\\n        \"\"\"\\\\n        for field in REQUIRED_FIELDS:\\\\n            if field not in task or (field == \"title\" and not task[\"title\"].strip()):\\\\n                raise TaskTemplateError(f\"Task missing required field: \\\\\\'{field}\\\\\\'\")\\\\n        if not isinstance(task[\"type\"], str):\\\\n            raise TaskTemplateError(\"Task type must be str.\")\\\\n        if \"id\" in task and not isinstance(task[\"id\"], str):\\\\n            task[\"id\"] = str(task[\"id\"])\\\\n        # Optionally: check status value, etc.\\\\n        return task\\\\n\\\\n    # For future agentic/LLM/human input: accept strings, call LLM API, etc.\\\\n    # Extend here with agent hooks.\\\\n\\\\n# Standalone/test CLI example (not for production)\\\\nif __name__ == \"__main__\":\\\\n    # Example: generate 2 microtasks from default, print as JSON:\\\\n    g = TaskGenerator()\\\\n    tasks = g.generate_tasks(mode=\"micro\", count=2, human_prompt=\"Example user-initiated task\")\\\\n    print(json.dumps(tasks, indent=2))\\', \\'cadence/dev/backlog.py\\': \\'\\\\n# cadence/dev/backlog.py\\\\n\\\\n\"\"\"\\\\nCadence BacklogManager\\\\n---------------------\\\\nSingle Responsibility: CRUD on task backlog (no code/diffs). All file IO explicit, JSON-logged, and future agent-ready.\\\\n\"\"\"\\\\n\\\\nimport os\\\\nimport json\\\\nimport uuid\\\\nfrom typing import List, Dict, Optional\\\\n\\\\nclass BacklogEmptyError(Exception):\\\\n    \"\"\"Raised if attempting to pop or select from an empty backlog.\"\"\"\\\\n    pass\\\\n\\\\nclass TaskStructureError(Exception):\\\\n    \"\"\"Raised if a task dict doesn\\\\\\'t conform to required structure.\"\"\"\\\\n    pass\\\\n\\\\nclass TaskNotFoundError(Exception):\\\\n    \"\"\"Raised if a requested task_id is not in the backlog.\"\"\"\\\\n    pass\\\\n\\\\nREQUIRED_FIELDS = (\"id\", \"title\", \"type\", \"status\", \"created_at\")\\\\n\\\\nclass BacklogManager:\\\\n    \"\"\"\\\\n    Manages Cadence backlog: microtasks, stories, and epics.\\\\n    - All tasks are plain dicts with mandatory fields.\\\\n    - Underlying store is a JSON file [{...}, ...].\\\\n    \"\"\"\\\\n\\\\n    def __init__(self, backlog_path: str):\\\\n        self.path = backlog_path\\\\n        self._items: List[Dict] = []\\\\n        self.load()\\\\n\\\\n    def list_items(self, status: str = \"open\") -> List[Dict]:\\\\n        \"\"\"\\\\n        Return a list of tasks filtered by status.\\\\n        status: \"open\", \"in_progress\", \"done\", or \"all\"\\\\n        \"\"\"\\\\n        if status == \"all\":\\\\n            return list(self._items)\\\\n        return [item for item in self._items if item.get(\"status\", \"open\") == status]\\\\n\\\\n    def add_item(self, task: Dict) -> None:\\\\n        \"\"\"\\\\n        Add a new task to backlog. Enforce structure and unique id.\\\\n        \"\"\"\\\\n        task = self._normalize_task(task)\\\\n        if any(t[\"id\"] == task[\"id\"] for t in self._items):\\\\n            raise TaskStructureError(f\"Duplicate task id: {task[\\\\\\'id\\\\\\']}\")\\\\n        self._items.append(task)\\\\n        self.save()\\\\n\\\\n    def remove_item(self, task_id: str) -> None:\\\\n        \"\"\"\\\\n        Mark a task as archived (status = \\\\\\'archived\\\\\\').\\\\n        \"\"\"\\\\n        idx = self._task_index(task_id)\\\\n        self._items[idx][\"status\"] = \"archived\"\\\\n        self.save()\\\\n\\\\n    def archive_completed(self) -> None:\\\\n        \"\"\"\\\\n        Mark all tasks with status \\\\\\'done\\\\\\' as \\\\\\'archived\\\\\\'.\\\\n        \"\"\"\\\\n        n = 0\\\\n        for item in self._items:\\\\n            if item.get(\"status\") == \"done\":\\\\n                item[\"status\"] = \"archived\"\\\\n                n += 1\\\\n        if n:\\\\n            self.save()\\\\n\\\\n    def save(self) -> None:\\\\n        \"\"\"Persist backlog state to self.path as JSON (UTF-8, indent).\"\"\"\\\\n        tmp_path = self.path + \".tmp\"\\\\n        with open(tmp_path, \"w\", encoding=\"utf8\") as f:\\\\n            json.dump(self._items, f, indent=2)\\\\n        os.replace(tmp_path, self.path)\\\\n\\\\n    def load(self) -> None:\\\\n        \"\"\"\\\\n        Reload backlog state from file. If the file does not exist, starts empty.\\\\n        \"\"\"\\\\n        if not os.path.exists(self.path):\\\\n            self._items = []\\\\n            return\\\\n        with open(self.path, \"r\", encoding=\"utf8\") as f:\\\\n            data = json.load(f)\\\\n            if not isinstance(data, list):\\\\n                raise ValueError(\"Backlog JSON must be a list of tasks\")\\\\n            self._items = [self._normalize_task(t) for t in data]\\\\n\\\\n    def _normalize_task(self, task: Dict) -> Dict:\\\\n        \"\"\"\\\\n        Ensure the dict has all required fields, fill missing, return new dict.\\\\n        \"\"\"\\\\n        t = dict(task)  # copy\\\\n        for field in REQUIRED_FIELDS:\\\\n            if field not in t:\\\\n                if field == \"id\":\\\\n                    t[\"id\"] = str(uuid.uuid4())\\\\n                elif field == \"created_at\":\\\\n                    import datetime\\\\n                    t[\"created_at\"] = datetime.datetime.utcnow().isoformat()\\\\n                elif field == \"status\":\\\\n                    t[\"status\"] = \"open\"\\\\n                elif field == \"type\":\\\\n                    t[\"type\"] = \"micro\"\\\\n                else:\\\\n                    raise TaskStructureError(f\"Missing required field: {field}\")\\\\n        # Sanity check: no harmful keys\\\\n        if not isinstance(t[\"id\"], str):\\\\n            t[\"id\"] = str(t[\"id\"])\\\\n        return t\\\\n\\\\n    def _task_index(self, task_id: str) -> int:\\\\n        \"\"\"\\\\n        Internal: find list index of task by id or raise.\\\\n        \"\"\"\\\\n        for ix, t in enumerate(self._items):\\\\n            if t[\"id\"] == task_id:\\\\n                return ix\\\\n        raise TaskNotFoundError(f\"No task found with id={task_id}\")\\\\n\\\\n    def get_item(self, task_id: str) -> Dict:\\\\n        \"\"\"Retrieve a task by id.\"\"\"\\\\n        idx = self._task_index(task_id)\\\\n        return self._items[idx]\\\\n\\\\n    def update_item(self, task_id: str, updates: Dict) -> None:\\\\n        \"\"\"\\\\n        Update arbitrary fields of a task (e.g. assign, progress, edit).\\\\n        \"\"\"\\\\n        idx = self._task_index(task_id)\\\\n        self._items[idx].update(updates)\\\\n        self.save()\\\\n\\\\n    def export(self) -> List[Dict]:\\\\n        \"\"\"\\\\n        Return a (deep) copy of all backlog items.\\\\n        \"\"\"\\\\n        import copy\\\\n        return copy.deepcopy(self._items)\\\\n\\\\n    # Optional: friendly CLI/str output\\\\n    def __str__(self) -> str:\\\\n        from tabulate import tabulate\\\\n        if not self._items:\\\\n            return \"(Backlog empty)\"\\\\n        rows = [\\\\n            (t[\"id\"][:8], t[\"title\"], t[\"type\"], t.get(\"status\", \"open\"), t.get(\"created_at\", \"\"))\\\\n            for t in self._items if t.get(\"status\") != \"archived\"\\\\n        ]\\\\n        headers = [\"id\", \"title\", \"type\", \"status\", \"created\"]\\\\n        return tabulate(rows, headers, tablefmt=\"github\")\\\\n\\\\n# For direct module test/dev, NOT in prod code.\\\\nif __name__ == \"__main__\":\\\\n    # Example usage\\\\n    mgr = BacklogManager(\"dev_backlog.json\")\\\\n    print(mgr)\\\\n    # To add: mgr.add_item({\"title\": \"Test microtask\", \"type\": \"micro\"})\\', \\'cadence/agents/sidekick.py\\': \\'# ./cadence/agents/sidekick.py\\\\n\"\"\"\\\\nPersona agent that *delegates* to a ReasoningAgent but presents a\\\\nhuman-centric mentor/advisor interface.\\\\n\"\"\"\\\\nfrom __future__ import annotations\\\\n\\\\nimport json\\\\nfrom pathlib import Path\\\\n\\\\nfrom .profile import AgentProfile, REASONING_PROFILE\\\\nfrom .reasoning import ReasoningAgent\\\\n\\\\n\\\\n_SIDEKICK_PROMPT = \"\"\"\\\\nYou are an AI-enhanced co-developer and mentor. Your primary goal is to\\\\nextract the most creative, high-leverage ideas from the human user and\\\\ntransform them into actionable improvements for the Cadence platform.\\\\nAvoid tactical implementation details unless asked; focus on vision,\\\\narchitecture, and pragmatic next steps.\\\\n\"\"\"\\\\n\\\\n\\\\nclass Sidekick:\\\\n    \"\"\"\\\\n    Thin wrapper: exposes `run_interaction` but delegates work to an\\\\n    internal ReasoningAgent instance configured with a custom prompt.\\\\n    \"\"\"\\\\n\\\\n    def __init__(self):\\\\n        profile = AgentProfile(\\\\n            name=\"sidekick\",\\\\n            role=\"advisor\",\\\\n            model=REASONING_PROFILE.model,\\\\n            context_limit=REASONING_PROFILE.context_limit,\\\\n            review_policy=REASONING_PROFILE.review_policy,\\\\n            default_system_prompt=REASONING_PROFILE.default_system_prompt,\\\\n            extra=REASONING_PROFILE.extra.copy() if REASONING_PROFILE.extra else {},\\\\n        )\\\\n        self._agent = ReasoningAgent(profile=profile, system_prompt=_SIDEKICK_PROMPT)\\\\n        self._inject_seed_context()\\\\n\\\\n    # ------------------------------------------------------------------ #\\\\n    # Public façade\\\\n    # ------------------------------------------------------------------ #\\\\n    def run_interaction(self, user_input: str, **kwargs) -> str:\\\\n        return self._agent.run_interaction(user_input, **kwargs)\\\\n\\\\n    async def async_run_interaction(self, user_input: str, **kwargs) -> str:\\\\n        return await self._agent.async_run_interaction(user_input, **kwargs)\\\\n\\\\n    # ------------------------------------------------------------------ #\\\\n    # Private helpers\\\\n    # ------------------------------------------------------------------ #\\\\n    def _inject_seed_context(self):\\\\n        docs = self._agent.gather_codebase_context(\\\\n            root=(\"docs\",),\\\\n            ext=(\".md\", \".mermaid\", \".json\"),\\\\n        )\\\\n\\\\n        modules_path = Path(\"agent_context/module_contexts.json\")\\\\n        modules = {}\\\\n        if modules_path.exists():\\\\n            modules = json.loads(modules_path.read_text())\\\\n\\\\n        self._agent.append_message(\\\\n            \"user\",\\\\n            f\"DOCS:\\\\\\\\n{docs}\\\\\\\\n---\\\\\\\\nMODULE_CONTEXTS:\\\\\\\\n{json.dumps(modules)[:10_000]}\",\\\\n        )\\', \\'cadence/agents/base.py\\': \\'# ./cadence/agents/base.py\\\\nfrom __future__ import annotations\\\\n\\\\nfrom typing import List, Dict, Any, Optional, Tuple\\\\nfrom pathlib import Path\\\\n\\\\nfrom cadence.llm.client import LLMClient, get_default_client\\\\nfrom cadence.context.provider import ContextProvider, SnapshotContextProvider\\\\nfrom .profile import AgentProfile\\\\n\\\\n\\\\nclass BaseAgent:\\\\n    \"\"\"\\\\n    The one true superclass for *all* Cadence agents.\\\\n\\\\n    An agent = (profile) + (conversation state) + (LLM client) [+ optional helpers]\\\\n\\\\n    Subclasses SHOULD NOT hard-code models; they inherit that from the supplied\\\\n    `AgentProfile`.  Core agents (Reasoning / Execution / Efficiency) simply\\\\n    pass the canonical profile; personas may inject a custom one.\\\\n    \"\"\"\\\\n\\\\n    def __init__(\\\\n        self,\\\\n        profile: AgentProfile,\\\\n        *,\\\\n        llm_client: Optional[LLMClient] = None,\\\\n        system_prompt: Optional[str] = None,\\\\n        context_provider: Optional[ContextProvider] = None,\\\\n    ):\\\\n        self.profile = profile\\\\n        self.llm_client = llm_client or get_default_client()\\\\n        self.system_prompt = system_prompt or profile.default_system_prompt\\\\n        self.context_provider = context_provider or SnapshotContextProvider()\\\\n        self.messages: List[Dict[str, Any]] = []\\\\n        self.reset_context()\\\\n\\\\n    # --------------------------------------------------------------------- #\\\\n    # Conversation helpers\\\\n    # --------------------------------------------------------------------- #\\\\n    def reset_context(self, system_prompt: Optional[str] = None):\\\\n        \"\"\"Clear history and (re)set the system prompt.\"\"\"\\\\n        self.messages = []\\\\n        sys_prompt = system_prompt or self.system_prompt\\\\n        if sys_prompt:\\\\n            self.append_message(\"system\", sys_prompt)\\\\n\\\\n    def append_message(self, role: str, content: str):\\\\n        self.messages.append({\"role\": role, \"content\": content})\\\\n\\\\n    # --------------------------------------------------------------------- #\\\\n    # LLM calls\\\\n    # --------------------------------------------------------------------- #\\\\n    def run_interaction(self, user_input: str, **llm_kwargs) -> str:\\\\n        self.append_message(\"user\", user_input)\\\\n        response = self.llm_client.call(\\\\n            self.messages,\\\\n            model=self.profile.model,\\\\n            system_prompt=None,  # already injected\\\\n            **llm_kwargs,\\\\n        )\\\\n        self.append_message(\"assistant\", response)\\\\n        return response\\\\n\\\\n    async def async_run_interaction(self, user_input: str, **llm_kwargs) -> str:\\\\n        self.append_message(\"user\", user_input)\\\\n        response = await self.llm_client.acall(\\\\n            self.messages,\\\\n            model=self.profile.model,\\\\n            system_prompt=None,\\\\n            **llm_kwargs,\\\\n        )\\\\n        self.append_message(\"assistant\", response)\\\\n        return response\\\\n\\\\n    # --------------------------------------------------------------------- #\\\\n    # Persistence\\\\n    # --------------------------------------------------------------------- #\\\\n    def save_history(self, path: str):\\\\n        import json\\\\n        Path(path).write_text(json.dumps(self.messages, indent=2, ensure_ascii=False))\\\\n\\\\n    def load_history(self, path: str):\\\\n        import json\\\\n        self.messages = json.loads(Path(path).read_text())\\\\n\\\\n    # --------------------------------------------------------------------- #\\\\n    # Context helpers\\\\n    # --------------------------------------------------------------------- #\\\\n    def gather_codebase_context(\\\\n        self,\\\\n        root: Tuple[str, ...] = (\"cadence\", \"docs\"),\\\\n        ext: Tuple[str, ...] = (\".py\", \".md\", \".json\", \".mermaid\"),\\\\n        **kwargs,\\\\n    ) -> str:\\\\n        \"\"\"Return repo/docs snapshot via the injected ContextProvider.\"\"\"\\\\n        return self.context_provider.get_context(*(Path(r) for r in root), exts=ext, **kwargs)\\\\n\\', \\'cadence/agents/efficiency.py\\': \\'# ./cadence/agents/efficiency.py\\\\nfrom __future__ import annotations\\\\n\\\\nfrom .base import BaseAgent\\\\nfrom .profile import EFFICIENCY_PROFILE, AgentProfile\\\\n\\\\n\\\\nclass EfficiencyAgent(BaseAgent):\\\\n    \"\"\"\\\\n    Final class: fast, low-cost linting & summarisation.\\\\n    \"\"\"\\\\n\\\\n    def __init__(self, profile: AgentProfile = EFFICIENCY_PROFILE, **kwargs):\\\\n        super().__init__(profile, **kwargs)\\', \\'cadence/agents/reasoning.py\\': \\'# ./cadence/agents/reasoning.py\\\\nfrom __future__ import annotations\\\\n\\\\nfrom .base import BaseAgent\\\\nfrom .profile import REASONING_PROFILE, AgentProfile\\\\n\\\\n\\\\nclass ReasoningAgent(BaseAgent):\\\\n    \"\"\"\\\\n    Final class: provides deep, chain-of-thought reasoning and architectural review.\\\\n    \"\"\"\\\\n\\\\n    def __init__(self, profile: AgentProfile = REASONING_PROFILE, **kwargs):\\\\n        super().__init__(profile, **kwargs)\\\\n\\\\n    # Automatically inject a fresh code snapshot on each reset\\\\n    def reset_context(self, system_prompt: str | None = None):\\\\n        super().reset_context(system_prompt)\\\\n        docs = self.gather_codebase_context(\\\\n            root=(\"docs\",),\\\\n            ext=(\".md\", \".mermaid\", \".json\"),\\\\n        )\\\\n        self.append_message(\"user\", f\"REFERENCE_DOCUMENTS:\\\\\\\\n{docs}\\\\\\\\n---\\\\\\\\nYou are cleared for deep reasoning.\")\\', \\'cadence/agents/profile.py\\': \\'# ./cadence/agents/profile.py\\\\nfrom dataclasses import dataclass, field\\\\nfrom typing import Dict, Any\\\\n\\\\n\\\\n@dataclass(frozen=True, slots=True)\\\\nclass AgentProfile:\\\\n    \"\"\"\\\\n    Immutable definition of an agent’s operational contract.\\\\n\\\\n    Nothing here executes code; it is pure data that can be validated,\\\\n    serialised, or inspected by the Meta-agent and CI tooling.\\\\n    \"\"\"\\\\n    name: str\\\\n    role: str\\\\n    model: str\\\\n    context_limit: int\\\\n    review_policy: str = \"\"\\\\n    default_system_prompt: str = \"\"\\\\n    extra: Dict[str, Any] = field(default_factory=dict)\\\\n\\\\n\\\\n# --------------------------------------------------------------------------- #\\\\n# Canonical profiles – these are the ONLY ones that Core Agents will default to\\\\n# --------------------------------------------------------------------------- #\\\\nREASONING_PROFILE = AgentProfile(\\\\n    name=\"reasoning\",\\\\n    role=\"plan-review\",\\\\n    model=\"o3-2025-04-16\",\\\\n    context_limit=200_000,\\\\n    review_policy=\"Cannot commit code; must review Execution diff\",\\\\n)\\\\n\\\\nEXECUTION_PROFILE = AgentProfile(\\\\n    name=\"execution\",\\\\n    role=\"implement\",\\\\n    model=\"gpt-4.1\",\\\\n    context_limit=1_000_000,\\\\n    review_policy=\"Needs review by Reasoning or Efficiency\",\\\\n)\\\\n\\\\nEFFICIENCY_PROFILE = AgentProfile(\\\\n    name=\"efficiency\",\\\\n    role=\"lint-summarise\",\\\\n    model=\"o4-mini\",\\\\n    context_limit=200_000,\\\\n    review_policy=\"Reviews Execution unless diff is non-code\",\\\\n)\\\\n\\\\n# Convenience lookup\\\\nBUILTIN_PROFILES = {\\\\n    \"reasoning\": REASONING_PROFILE,\\\\n    \"execution\": EXECUTION_PROFILE,\\\\n    \"efficiency\": EFFICIENCY_PROFILE,\\\\n}\\', \\'cadence/agents/__init__.py\\': \\'\\\\n\\', \\'cadence/agents/registry.py\\': \\'# ./cadence/agents/registry.py\\\\n\"\"\"\\\\nSingle place to obtain a Core Agent or Profile.\\\\n\\\\nAvoids hard-coding classes throughout the codebase.\\\\n\"\"\"\\\\n\\\\nfrom typing import Type\\\\n\\\\nfrom .reasoning import ReasoningAgent\\\\nfrom .execution import ExecutionAgent\\\\nfrom .efficiency import EfficiencyAgent\\\\nfrom .profile import BUILTIN_PROFILES, AgentProfile\\\\n\\\\n_CORE_AGENTS: dict[str, Type] = {\\\\n    \"reasoning\": ReasoningAgent,\\\\n    \"execution\": ExecutionAgent,\\\\n    \"efficiency\": EfficiencyAgent,\\\\n}\\\\n\\\\n\\\\ndef get_agent(agent_type: str, **kwargs):\\\\n    \"\"\"\\\\n    Instantiate a Core Agent by `agent_type`.\\\\n\\\\n    Example:\\\\n        agent = get_agent(\"execution\")\\\\n    \"\"\"\\\\n    if agent_type not in _CORE_AGENTS:\\\\n        raise ValueError(f\"Unknown agent_type \\\\\\'{agent_type}\\\\\\'. Valid: {list(_CORE_AGENTS)}\")\\\\n    return _CORE_AGENTS[agent_type](**kwargs)\\\\n\\\\n\\\\ndef get_profile(profile_name: str) -> AgentProfile:\\\\n    if profile_name not in BUILTIN_PROFILES:\\\\n        raise ValueError(f\"Unknown profile \\\\\\'{profile_name}\\\\\\'. Valid: {list(BUILTIN_PROFILES)}\")\\\\n    return BUILTIN_PROFILES[profile_name]\\', \\'cadence/agents/execution.py\\': \\'# ./cadence/agents/execution.py\\\\nfrom __future__ import annotations\\\\n\\\\nfrom .base import BaseAgent\\\\nfrom .profile import EXECUTION_PROFILE, AgentProfile\\\\n\\\\n\\\\nclass ExecutionAgent(BaseAgent):\\\\n    \"\"\"\\\\n    Final class: generates or refactors significant portions of the codebase.\\\\n    \"\"\"\\\\n\\\\n    def __init__(self, profile: AgentProfile = EXECUTION_PROFILE, **kwargs):\\\\n        super().__init__(profile, **kwargs)\\', \\'cadence/llm/client.py\\': \\'\\\\nimport os\\\\nimport logging\\\\nimport asyncio\\\\nfrom typing import List, Dict, Any, Optional, cast\\\\nfrom openai import AsyncOpenAI, OpenAI\\\\nfrom openai.types.chat import ChatCompletionMessageParam\\\\nfrom dotenv import load_dotenv\\\\n\\\\n# One-time load\\\\nload_dotenv()\\\\n\\\\n# Set up logger\\\\nlogger = logging.getLogger(\"cadence.llm.client\")\\\\nif not logger.handlers:\\\\n    handler = logging.StreamHandler()\\\\n    handler.setFormatter(logging.Formatter(\"[%(asctime)s] %(levelname)s %(message)s\"))\\\\n    logger.addHandler(handler)\\\\nlogger.setLevel(logging.INFO)\\\\n\\\\n# Global default model configs\\\\n_DEFAULT_MODELS = {\\\\n    \"reasoning\": \"o3-2025-04-16\",\\\\n    \"execution\": \"gpt-4.1\",\\\\n    \"efficiency\": \"o4-mini\"\\\\n}\\\\n\\\\ndef get_env(key: str, required=True, default=None):\\\\n    val = os.getenv(key)\\\\n    if not val and required:\\\\n        raise RuntimeError(f\"Environment variable {key} not set.\")\\\\n    return val or default\\\\n\\\\n# Centralized sync/async LLM client\\\\nclass LLMClient:\\\\n    def __init__(\\\\n        self,\\\\n        api_key: Optional[str] = None,\\\\n        api_base: Optional[str] = None,\\\\n        api_version: Optional[str] = None,\\\\n        default_model: Optional[str] = None,\\\\n    ):\\\\n        self.api_key = api_key or get_env(\\\\\\'OPENAI_API_KEY\\\\\\')\\\\n        self.api_base = api_base or os.getenv(\\\\\\'OPENAI_API_BASE\\\\\\', None)\\\\n        self.api_version = api_version or os.getenv(\\\\\\'OPENAI_API_VERSION\\\\\\', None)\\\\n        self.default_model = default_model or _DEFAULT_MODELS[\"execution\"]\\\\n\\\\n        # Sync and Async clients\\\\n        self._async_client = AsyncOpenAI(api_key=self.api_key, base_url=self.api_base)\\\\n        self._sync_client = OpenAI(api_key=self.api_key, base_url=self.api_base)\\\\n\\\\n    def _resolve_model(self, model: Optional[str], agent_type: Optional[str]):\\\\n        if model:\\\\n            return model\\\\n        if agent_type and agent_type in _DEFAULT_MODELS:\\\\n            return _DEFAULT_MODELS[agent_type]\\\\n        return self.default_model\\\\n\\\\n    def call(\\\\n        self,\\\\n        messages: List[Dict[str, Any]],\\\\n        model: Optional[str] = None,\\\\n        agent_type: Optional[str] = None,\\\\n        system_prompt: Optional[str] = None,\\\\n        max_tokens: Optional[int] = None,\\\\n        **kwargs\\\\n    ) -> str:\\\\n        used_model = self._resolve_model(model, agent_type)\\\\n        msgs = messages.copy()\\\\n        if system_prompt and not any(m.get(\"role\") == \"system\" for m in msgs):\\\\n            msgs.insert(0, {\"role\": \"system\", \"content\": system_prompt})\\\\n\\\\n        logger.info(f\"LLM sync call: model={used_model}, msgs_len={len(msgs)}\")\\\\n        response = self._sync_client.chat.completions.create(  # type: ignore[arg-type]\\\\n            model=used_model,\\\\n            messages=cast(List[ChatCompletionMessageParam], msgs),\\\\n            # max_tokens=max_tokens,\\\\n            **kwargs\\\\n        )\\\\n        content = (response.choices[0].message.content or \"\").strip()\\\\n        logger.debug(f\"LLM response: {content[:120]}...\")\\\\n        return content\\\\n\\\\n    async def acall(\\\\n        self,\\\\n        messages: List[Dict[str, Any]],\\\\n        model: Optional[str] = None,\\\\n        agent_type: Optional[str] = None,\\\\n        system_prompt: Optional[str] = None,\\\\n        max_tokens: Optional[int] = None,\\\\n        **kwargs\\\\n    ) -> str:\\\\n        used_model = self._resolve_model(model, agent_type)\\\\n        msgs = messages.copy()\\\\n        if system_prompt and not any(m.get(\"role\") == \"system\" for m in msgs):\\\\n            msgs.insert(0, {\"role\": \"system\", \"content\": system_prompt})\\\\n\\\\n        logger.info(f\"LLM async call: model={used_model}, msgs_len={len(msgs)}\")\\\\n        response = await self._async_client.chat.completions.create(  # type: ignore[arg-type]\\\\n            model=used_model,\\\\n            messages=cast(List[ChatCompletionMessageParam], msgs),\\\\n            max_tokens=max_tokens,\\\\n            **kwargs\\\\n        )\\\\n        content = (response.choices[0].message.content or \"\").strip()\\\\n        logger.debug(f\"LLM response: {content[:120]}...\")\\\\n        return content\\\\n\\\\n# Provide a default client getter for agents\\\\ndef get_default_client() -> LLMClient:\\\\n    return _DEFAULT_CLIENT\\\\n\\\\n_DEFAULT_CLIENT = LLMClient()\\\\n\\', \\'cadence/llm/__init__.py\\': \\'\\\\n\\'}\\n=================\\nBacklog:\\n{\\'MVP_CRITICAL\\': {\\'EPICS\\': [{\\'id\\': \\'E-MVP-1\\', \\'title\\': \\'Agentic Core Loop Proof\\', \\'why\\': \\'Demonstrate an LLM-driven red→green patch cycle with zero human steps.\\', \\'stories\\': [\\'S-MVP-1.1\\', \\'S-MVP-1.2\\', \\'S-MVP-1.3\\', \\'S-MVP-1.4\\']}, {\\'id\\': \\'E-MVP-2\\', \\'title\\': \\'Risk Boundary & Circuit Breaker\\', \\'why\\': \\'Guarantee safety while agents learn (no shell, no disk writes).\\', \\'stories\\': [\\'S-MVP-2.1\\']}, {\\'id\\': \\'E-DEV-1\\', \\'title\\': \\'VS Code Sidekick Extension\\', \\'why\\': \\'First-class developer UX; chat, code-aware actions, live dashboards.\\', \\'stories\\': [\\'S-DEV-1.0\\', \\'S-DEV-1.1\\', \\'S-DEV-1.2\\', \\'S-DEV-1.3\\', \\'S-DEV-1.4\\']}], \\'STORIES\\': [{\\'id\\': \\'S-MVP-1.1\\', \\'epic\\': \\'E-MVP-1\\', \\'title\\': \\'Seed Toy Defect & Failing Test\\', \\'owner\\': \\'HYBRID\\', \\'tasks\\': [\\'T-MVP-1.1.1\\', \\'T-MVP-1.1.2\\']}, {\\'id\\': \\'S-MVP-1.2\\', \\'epic\\': \\'E-MVP-1\\', \\'title\\': \\'In-Process Orchestrator Skeleton\\', \\'owner\\': \\'HYBRID\\', \\'tasks\\': [\\'T-MVP-1.2.1\\', \\'T-MVP-1.2.2\\']}, {\\'id\\': \\'S-MVP-1.3\\', \\'epic\\': \\'E-MVP-1\\', \\'title\\': \\'LLM Patch Generator v0\\', \\'owner\\': \\'AGENT\\', \\'tasks\\': [\\'T-MVP-1.3.1\\']}, {\\'id\\': \\'S-MVP-1.4\\', \\'epic\\': \\'E-MVP-1\\', \\'title\\': \\'Autonomous Retry Loop & Success Detect\\', \\'owner\\': \\'AGENT\\', \\'tasks\\': [\\'T-MVP-1.4.1\\', \\'T-MVP-1.4.2\\']}, {\\'id\\': \\'S-MVP-2.1\\', \\'epic\\': \\'E-MVP-2\\', \\'title\\': \\'Circuit Breaker & Rollback Policy\\', \\'owner\\': \\'HYBRID\\', \\'tasks\\': [\\'T-MVP-2.1.1\\', \\'T-MVP-2.1.2\\']}, {\\'id\\': \\'S-DEV-1.0\\', \\'epic\\': \\'E-DEV-1\\', \\'title\\': \\'Phase-0 Hello-World Chat Webview\\', \\'owner\\': \\'HYBRID\\', \\'tasks\\': [\\'T-DEV-1.0.1\\', \\'T-DEV-1.0.2\\', \\'T-DEV-1.0.3\\']}, {\\'id\\': \\'S-DEV-1.1\\', \\'epic\\': \\'E-DEV-1\\', \\'title\\': \\'Phase-1 CodeLens & Selection Commands\\', \\'owner\\': \\'HYBRID\\', \\'tasks\\': [\\'T-DEV-1.1.1\\', \\'T-DEV-1.1.2\\']}, {\\'id\\': \\'S-DEV-1.2\\', \\'epic\\': \\'E-DEV-1\\', \\'title\\': \\'Phase-2 Backlog Tree View & Create-Task\\', \\'owner\\': \\'HYBRID\\', \\'tasks\\': [\\'T-DEV-1.2.1\\', \\'T-DEV-1.2.2\\']}, {\\'id\\': \\'S-DEV-1.3\\', \\'epic\\': \\'E-DEV-1\\', \\'title\\': \\'Phase-3 Patch Generation & Review Decorations\\', \\'owner\\': \\'HYBRID\\', \\'tasks\\': [\\'T-DEV-1.3.1\\', \\'T-DEV-1.3.2\\']}, {\\'id\\': \\'S-DEV-1.4\\', \\'epic\\': \\'E-DEV-1\\', \\'title\\': \\'Phase-4 Orchestrator Dashboard Webview\\', \\'owner\\': \\'HYBRID\\', \\'tasks\\': [\\'T-DEV-1.4.1\\']}], \\'TASKS\\': [{\\'id\\': \\'T-MVP-1.1.1\\', \\'story\\': \\'S-MVP-1.1\\', \\'desc\\': \\'Create utils/add.py that incorrectly returns (x - 1 + y).\\', \\'autonomous\\': False, \\'deps\\': []}, {\\'id\\': \\'T-MVP-1.1.2\\', \\'story\\': \\'S-MVP-1.1\\', \\'desc\\': \\'Add tests/test_add.py expecting add(2,3)==5 (should FAIL).\\', \\'autonomous\\': False, \\'deps\\': [\\'T-MVP-1.1.1\\']}, {\\'id\\': \\'T-MVP-1.2.1\\', \\'story\\': \\'S-MVP-1.2\\', \\'desc\\': \\'Build mvp_loop.py that runs pytest, calls TaskAgent, applies diff in-memory.\\', \\'autonomous\\': True, \\'deps\\': []}, {\\'id\\': \\'T-MVP-1.2.2\\', \\'story\\': \\'S-MVP-1.2\\', \\'desc\\': \\'Ensure mvp_loop has zero disk/subprocess side-effects; print JSON summary.\\', \\'autonomous\\': True, \\'deps\\': [\\'T-MVP-1.2.1\\']}, {\\'id\\': \\'T-MVP-1.3.1\\', \\'story\\': \\'S-MVP-1.3\\', \\'desc\\': \\'Implement TaskAgent.prompt() few-shot + TaskExecutor.build_patch.\\', \\'autonomous\\': True, \\'deps\\': [\\'T-MVP-1.2.2\\']}, {\\'id\\': \\'T-MVP-1.4.1\\', \\'story\\': \\'S-MVP-1.4\\', \\'desc\\': \\'Retry loop up to 3; send previous diff & error back to TaskAgent.\\', \\'autonomous\\': True, \\'deps\\': [\\'T-MVP-1.3.1\\']}, {\\'id\\': \\'T-MVP-1.4.2\\', \\'story\\': \\'S-MVP-1.4\\', \\'desc\\': \\'Exit SUCCESS on first green; else exit(1) after third failure.\\', \\'autonomous\\': True, \\'deps\\': [\\'T-MVP-1.4.1\\']}, {\\'id\\': \\'T-MVP-2.1.1\\', \\'story\\': \\'S-MVP-2.1\\', \\'desc\\': \\'Wrap pytest invocation in try/except; revert in-memory patch on crash.\\', \\'autonomous\\': True, \\'deps\\': [\\'T-MVP-1.2.2\\']}, {\\'id\\': \\'T-MVP-2.1.2\\', \\'story\\': \\'S-MVP-2.1\\', \\'desc\\': \\'Abort loop & require human after 3 consecutive failed attempts.\\', \\'autonomous\\': True, \\'deps\\': [\\'T-MVP-2.1.1\\']}, {\\'id\\': \\'T-DEV-1.0.1\\', \\'story\\': \\'S-DEV-1.0\\', \\'desc\\': \\'Scaffold VS Code extension with `yo code`. Register command: Sidekick:Open Chat.\\', \\'autonomous\\': False, \\'deps\\': []}, {\\'id\\': \\'T-DEV-1.0.2\\', \\'story\\': \\'S-DEV-1.0\\', \\'desc\\': \\'Implement WebSocket JSON-RPC bridge `tools/ext_bridge.py` exposing /chat endpoint.\\', \\'autonomous\\': True, \\'deps\\': [\\'T-DEV-1.0.1\\']}, {\\'id\\': \\'T-DEV-1.0.3\\', \\'story\\': \\'S-DEV-1.0\\', \\'desc\\': \\'Create Chat Webview that streams messages; status-bar ‘Sidekick • o3’.\\', \\'autonomous\\': False, \\'deps\\': [\\'T-DEV-1.0.2\\']}, {\\'id\\': \\'T-DEV-1.1.1\\', \\'story\\': \\'S-DEV-1.1\\', \\'desc\\': \\'Add CodeLens ‘Ask Sidekick’ at top of .py files; send file text + cursor pos.\\', \\'autonomous\\': False, \\'deps\\': [\\'T-DEV-1.0.3\\', \\'T-MVP-1.2.2\\']}, {\\'id\\': \\'T-DEV-1.1.2\\', \\'story\\': \\'S-DEV-1.1\\', \\'desc\\': \\'Register selection context-menu commands: Explain / Refactor / Create Test.\\', \\'autonomous\\': False, \\'deps\\': [\\'T-DEV-1.1.1\\']}, {\\'id\\': \\'T-DEV-1.2.1\\', \\'story\\': \\'S-DEV-1.2\\', \\'desc\\': \\'Implement Backlog TreeDataProvider reading via BacklogManager JSON.\\', \\'autonomous\\': False, \\'deps\\': [\\'T-DEV-1.0.3\\']}, {\\'id\\': \\'T-DEV-1.2.2\\', \\'story\\': \\'S-DEV-1.2\\', \\'desc\\': \\'Command ‘Create micro-task from chat’ → append to backlog file.\\', \\'autonomous\\': False, \\'deps\\': [\\'T-DEV-1.2.1\\']}, {\\'id\\': \\'T-DEV-1.3.1\\', \\'story\\': \\'S-DEV-1.3\\', \\'desc\\': \\'Generate-Patch command → invoke TaskExecutor.build_patch, open diff view.\\', \\'autonomous\\': False, \\'deps\\': [\\'T-MVP-1.3.1\\']}, {\\'id\\': \\'T-DEV-1.3.2\\', \\'story\\': \\'S-DEV-1.3\\', \\'desc\\': \\'After TaskReviewer.review_patch decorate hunks with pass/fail gutter icons.\\', \\'autonomous\\': False, \\'deps\\': [\\'T-DEV-1.3.1\\']}, {\\'id\\': \\'T-DEV-1.4.1\\', \\'story\\': \\'S-DEV-1.4\\', \\'desc\\': \\'Webview ‘Dev Dashboard’—show phase, task ID, commit SHA; ‘Run Full Cycle’ button.\\', \\'autonomous\\': False, \\'deps\\': [\\'T-MVP-1.4.2\\', \\'T-DEV-1.3.2\\']}]}, \\'POST_MVP\\': {\\'blocked_until\\': \\'E-MVP-1:DONE\\', \\'epics_placeholder\\': [\\'E-SCALE-1  Strict Typing & CI\\', \\'E-SCALE-2  Immutable Logging\\', \\'E-SCALE-3  ShellRunner Hardening\\', \\'E-SCALE-4  Observability & Metrics\\', \\'E-SCALE-5  Multi-file Diffs\\', \\'E-SCALE-6  Secrets & Security\\']}}\\n'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent = ReasoningAgent()\n",
    "agent.reset_context(system_prompt)\n",
    "agent.messages = agent.messages[:1]\n",
    "agent.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cee9ebc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-20 15:58:04,277] INFO LLM sync call: model=o3-2025-04-16, msgs_len=2\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "🧭 Immediate Next Steps — 45-Minute Kick-off Checklist  \n",
       "(aim: reach “red” state with a failing test that the autonomous loop can later turn green)\n",
       "\n",
       "1. Workspace & Environment\n",
       "   • Create / activate a fresh Python ≥3.10 virtual-env.  \n",
       "   • `pip install -U openai python-dotenv pytest tabulate streamlit pandas`  \n",
       "   • Ensure `OPENAI_API_KEY` is exported (or present in `.env`).\n",
       "\n",
       "2. Baseline Commit\n",
       "   • `git init` (if not already) → commit current code as “baseline-0”.\n",
       "\n",
       "3. Seed the Toy Defect (Story S-MVP-1.1)\n",
       "   a. `mkdir -p cadence/utils`  \n",
       "   b. `cadence/utils/add.py`  \n",
       "      ```python\n",
       "      def add(x: int, y: int) -> int:\n",
       "          \"\"\"Intentionally wrong implementation for MVP red→green demo.\"\"\"\n",
       "          return x - 1 + y\n",
       "      ```\n",
       "   c. `tests/test_add.py`  \n",
       "      ```python\n",
       "      from cadence.utils.add import add\n",
       "\n",
       "      def test_add():\n",
       "          assert add(2, 3) == 5\n",
       "      ```\n",
       "   d. `pytest` should now FAIL. Commit as “seed-defect”.\n",
       "\n",
       "4. Backlog File\n",
       "   • `dev_backlog.json` → paste the single micro-task that will drive the loop:\n",
       "\n",
       "   ```json\n",
       "   [\n",
       "     {\n",
       "       \"id\": \"bug-fix-add-001\",\n",
       "       \"title\": \"Fix utils.add.add() so that add(2,3)==5\",\n",
       "       \"type\": \"micro\",\n",
       "       \"status\": \"open\",\n",
       "       \"created_at\": \"2025-06-21T00:00:00Z\",\n",
       "       \"diff\": {\n",
       "         \"file\": \"cadence/utils/add.py\",\n",
       "         \"before\": \"def add(x: int, y: int) -> int:\\\\n    return x - 1 + y\\\\n\",\n",
       "         \"after\":  \"def add(x: int, y: int) -> int:\\\\n    return x + y\\\\n\"\n",
       "       }\n",
       "     }\n",
       "   ]\n",
       "   ```\n",
       "\n",
       "5. Minimal Config Stub\n",
       "   • Create `dev_config.json` (or inline in code) matching:\n",
       "\n",
       "   ```json\n",
       "   {\n",
       "     \"backlog_path\": \"dev_backlog.json\",\n",
       "     \"template_file\": \"dev_templates.json\",\n",
       "     \"src_root\": \"cadence\",\n",
       "     \"ruleset_file\": null,\n",
       "     \"repo_dir\": \".\",\n",
       "     \"record_file\": \"dev_record.json\"\n",
       "   }\n",
       "   ```\n",
       "\n",
       "6. Smoke-Test Orchestrator\n",
       "   ```bash\n",
       "   python -m cadence.dev.orchestrator start\n",
       "   ```\n",
       "   Expected flow:\n",
       "   • Executor builds patch (from backlog-diff).  \n",
       "   • Reviewer passes (static rules).  \n",
       "   • ShellRunner applies patch.  \n",
       "   • Pytest turns GREEN.  \n",
       "   • Commit & archive recorded to `dev_record.json`.\n",
       "\n",
       "7. Verify Audit Artefacts\n",
       "   • Open `dev_record.json` → confirm states: build_patch → patch_built → … → archived.  \n",
       "   • `git log -1` shows commit labeled “[Cadence] bug-fix-add-001 …”.\n",
       "\n",
       "8. Push to Remote / PR\n",
       "   • `git remote add origin …` (if needed)  \n",
       "   • `git push -u origin main`\n",
       "\n",
       "9. Stretch (optional, if time remains)\n",
       "   • Run `streamlit run cadence/dev/command_center.py` and walk through the same task via UI.  \n",
       "   • Add a lint rule to `ruleset.json` (e.g., forbid “print(”) and point config at it to see reviewer fail.\n",
       "\n",
       "––––––\n",
       "Once the above is green you have an end-to-end proof that the agentic pipeline can fix a real bug. The next milestone (Story S-MVP-1.2) is to shift from hand-authored diff to LLM-generated diff via `ExecutionAgent`; we’ll tackle that after the smoke test is stable."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = agent.run_interaction(\n",
    "\"\"\"\n",
    "Let's get started. Put togetehr some clear instructions for what to do next.\n",
    "\"\"\"\n",
    ")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e52d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_backlog = [\n",
    "    {\n",
    "        \"id\": \"bug-fix-add-001\",\n",
    "        \"title\": \"Fix utils.add.add() so that add(2,3)==5\",\n",
    "        \"type\": \"micro\",\n",
    "        \"status\": \"open\",\n",
    "        \"created_at\": \"2025-06-21T00:00:00Z\",\n",
    "        \"diff\": {\n",
    "            \"file\": \"cadence/utils/add.py\",\n",
    "            \"before\": \"def add(x: int, y: int) -> int:\\\\n    return x - 1 + y\\\\n\",\n",
    "            \"after\":  \"def add(x: int, y: int) -> int:\\\\n    return x + y\\\\n\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "dev_config = {\n",
    "    \"backlog_path\": \"dev_backlog.json\",\n",
    "    \"template_file\": \"dev_templates.json\",\n",
    "    \"src_root\": \"cadence\",\n",
    "    \"ruleset_file\": None,\n",
    "    \"repo_dir\": \".\",\n",
    "    \"record_file\": \"dev_record.json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c9772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeee3d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21987"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c05d02e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cadence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
