[
  {
    "title": "TASK-1 Auto-replenish backlog",
    "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
    "status": "open",
    "id": "ba002f7b-742f-4dce-911f-175c455bd673",
    "type": "micro",
    "created_at": "2025-06-21T23:48:17.392877",
    "diff": {
      "file": "<TBD>",
      "before": "",
      "after": ""
    },
    "generated_patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e8be57..8e85f70 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -1,7 +1,10 @@\n import logging\n+from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n+from cadence.backlog.manager import BacklogManager\n+from cadence.tasks.generator import TaskGenerator\n \n logger = logging.getLogger(__name__)\n \n@@ -29,10 +32,54 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self.backlog: BacklogManager  # type: ignore[attr-defined]\n+        self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n+        # backlog_autoreplenish_count may be set by CLI/global env\n+        self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n \n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n+            new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            snapshot(\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks}\n+            )\n+            logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n+        else:\n+            logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+        raise NotImplementedError()\n \n+\ndiff --git a/cadence/cli.py b/cadence/cli.py\nindex 92bc3fc..3ef930f 100644\n--- a/cadence/cli.py\n+++ b/cadence/cli.py\n@@ -64,6 +64,12 @@ def main():\n+    parser.add_argument(\n+        \"--backlog-autoreplenish-count\",\n+        type=int,\n+        default=3,\n+        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\"\n+    )\n@@ -131,6 +137,9 @@ def main():\n     if \"dev-orchestrator\" in args.orchestrator:\n         from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n         orchestrator = DevOrchestrator(\n             *orchestrator_args,\n             **orchestrator_kwargs,\n         )\n+        if hasattr(args, \"backlog_autoreplenish_count\"):\n+            orchestrator.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n@@ -155,6 +164,7 @@ def main():\n     try:\n         orchestrator.run_task_cycle(\n             interactive=args.interactive,\n         )\n     except RuntimeError as exc:\n         if \"No tasks exist\" in str(exc):\n-            print(\"ERROR: No tasks available.\", file=sys.stderr)\n+            print(\"ERROR: No tasks available.\", file=sys.stderr)\n         raise\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nnew file mode 100644\nindex 0000000..96b5837\n--- /dev/null\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -0,0 +1,54 @@\n+import tempfile\n+import shutil\n+import os\n+import pytest\n+\n+from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n+\n+class DummyTask:\n+    def __init__(self, desc):\n+        self.description = desc\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [i for i in self._items if getattr(i, \"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(task)\n+\n+class DummyTaskGen:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        return [DummyTask(f\"TASK-{i+1}\") for i in range(count)]\n+\n+\n+class DummySnapshotCtx:\n+    \"\"\"\n+    For monkeypatching the snapshot function used by ._ensure_backlog\n+    \"\"\"\n+    def __init__(self):\n+        self.calls = []\n+    def __call__(self, state, extra):\n+        self.calls.append((state, dict(extra)))\n+\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    # Patch out snapshot\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 3\n+    # Pre-condition: empty backlog\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    # Should auto-populate with 3 tasks, and snapshot\n+    orch._ensure_backlog()\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == 3\n+    assert snapctx.calls[-1][0] == \"backlog_replenished\"\n+    assert snapctx.calls[-1][1][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"count\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, count):\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 9  # should be overridden by param\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(count)\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == count\n+    assert snapctx.calls[-1][1][\"count\"] == count",
    "patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e8be57..8e85f70 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -1,7 +1,10 @@\n import logging\n+from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n+from cadence.backlog.manager import BacklogManager\n+from cadence.tasks.generator import TaskGenerator\n \n logger = logging.getLogger(__name__)\n \n@@ -29,10 +32,54 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self.backlog: BacklogManager  # type: ignore[attr-defined]\n+        self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n+        # backlog_autoreplenish_count may be set by CLI/global env\n+        self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n \n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n+            new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            snapshot(\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks}\n+            )\n+            logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n+        else:\n+            logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+        raise NotImplementedError()\n \n+\ndiff --git a/cadence/cli.py b/cadence/cli.py\nindex 92bc3fc..3ef930f 100644\n--- a/cadence/cli.py\n+++ b/cadence/cli.py\n@@ -64,6 +64,12 @@ def main():\n+    parser.add_argument(\n+        \"--backlog-autoreplenish-count\",\n+        type=int,\n+        default=3,\n+        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\"\n+    )\n@@ -131,6 +137,9 @@ def main():\n     if \"dev-orchestrator\" in args.orchestrator:\n         from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n         orchestrator = DevOrchestrator(\n             *orchestrator_args,\n             **orchestrator_kwargs,\n         )\n+        if hasattr(args, \"backlog_autoreplenish_count\"):\n+            orchestrator.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n@@ -155,6 +164,7 @@ def main():\n     try:\n         orchestrator.run_task_cycle(\n             interactive=args.interactive,\n         )\n     except RuntimeError as exc:\n         if \"No tasks exist\" in str(exc):\n-            print(\"ERROR: No tasks available.\", file=sys.stderr)\n+            print(\"ERROR: No tasks available.\", file=sys.stderr)\n         raise\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nnew file mode 100644\nindex 0000000..96b5837\n--- /dev/null\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -0,0 +1,54 @@\n+import tempfile\n+import shutil\n+import os\n+import pytest\n+\n+from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n+\n+class DummyTask:\n+    def __init__(self, desc):\n+        self.description = desc\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [i for i in self._items if getattr(i, \"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(task)\n+\n+class DummyTaskGen:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        return [DummyTask(f\"TASK-{i+1}\") for i in range(count)]\n+\n+\n+class DummySnapshotCtx:\n+    \"\"\"\n+    For monkeypatching the snapshot function used by ._ensure_backlog\n+    \"\"\"\n+    def __init__(self):\n+        self.calls = []\n+    def __call__(self, state, extra):\n+        self.calls.append((state, dict(extra)))\n+\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    # Patch out snapshot\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 3\n+    # Pre-condition: empty backlog\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    # Should auto-populate with 3 tasks, and snapshot\n+    orch._ensure_backlog()\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == 3\n+    assert snapctx.calls[-1][0] == \"backlog_replenished\"\n+    assert snapctx.calls[-1][1][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"count\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, count):\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 9  # should be overridden by param\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(count)\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == count\n+    assert snapctx.calls[-1][1][\"count\"] == count"
  },
  {
    "title": "TASK-2 EfficiencyAgent second review",
    "description": "Title: Wire EfficiencyAgent as mandatory second review\nGoal: Conform to DEV_PROCESS phase table (\u201cReview\u201d \u2192 Reasoning *and* Efficiency).\nImplementation Steps:\n\n1. In\u00a0**`DevOrchestrator.__init__`**\u00a0create\u00a0**`self.efficiency = get_agent(\"efficiency\")`**.\n2. After\u00a0**first**\u00a0review passes, call\u00a0**`eff_review = self.efficiency.run_interaction(<prompt_with_patch>)`**\u00a0or, simpler for now, reuse\u00a0**`TaskReviewer`**\u00a0but tag the state\u00a0**`\"efficiency_reviewed\"`**.\n3. Fail the task cycle unless both reviews pass.\n4. Record both review results with distinct states:\u00a0**`\"patch_reviewed_reasoning\"`**\u00a0/\u00a0**`\"patch_reviewed_efficiency\"`**.\n5. Extend phase flags so\u00a0**`git_commit`**\u00a0requires\u00a0**`\"efficiency_passed\"`**\u00a0as well.\n\nAcceptance: A commit cannot occur unless *both* reviews have succeeded; tests updated accordingly.",
    "status": "open",
    "id": "63014e53-0364-4b4d-aea4-6f43053e3368",
    "type": "micro",
    "created_at": "2025-06-21T23:48:17.393826",
    "diff": {
      "file": "<TBD>",
      "before": "",
      "after": ""
    },
    "generated_patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e85f70..59c5795 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -2,6 +2,7 @@\n from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n from cadence.backlog.manager import BacklogManager\n from cadence.tasks.generator import TaskGenerator\n+from cadence.agents import get_agent\n+from cadence.review.task_review import TaskReviewer\n \n logger = logging.getLogger(__name__)\n \n@@ -33,11 +35,14 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         self.backlog: BacklogManager  # type: ignore[attr-defined]\n         self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n         # backlog_autoreplenish_count may be set by CLI/global env\n         self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n+        # Wire up EfficiencyAgent for mandatory second review\n+        self.efficiency = get_agent(\"efficiency\")\n \n     def _ensure_backlog(self, count: Optional[int] = None):\n         \"\"\"\n         Ensures the backlog is not empty. If empty, generates and adds new tasks.\n         Records a snapshot when it replenishes.\n         \"\"\"\n         open_items = self.backlog.list_items(\"open\")\n         if not open_items:\n             num_tasks = count if count is not None else self.backlog_autoreplenish_count\n             logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n             new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n             for t in new_tasks:\n                 self.backlog.add_item(t)\n             snapshot(\n                 state=\"backlog_replenished\",\n                 extra={\"count\": num_tasks}\n             )\n             logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n         else:\n             logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # At the very top, auto-replenish backlog if needed\n-        self._ensure_backlog()\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+\n+        # (Placeholder for full pipeline; the essential portion for review follows:)\n+        # [ ... code for selecting a task and producing a patch ... ]\n+        patch = getattr(self, \"current_patch\", None)  # placeholder\n+        task = getattr(self, \"current_task\", None)    # placeholder\n+        # -- Reasoning review step\n+        reviewer = TaskReviewer()\n+        reasoning_result = reviewer.run_review(patch, task, agent=\"reasoning\")\n+        snapshot(state=\"patch_reviewed_reasoning\", extra={\"success\": reasoning_result.success, \"message\": reasoning_result.message})\n+        if not reasoning_result.success:\n+            logger.info(\"Reasoning review failed.\")\n+            raise RuntimeError(\"Reasoning review failed.\")\n+        # -- Efficiency review step (second review)\n+        efficiency_result = reviewer.run_review(patch, task, agent=\"efficiency\")\n+        snapshot(state=\"patch_reviewed_efficiency\", extra={\"success\": efficiency_result.success, \"message\": efficiency_result.message})\n+        if not efficiency_result.success:\n+            logger.info(\"Efficiency review failed.\")\n+            raise RuntimeError(\"Efficiency review failed.\")\n+        # Only after both passed:\n+        setattr(self, \"reasoning_passed\", True)\n+        setattr(self, \"efficiency_passed\", True)\n+        # [ ... further steps, e.g., commit, etc ... ]\n+        raise NotImplementedError()\n+\ndiff --git a/cadence/orchestrator/phases.py b/cadence/orchestrator/phases.py\nindex 727f112..423c1b3 100644\n--- a/cadence/orchestrator/phases.py\n+++ b/cadence/orchestrator/phases.py\n@@ -10,7 +10,9 @@ PHASE_FLAGS = {\n     \"plan_task\": [],\n     \"implement\": [\"plan_passed\"],\n     \"review\": [\"implemented\"],\n-    \"git_commit\": [\"review_passed\"],  # <-- previously only needed review_passed\n+    \"git_commit\": [\"review_passed\", \"efficiency_passed\"],  # Now require both reviews\n     # ...\n }\n \ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nindex 96b5837..d950125 100644\n--- a/cadence/orchestrator/tests/test_dev_orchestrator.py\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -55,6 +55,64 @@ def test_ensure_backlog_autopopulates(monkeypatch):\n     assert snapctx.calls[-1][0] == \"backlog_replenished\"\n     assert snapctx.calls[-1][1][\"count\"] == 3\n \n @pytest.mark.parametrize(\"count\", [2, 5])\n def test_ensure_backlog_respects_count(monkeypatch, count):\n     snapctx = DummySnapshotCtx()\n     monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n     orch = DevOrchestrator()\n     orch.backlog = DummyBacklog()\n     orch.task_generator = DummyTaskGen()\n     orch.backlog_autoreplenish_count = 9  # should be overridden by param\n     assert len(orch.backlog.list_items(\"open\")) == 0\n     orch._ensure_backlog(count)\n     tasks = orch.backlog.list_items(\"open\")\n     assert len(tasks) == count\n     assert snapctx.calls[-1][1][\"count\"] == count\n+\n+\n+# -- EfficiencyAgent second review wiring tests\n+class DummyReviewResult:\n+    def __init__(self, success, message=\"all good\"):\n+        self.success = success\n+        self.message = message\n+\n+class DummyTaskReviewer:\n+    def __init__(self, reviews):\n+        self._reviews = reviews\n+        self.calls = []\n+    def run_review(self, patch, task, agent):\n+        self.calls.append(agent)\n+        return self._reviews[agent]\n+\n+def test_both_reviews_must_pass(monkeypatch):\n+    \"\"\"\n+    Both reasoning and efficiency reviews must pass for cycle to proceed.\n+    \"\"\"\n+    orch = DevOrchestrator()\n+    orch._ensure_backlog = lambda *a, **kw: None  # skip\n+    # Patch reviewer\n+    dummy_reviews = {\n+        \"reasoning\": DummyReviewResult(True),\n+        \"efficiency\": DummyReviewResult(True),\n+    }\n+    reviewer = DummyTaskReviewer(dummy_reviews)\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.TaskReviewer\", lambda: reviewer)\n+    # Patch snapshot\n+    snaps = []\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", lambda state, extra=None: snaps.append((state, dict(extra or {}))))\n+    # Patch placeholders for patch/task\n+    orch.current_patch = \"diff --git a/foo b/foo\"\n+    orch.current_task = DummyTask(\"foobar\")\n+    # the NotImplementedError is expected after reviews\n+    with pytest.raises(NotImplementedError):\n+        orch.run_task_cycle(interactive=False)\n+    assert snaps[0][0] == \"patch_reviewed_reasoning\"\n+    assert snaps[1][0] == \"patch_reviewed_efficiency\"\n+    assert getattr(orch, \"reasoning_passed\", False)\n+    assert getattr(orch, \"efficiency_passed\", False) is not False  # True\n+\n+\n+@pytest.mark.parametrize(\"fail_reasoning,fail_efficiency\", [(True,False),(False,True)])\n+def test_review_failures_raise(monkeypatch, fail_reasoning, fail_efficiency):\n+    orch = DevOrchestrator()\n+    orch._ensure_backlog = lambda *a,**kw: None\n+    dummy_reviews = {\n+        \"reasoning\": DummyReviewResult(not fail_reasoning),\n+        \"efficiency\": DummyReviewResult(not fail_efficiency),\n+    }\n+    reviewer = DummyTaskReviewer(dummy_reviews)\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.TaskReviewer\", lambda: reviewer)\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", lambda state, extra=None: None)\n+    orch.current_patch = \"diff --git\"\n+    orch.current_task = DummyTask(\"foo\")\n+    if fail_reasoning:\n+        with pytest.raises(RuntimeError, match=\"Reasoning review failed\"):\n+            orch.run_task_cycle(interactive=False)\n+    elif fail_efficiency:\n+        with pytest.raises(RuntimeError, match=\"Efficiency review failed\"):\n+            orch.run_task_cycle(interactive=False)",
    "patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e85f70..4d9482a 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -1,6 +1,8 @@\n import logging\n from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n from cadence.backlog.manager import BacklogManager\n from cadence.tasks.generator import TaskGenerator\n+from cadence.agents import get_agent\n+from cadence.review.task_review import TaskReviewer\n \n logger = logging.getLogger(__name__)\n \n@@ -33,11 +35,46 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         self.backlog: BacklogManager  # type: ignore[attr-defined]\n         self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n         # backlog_autoreplenish_count may be set by CLI/global env\n         self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n+        # Wire up EfficiencyAgent for mandatory second review\n+        self.efficiency = get_agent(\"efficiency\")\n \n     def _ensure_backlog(self, count: Optional[int] = None):\n         \"\"\"\n         Ensures the backlog is not empty. If empty, generates and adds new tasks.\n         Records a snapshot when it replenishes.\n         \"\"\"\n         open_items = self.backlog.list_items(\"open\")\n         if not open_items:\n             num_tasks = count if count is not None else self.backlog_autoreplenish_count\n             logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n             new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n             for t in new_tasks:\n                 self.backlog.add_item(t)\n             snapshot(\n                 state=\"backlog_replenished\",\n                 extra={\"count\": num_tasks}\n             )\n             logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n         else:\n             logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # At the very top, auto-replenish backlog if needed\n-        self._ensure_backlog()\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+\n+        # (Placeholder for full pipeline; the essential portion for review follows:)\n+        # [ ... code for selecting a task and producing a patch ... ]\n+        patch = getattr(self, \"current_patch\", None)  # placeholder\n+        task = getattr(self, \"current_task\", None)    # placeholder\n+        # -- Reasoning review step\n+        reviewer = TaskReviewer()\n+        reasoning_result = reviewer.run_review(patch, task, agent=\"reasoning\")\n+        snapshot(state=\"patch_reviewed_reasoning\", extra={\"success\": reasoning_result.success, \"message\": reasoning_result.message})\n+        if not reasoning_result.success:\n+            logger.info(\"Reasoning review failed.\")\n+            raise RuntimeError(\"Reasoning review failed.\")\n+        # -- Efficiency review step (second review)\n+        efficiency_result = reviewer.run_review(patch, task, agent=\"efficiency\")\n+        snapshot(state=\"patch_reviewed_efficiency\", extra={\"success\": efficiency_result.success, \"message\": efficiency_result.message})\n+        if not efficiency_result.success:\n+            logger.info(\"Efficiency review failed.\")\n+            raise RuntimeError(\"Efficiency review failed.\")\n+        # Only after both passed:\n+        setattr(self, \"reasoning_passed\", True)\n+        setattr(self, \"efficiency_passed\", True)\n+        # [ ... further steps, e.g., commit, etc ... ]\n+        raise NotImplementedError()\n+\ndiff --git a/cadence/orchestrator/phases.py b/cadence/orchestrator/phases.py\nindex 727f112..423c1b3 100644\n--- a/cadence/orchestrator/phases.py\n+++ b/cadence/orchestrator/phases.py\n@@ -10,7 +10,9 @@ PHASE_FLAGS = {\n     \"plan_task\": [],\n     \"implement\": [\"plan_passed\"],\n     \"review\": [\"implemented\"],\n-    \"git_commit\": [\"review_passed\"],  # <-- previously only needed review_passed\n+    \"git_commit\": [\"review_passed\", \"efficiency_passed\"],  # Now require both reviews\n     # ...\n }\n \ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nindex 96b5837..d950125 100644\n--- a/cadence/orchestrator/tests/test_dev_orchestrator.py\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -55,6 +55,64 @@ def test_ensure_backlog_autopopulates(monkeypatch):\n     assert snapctx.calls[-1][0] == \"backlog_replenished\"\n     assert snapctx.calls[-1][1][\"count\"] == 3\n \n @pytest.mark.parametrize(\"count\", [2, 5])\n def test_ensure_backlog_respects_count(monkeypatch, count):\n     snapctx = DummySnapshotCtx()\n     monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n     orch = DevOrchestrator()\n     orch.backlog = DummyBacklog()\n     orch.task_generator = DummyTaskGen()\n     orch.backlog_autoreplenish_count = 9  # should be overridden by param\n     assert len(orch.backlog.list_items(\"open\")) == 0\n     orch._ensure_backlog(count)\n     tasks = orch.backlog.list_items(\"open\")\n     assert len(tasks) == count\n     assert snapctx.calls[-1][1][\"count\"] == count\n+\n+\n+# -- EfficiencyAgent second review wiring tests\n+class DummyReviewResult:\n+    def __init__(self, success, message=\"all good\"):\n+        self.success = success\n+        self.message = message\n+\n+class DummyTaskReviewer:\n+    def __init__(self, reviews):\n+        self._reviews = reviews\n+        self.calls = []\n+    def run_review(self, patch, task, agent):\n+        self.calls.append(agent)\n+        return self._reviews[agent]\n+\n+def test_both_reviews_must_pass(monkeypatch):\n+    \"\"\"\n+    Both reasoning and efficiency reviews must pass for cycle to proceed.\n+    \"\"\"\n+    orch = DevOrchestrator()\n+    orch._ensure_backlog = lambda *a, **kw: None  # skip\n+    # Patch reviewer\n+    dummy_reviews = {\n+        \"reasoning\": DummyReviewResult(True),\n+        \"efficiency\": DummyReviewResult(True),\n+    }\n+    reviewer = DummyTaskReviewer(dummy_reviews)\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.TaskReviewer\", lambda: reviewer)\n+    # Patch snapshot\n+    snaps = []\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", lambda state, extra=None: snaps.append((state, dict(extra or {}))))\n+    # Patch placeholders for patch/task\n+    orch.current_patch = \"diff --git a/foo b/foo\"\n+    orch.current_task = DummyTask(\"foobar\")\n+    # the NotImplementedError is expected after reviews\n+    with pytest.raises(NotImplementedError):\n+        orch.run_task_cycle(interactive=False)\n+    assert snaps[0][0] == \"patch_reviewed_reasoning\"\n+    assert snaps[1][0] == \"patch_reviewed_efficiency\"\n+    assert getattr(orch, \"reasoning_passed\", False)\n+    assert getattr(orch, \"efficiency_passed\", False) is not False  # True\n+\n+\n+@pytest.mark.parametrize(\"fail_reasoning,fail_efficiency\", [(True,False),(False,True)])\n+def test_review_failures_raise(monkeypatch, fail_reasoning, fail_efficiency):\n+    orch = DevOrchestrator()\n+    orch._ensure_backlog = lambda *a,**kw: None\n+    dummy_reviews = {\n+        \"reasoning\": DummyReviewResult(not fail_reasoning),\n+        \"efficiency\": DummyReviewResult(not fail_efficiency),\n+    }\n+    reviewer = DummyTaskReviewer(dummy_reviews)\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.TaskReviewer\", lambda: reviewer)\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", lambda state, extra=None: None)\n+    orch.current_patch = \"diff --git\"\n+    orch.current_task = DummyTask(\"foo\")\n+    if fail_reasoning:\n+        with pytest.raises(RuntimeError, match=\"Reasoning review failed\"):\n+            orch.run_task_cycle(interactive=False)\n+    elif fail_efficiency:\n+        with pytest.raises(RuntimeError, match=\"Efficiency review failed\"):\n+            orch.run_task_cycle(interactive=False)"
  },
  {
    "title": "TASK-3 MetaAgent hook",
    "description": "Title: First-class MetaAgent hook\nGoal: Provide real-time governance / drift detection per DEV_PROCESS.\nImplementation Steps:\n\n1. Add simple\u00a0**`MetaAgent.analyse(run_summary: dict)`**\u00a0stub that just logs or appends to TaskRecord.\n2. Call it at the end of every\u00a0**`run_task_cycle()`**\u00a0(success\u00a0*or*\u00a0failure) with the full result dict.\n3. Record state\u00a0**`\"meta_analysis\"`**\u00a0plus whatever telemetry the MetaAgent returns.\n4. (Future-proof) Keep invocation behind\u00a0**`config[\"enable_meta\"]`**\u00a0flag (default True).\n\nAcceptance: TaskRecord shows a **`meta_analysis`** snapshot for every cycle; meta failures do not crash the run.",
    "status": "open",
    "id": "3f54ce61-cd7a-4e9a-b6aa-008c23748873",
    "type": "micro",
    "created_at": "2025-06-21T23:48:17.394043",
    "diff": {
      "file": "<TBD>",
      "before": "",
      "after": ""
    },
    "generated_patch": "diff --git a/cadence/agents/meta.py b/cadence/agents/meta.py\nnew file mode 100644\nindex 0000000..4e7332e\n--- /dev/null\n+++ b/cadence/agents/meta.py\n@@ -0,0 +1,23 @@\n+import logging\n+# First-class MetaAgent stub\n+logger = logging.getLogger(\"cadence.agents.meta\")\n+\n+class MetaAgent:\n+    def __init__(self, *args, **kwargs):\n+        pass\n+\n+    def analyse(self, run_summary: dict):\n+        \"\"\"\n+        Accepts a dictionary of the run summary. For now, just logs it and returns a (possibly empty) dict.\n+        Future: implement governance/drift/etc.\n+        \"\"\"\n+        logger.info(\"MetaAgent.analyse summary: %r\", run_summary)\n+        # Simulate possible annotation etc\n+        results = {\n+            \"feedback\": \"MetaAgent review passed\",\n+            \"minor_drift_detected\": False,\n+        }\n+        # (Optional: mutating or appending to TaskRecord elsewhere)\n+        return results\n+\n+\ndiff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 59c5795..fe6fabd 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -6,6 +6,8 @@\n from cadence.backlog.manager import BacklogManager\n from cadence.tasks.generator import TaskGenerator\n from cadence.agents import get_agent\n from cadence.review.task_review import TaskReviewer\n+from cadence.agents.meta import MetaAgent\n+import copy\n \n logger = logging.getLogger(__name__)\n \n@@ -36,12 +38,19 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         self.backlog: BacklogManager  # type: ignore[attr-defined]\n         self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n         # backlog_autoreplenish_count may be set by CLI/global env\n         self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n         # Wire up EfficiencyAgent for mandatory second review\n         self.efficiency = get_agent(\"efficiency\")\n+        # MetaAgent and config/flag\n+        self.meta_agent = MetaAgent()\n+        self.config = getattr(self, \"config\", {})\n+        if \"enable_meta\" not in self.config:\n+            self.config[\"enable_meta\"] = True\n+        # track last run summary\n+        self._last_run_summary = None\n \n     def _ensure_backlog(self, count: Optional[int] = None):\n         \"\"\"\n         Ensures the backlog is not empty. If empty, generates and adds new tasks.\n         Records a snapshot when it replenishes.\n         \"\"\"\n         open_items = self.backlog.list_items(\"open\")\n         if not open_items:\n             num_tasks = count if count is not None else self.backlog_autoreplenish_count\n             logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n             new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n             for t in new_tasks:\n                 self.backlog.add_item(t)\n             snapshot(\n                 state=\"backlog_replenished\",\n                 extra={\"count\": num_tasks}\n             )\n             logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n         else:\n             logger.debug(\"Backlog has open items, not replenishing.\")\n \n-    def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # At the very top, auto-replenish backlog if needed\n-        self._ensure_backlog()\n-        # Main task pipeline, schedules, tracks, etc.\n-\n-        # (Placeholder for full pipeline; the essential portion for review follows:)\n-        # [ ... code for selecting a task and producing a patch ... ]\n-        patch = getattr(self, \"current_patch\", None)  # placeholder\n-        task = getattr(self, \"current_task\", None)    # placeholder\n-        # -- Reasoning review step\n-        reviewer = TaskReviewer()\n-        reasoning_result = reviewer.run_review(patch, task, agent=\"reasoning\")\n-        snapshot(state=\"patch_reviewed_reasoning\", extra={\"success\": reasoning_result.success, \"message\": reasoning_result.message})\n-        if not reasoning_result.success:\n-            logger.info(\"Reasoning review failed.\")\n-            raise RuntimeError(\"Reasoning review failed.\")\n-        # -- Efficiency review step (second review)\n-        efficiency_result = reviewer.run_review(patch, task, agent=\"efficiency\")\n-        snapshot(state=\"patch_reviewed_efficiency\", extra={\"success\": efficiency_result.success, \"message\": efficiency_result.message})\n-        if not efficiency_result.success:\n-            logger.info(\"Efficiency review failed.\")\n-            raise RuntimeError(\"Efficiency review failed.\")\n-        # Only after both passed:\n-        setattr(self, \"reasoning_passed\", True)\n-        setattr(self, \"efficiency_passed\", True)\n-        # [ ... further steps, e.g., commit, etc ... ]\n-        raise NotImplementedError()\n+    def run_task_cycle(self, *args, interactive=True, **kwargs):\n+        \"\"\"\n+        Run a full task pipeline cycle; triggers meta agent analysis on all outcomes.\n+        \"\"\"\n+        run_summary = {}\n+        self._ensure_backlog()\n+        try:\n+            # [ ... code for selecting a task and producing a patch ... ]\n+            patch = getattr(self, \"current_patch\", None)  # placeholder\n+            task = getattr(self, \"current_task\", None)    # placeholder\n+            run_summary[\"task\"] = str(getattr(task, \"description\", None))\n+            reviewer = TaskReviewer()\n+            reasoning_result = reviewer.run_review(patch, task, agent=\"reasoning\")\n+            run_summary[\"reasoning_result\"] = {\"success\": reasoning_result.success, \"message\": reasoning_result.message}\n+            snapshot(state=\"patch_reviewed_reasoning\", extra={\"success\": reasoning_result.success, \"message\": reasoning_result.message})\n+            if not reasoning_result.success:\n+                run_summary[\"failure\"] = \"reasoning_review\"\n+                logger.info(\"Reasoning review failed.\")\n+                raise RuntimeError(\"Reasoning review failed.\")\n+            efficiency_result = reviewer.run_review(patch, task, agent=\"efficiency\")\n+            run_summary[\"efficiency_result\"] = {\"success\": efficiency_result.success, \"message\": efficiency_result.message}\n+            snapshot(state=\"patch_reviewed_efficiency\", extra={\"success\": efficiency_result.success, \"message\": efficiency_result.message})\n+            if not efficiency_result.success:\n+                run_summary[\"failure\"] = \"efficiency_review\"\n+                logger.info(\"Efficiency review failed.\")\n+                raise RuntimeError(\"Efficiency review failed.\")\n+            setattr(self, \"reasoning_passed\", True)\n+            setattr(self, \"efficiency_passed\", True)\n+            run_summary[\"reasoning_passed\"] = True\n+            run_summary[\"efficiency_passed\"] = True\n+            # [ ... further steps ... ]\n+            # Simulate post-review/completion: success\n+            run_summary[\"success\"] = True\n+            raise NotImplementedError()\n+        except Exception as e:\n+            run_summary[\"exception\"] = repr(e)\n+            run_summary[\"success\"] = False\n+            raise\n+        finally:\n+            # Record meta agent analysis regardless of in-pipeline success/failure\n+            if self.config.get(\"enable_meta\", True):\n+                try:\n+                    # Send a deep copy to meta_agent so information remains immutable\n+                    meta_result = self.meta_agent.analyse(copy.deepcopy(run_summary))\n+                    snapshot(state=\"meta_analysis\", extra=dict(meta_result or {}))\n+                except Exception as meta_exc:\n+                    logger.warning(\"MetaAgent analysis failed: %r\", meta_exc)\n+            self._last_run_summary = run_summary\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nindex d950125..cfc0286 100644\n--- a/cadence/orchestrator/tests/test_dev_orchestrator.py\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -83,6 +83,42 @@ def test_both_reviews_must_pass(monkeypatch):\n     assert getattr(orch, \"reasoning_passed\", False)\n     assert getattr(orch, \"efficiency_passed\", False) is not False  # True\n \n \n @pytest.mark.parametrize(\"fail_reasoning,fail_efficiency\", [(True,False),(False,True)])\n def test_review_failures_raise(monkeypatch, fail_reasoning, fail_efficiency):\n     orch = DevOrchestrator()\n     orch._ensure_backlog = lambda *a,**kw: None\n     dummy_reviews = {\n         \"reasoning\": DummyReviewResult(not fail_reasoning),\n         \"efficiency\": DummyReviewResult(not fail_efficiency),\n     }\n     reviewer = DummyTaskReviewer(dummy_reviews)\n     monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.TaskReviewer\", lambda: reviewer)\n     monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", lambda state, extra=None: None)\n     orch.current_patch = \"diff --git\"\n     orch.current_task = DummyTask(\"foo\")\n     if fail_reasoning:\n         with pytest.raises(RuntimeError, match=\"Reasoning review failed\"):\n             orch.run_task_cycle(interactive=False)\n     elif fail_efficiency:\n         with pytest.raises(RuntimeError, match=\"Efficiency review failed\"):\n             orch.run_task_cycle(interactive=False)\n+\n+\n+# --- MetaAgent hook tests\n+class DummyMetaAgent:\n+    def __init__(self):\n+        self.calls = []\n+        self.return_dict = {\"meta_result\":\"ok\"}\n+    def analyse(self, run_summary):\n+        self.calls.append(run_summary)\n+        return self.return_dict\n+\n+def test_meta_analysis_snap(monkeypatch):\n+    \"\"\"MetaAgent should be called at end of run_task_cycle and snapshot records meta_analysis.\"\"\"\n+    orch = DevOrchestrator()\n+    orch._ensure_backlog = lambda *a,**k: None\n+    orch.current_patch = \"patch\"\n+    orch.current_task = DummyTask(\"t\")\n+    # Reviewer passes both; NotImplementedError always raised at end\n+    reviewer = DummyTaskReviewer({\"reasoning\": DummyReviewResult(True), \"efficiency\": DummyReviewResult(True)})\n+    meta = DummyMetaAgent()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.TaskReviewer\", lambda: reviewer)\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.MetaAgent\", lambda: meta)\n+    snaps = []\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", lambda state, extra=None: snaps.append((state, dict(extra or {}))))\n+    orch.config = {\"enable_meta\": True}\n+    orch.meta_agent = meta\n+    with pytest.raises(NotImplementedError):\n+        orch.run_task_cycle()\n+    # meta_analysis should exist as snapshot\n+    assert any(s for s in snaps if s[0] == \"meta_analysis\")\n+    assert meta.calls  # MetaAgent was called\n+\n+def test_meta_failure_does_not_crash(monkeypatch):\n+    orch = DevOrchestrator()\n+    orch._ensure_backlog = lambda *a,**k: None\n+    orch.current_patch = \"patch\"\n+    orch.current_task = DummyTask(\"t\")\n+    reviewer = DummyTaskReviewer({\"reasoning\": DummyReviewResult(True), \"efficiency\": DummyReviewResult(True)})\n+    # meta agent throws\n+    class FailingMetaAgent:\n+        def analyse(self, run_summary): raise RuntimeError(\"meta fail!\")\n+    meta = FailingMetaAgent()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.TaskReviewer\", lambda: reviewer)\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.MetaAgent\", lambda: meta)\n+    snaps = []\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", lambda state, extra=None: snaps.append((state, dict(extra or {}))))\n+    orch.config = {\"enable_meta\": True}\n+    orch.meta_agent = meta\n+    with pytest.raises(NotImplementedError):\n+        orch.run_task_cycle()\n+    # no exception from meta agent should propagate",
    "patch": "diff --git a/cadence/agents/meta.py b/cadence/agents/meta.py\nnew file mode 100644\nindex 0000000..4e7332e\n--- /dev/null\n+++ b/cadence/agents/meta.py\n@@ -0,0 +1,23 @@\n+import logging\n+# First-class MetaAgent stub\n+logger = logging.getLogger(\"cadence.agents.meta\")\n+\n+class MetaAgent:\n+    def __init__(self, *args, **kwargs):\n+        pass\n+\n+    def analyse(self, run_summary: dict):\n+        \"\"\"\n+        Accepts a dictionary of the run summary. For now, just logs it and returns a (possibly empty) dict.\n+        Future: implement governance/drift/etc.\n+        \"\"\"\n+        logger.info(\"MetaAgent.analyse summary: %r\", run_summary)\n+        # Simulate possible annotation etc\n+        results = {\n+            \"feedback\": \"MetaAgent review passed\",\n+            \"minor_drift_detected\": False,\n+        }\n+        # (Optional: mutating or appending to TaskRecord elsewhere)\n+        return results\n+\n+\ndiff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 59c5795..fe6fabd 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -6,6 +6,8 @@\n from cadence.backlog.manager import BacklogManager\n from cadence.tasks.generator import TaskGenerator\n from cadence.agents import get_agent\n from cadence.review.task_review import TaskReviewer\n+from cadence.agents.meta import MetaAgent\n+import copy\n \n logger = logging.getLogger(__name__)\n \n@@ -36,12 +38,19 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         self.backlog: BacklogManager  # type: ignore[attr-defined]\n         self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n         # backlog_autoreplenish_count may be set by CLI/global env\n         self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n         # Wire up EfficiencyAgent for mandatory second review\n         self.efficiency = get_agent(\"efficiency\")\n+        # MetaAgent and config/flag\n+        self.meta_agent = MetaAgent()\n+        self.config = getattr(self, \"config\", {})\n+        if \"enable_meta\" not in self.config:\n+            self.config[\"enable_meta\"] = True\n+        # track last run summary\n+        self._last_run_summary = None\n \n     def _ensure_backlog(self, count: Optional[int] = None):\n         \"\"\"\n         Ensures the backlog is not empty. If empty, generates and adds new tasks.\n         Records a snapshot when it replenishes.\n         \"\"\"\n         open_items = self.backlog.list_items(\"open\")\n         if not open_items:\n             num_tasks = count if count is not None else self.backlog_autoreplenish_count\n             logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n             new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n             for t in new_tasks:\n                 self.backlog.add_item(t)\n             snapshot(\n                 state=\"backlog_replenished\",\n                 extra={\"count\": num_tasks}\n             )\n             logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n         else:\n             logger.debug(\"Backlog has open items, not replenishing.\")\n \n-    def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # At the very top, auto-replenish backlog if needed\n-        self._ensure_backlog()\n-        # Main task pipeline, schedules, tracks, etc.\n-\n-        # (Placeholder for full pipeline; the essential portion for review follows:)\n-        # [ ... code for selecting a task and producing a patch ... ]\n-        patch = getattr(self, \"current_patch\", None)  # placeholder\n-        task = getattr(self, \"current_task\", None)    # placeholder\n-        # -- Reasoning review step\n-        reviewer = TaskReviewer()\n-        reasoning_result = reviewer.run_review(patch, task, agent=\"reasoning\")\n-        snapshot(state=\"patch_reviewed_reasoning\", extra={\"success\": reasoning_result.success, \"message\": reasoning_result.message})\n-        if not reasoning_result.success:\n-            logger.info(\"Reasoning review failed.\")\n-            raise RuntimeError(\"Reasoning review failed.\")\n-        # -- Efficiency review step (second review)\n-        efficiency_result = reviewer.run_review(patch, task, agent=\"efficiency\")\n-        snapshot(state=\"patch_reviewed_efficiency\", extra={\"success\": efficiency_result.success, \"message\": efficiency_result.message})\n-        if not efficiency_result.success:\n-            logger.info(\"Efficiency review failed.\")\n-            raise RuntimeError(\"Efficiency review failed.\")\n-        # Only after both passed:\n-        setattr(self, \"reasoning_passed\", True)\n-        setattr(self, \"efficiency_passed\", True)\n-        # [ ... further steps, e.g., commit, etc ... ]\n-        raise NotImplementedError()\n+    def run_task_cycle(self, *args, interactive=True, **kwargs):\n+        \"\"\"\n+        Run a full task pipeline cycle; triggers meta agent analysis on all outcomes.\n+        \"\"\"\n+        run_summary = {}\n+        self._ensure_backlog()\n+        try:\n+            # [ ... code for selecting a task and producing a patch ... ]\n+            patch = getattr(self, \"current_patch\", None)  # placeholder\n+            task = getattr(self, \"current_task\", None)    # placeholder\n+            run_summary[\"task\"] = str(getattr(task, \"description\", None))\n+            reviewer = TaskReviewer()\n+            reasoning_result = reviewer.run_review(patch, task, agent=\"reasoning\")\n+            run_summary[\"reasoning_result\"] = {\"success\": reasoning_result.success, \"message\": reasoning_result.message}\n+            snapshot(state=\"patch_reviewed_reasoning\", extra={\"success\": reasoning_result.success, \"message\": reasoning_result.message})\n+            if not reasoning_result.success:\n+                run_summary[\"failure\"] = \"reasoning_review\"\n+                logger.info(\"Reasoning review failed.\")\n+                raise RuntimeError(\"Reasoning review failed.\")\n+            efficiency_result = reviewer.run_review(patch, task, agent=\"efficiency\")\n+            run_summary[\"efficiency_result\"] = {\"success\": efficiency_result.success, \"message\": efficiency_result.message}\n+            snapshot(state=\"patch_reviewed_efficiency\", extra={\"success\": efficiency_result.success, \"message\": efficiency_result.message})\n+            if not efficiency_result.success:\n+                run_summary[\"failure\"] = \"efficiency_review\"\n+                logger.info(\"Efficiency review failed.\")\n+                raise RuntimeError(\"Efficiency review failed.\")\n+            setattr(self, \"reasoning_passed\", True)\n+            setattr(self, \"efficiency_passed\", True)\n+            run_summary[\"reasoning_passed\"] = True\n+            run_summary[\"efficiency_passed\"] = True\n+            # [ ... further steps ... ]\n+            # Simulate post-review/completion: success\n+            run_summary[\"success\"] = True\n+            raise NotImplementedError()\n+        except Exception as e:\n+            run_summary[\"exception\"] = repr(e)\n+            run_summary[\"success\"] = False\n+            raise\n+        finally:\n+            # Record meta agent analysis regardless of in-pipeline success/failure\n+            if self.config.get(\"enable_meta\", True):\n+                try:\n+                    # Send a deep copy to meta_agent so information remains immutable\n+                    meta_result = self.meta_agent.analyse(copy.deepcopy(run_summary))\n+                    snapshot(state=\"meta_analysis\", extra=dict(meta_result or {}))\n+                except Exception as meta_exc:\n+                    logger.warning(\"MetaAgent analysis failed: %r\", meta_exc)\n+            self._last_run_summary = run_summary\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nindex d950125..cfc0286 100644\n--- a/cadence/orchestrator/tests/test_dev_orchestrator.py\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -83,6 +83,42 @@ def test_both_reviews_must_pass(monkeypatch):\n     assert getattr(orch, \"reasoning_passed\", False)\n     assert getattr(orch, \"efficiency_passed\", False) is not False  # True\n \n \n @pytest.mark.parametrize(\"fail_reasoning,fail_efficiency\", [(True,False),(False,True)])\n def test_review_failures_raise(monkeypatch, fail_reasoning, fail_efficiency):\n     orch = DevOrchestrator()\n     orch._ensure_backlog = lambda *a,**kw: None\n     dummy_reviews = {\n         \"reasoning\": DummyReviewResult(not fail_reasoning),\n         \"efficiency\": DummyReviewResult(not fail_efficiency),\n     }\n     reviewer = DummyTaskReviewer(dummy_reviews)\n     monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.TaskReviewer\", lambda: reviewer)\n     monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", lambda state, extra=None: None)\n     orch.current_patch = \"diff --git\"\n     orch.current_task = DummyTask(\"foo\")\n     if fail_reasoning:\n         with pytest.raises(RuntimeError, match=\"Reasoning review failed\"):\n             orch.run_task_cycle(interactive=False)\n     elif fail_efficiency:\n         with pytest.raises(RuntimeError, match=\"Efficiency review failed\"):\n             orch.run_task_cycle(interactive=False)\n+\n+\n+# --- MetaAgent hook tests\n+class DummyMetaAgent:\n+    def __init__(self):\n+        self.calls = []\n+        self.return_dict = {\"meta_result\":\"ok\"}\n+    def analyse(self, run_summary):\n+        self.calls.append(run_summary)\n+        return self.return_dict\n+\n+def test_meta_analysis_snap(monkeypatch):\n+    \"\"\"MetaAgent should be called at end of run_task_cycle and snapshot records meta_analysis.\"\"\"\n+    orch = DevOrchestrator()\n+    orch._ensure_backlog = lambda *a,**k: None\n+    orch.current_patch = \"patch\"\n+    orch.current_task = DummyTask(\"t\")\n+    # Reviewer passes both; NotImplementedError always raised at end\n+    reviewer = DummyTaskReviewer({\"reasoning\": DummyReviewResult(True), \"efficiency\": DummyReviewResult(True)})\n+    meta = DummyMetaAgent()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.TaskReviewer\", lambda: reviewer)\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.MetaAgent\", lambda: meta)\n+    snaps = []\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", lambda state, extra=None: snaps.append((state, dict(extra or {}))))\n+    orch.config = {\"enable_meta\": True}\n+    orch.meta_agent = meta\n+    with pytest.raises(NotImplementedError):\n+        orch.run_task_cycle()\n+    # meta_analysis should exist as snapshot\n+    assert any(s for s in snaps if s[0] == \"meta_analysis\")\n+    assert meta.calls  # MetaAgent was called\n+\n+def test_meta_failure_does_not_crash(monkeypatch):\n+    orch = DevOrchestrator()\n+    orch._ensure_backlog = lambda *a,**k: None\n+    orch.current_patch = \"patch\"\n+    orch.current_task = DummyTask(\"t\")\n+    reviewer = DummyTaskReviewer({\"reasoning\": DummyReviewResult(True), \"efficiency\": DummyReviewResult(True)})\n+    # meta agent throws\n+    class FailingMetaAgent:\n+        def analyse(self, run_summary): raise RuntimeError(\"meta fail!\")\n+    meta = FailingMetaAgent()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.TaskReviewer\", lambda: reviewer)\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.MetaAgent\", lambda: meta)\n+    snaps = []\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", lambda state, extra=None: snaps.append((state, dict(extra or {}))))\n+    orch.config = {\"enable_meta\": True}\n+    orch.meta_agent = meta\n+    with pytest.raises(NotImplementedError):\n+        orch.run_task_cycle()\n+    # no exception from meta agent should propagate"
  },
  {
    "title": "TASK-4 Reviewer strict rule types",
    "description": "Title: Harden TaskReviewer rule parsing\nGoal: Unknown rule types must never be ignored silently.\nImplementation Steps:\n\n1. In\u00a0**`TaskReviewer._load_ruleset`**\u00a0raise\u00a0**`PatchReviewError`**\u00a0**or**\u00a0emit\u00a0**`logger.warning`**\u00a0when\u00a0**`type`**\u00a0is unrecognised.\n2. Provide\u00a0**`strict`**\u00a0constructor flag (default True).\n3. Add regression test loading a ruleset with an invalid type \u2192 expect exception or warning.\n\nAcceptance: CI fails (or logs) on an unrecognised rule type; no silent pass.",
    "status": "open",
    "id": "fdbcdfae-1a3f-4023-a79e-49e40c69371e",
    "type": "micro",
    "created_at": "2025-06-21T23:48:17.394250",
    "diff": {
      "file": "<TBD>",
      "before": "",
      "after": ""
    },
    "generated_patch": "diff --git a/cadence/review/task_review.py b/cadence/review/task_review.py\nindex 7736809..d58caae 100644\n--- a/cadence/review/task_review.py\n+++ b/cadence/review/task_review.py\n@@ -1,11 +1,21 @@\n import logging\n+from typing import Any, Dict, List, Optional\n \n logger = logging.getLogger(__name__)\n \n class PatchReviewError(Exception):\n     pass\n \n class TaskReviewer:\n-    def __init__(self, ruleset=None, agent=\"reasoning\"):\n-        self.ruleset = ruleset or []\n-        self.agent = agent\n+    def __init__(self, ruleset: Optional[List[Dict[str, Any]]] = None, agent=\"reasoning\", strict: bool = True):\n+        self.ruleset = ruleset or []\n+        self.agent = agent\n+        self.strict = strict\n         self._parsed_rules = self._load_ruleset(self.ruleset)\n \n-    def _load_ruleset(self, ruleset):\n-        # parse rules for later\n-        parsed = []\n-        for rule in ruleset:\n-            # TODO: Real validation, multiple types\n-            if rule.get(\"type\") == \"diff_contains\":\n-                parsed.append(rule)\n-            # Could extend here...\n-        return parsed\n+    def _load_ruleset(self, ruleset):\n+        parsed = []\n+        allowed_types = {\"diff_contains\"}\n+        for rule in ruleset:\n+            rtype = rule.get(\"type\")\n+            if rtype in allowed_types:\n+                parsed.append(rule)\n+            else:\n+                msg = f\"Unknown rule type: {rtype!r} in ruleset\"\n+                if self.strict:\n+                    logger.error(msg)\n+                    raise PatchReviewError(msg)\n+                else:\n+                    logger.warning(msg)\n+        return parsed\ndiff --git a/cadence/review/tests/test_task_review.py b/cadence/review/tests/test_task_review.py\nindex 9570e0f..d0b73dc 100644\n--- a/cadence/review/tests/test_task_review.py\n+++ b/cadence/review/tests/test_task_review.py\n@@ -1,5 +1,29 @@\n import pytest\n-from cadence.review.task_review import TaskReviewer, PatchReviewError\n+import logging\n+from cadence.review.task_review import TaskReviewer, PatchReviewError\n+\n+\n+def test_invalid_rule_type_raises_by_default():\n+    bad_ruleset = [\n+        {\"type\": \"diff_contains\", \"match\": \"foo\"},\n+        {\"type\": \"totally_fake_rule\", \"abc\": \"123\"}\n+    ]\n+    with pytest.raises(PatchReviewError) as excinfo:\n+        TaskReviewer(ruleset=bad_ruleset)\n+    assert \"Unknown rule type\" in str(excinfo.value)\n+\n+\n+def test_invalid_rule_type_logs_warning_if_not_strict(caplog):\n+    bad_ruleset = [\n+        {\"type\": \"diff_contains\", \"match\": \"foo\"},\n+        {\"type\": \"nonesuch\", \"foobar\": \"yes\"}\n+    ]\n+    caplog.set_level(logging.WARNING)\n+    # Should only log warning, not raise\n+    reviewer = TaskReviewer(ruleset=bad_ruleset, strict=False)\n+    warnings = [r for r in caplog.records if r.levelno >= logging.WARNING]\n+    assert any(\"Unknown rule type\" in r.msg for r in warnings)\n+    # Only first rule accepted\n+    assert len(reviewer._parsed_rules) == 1",
    "patch": "diff --git a/cadence/review/task_review.py b/cadence/review/task_review.py\nindex 7736809..d58caae 100644\n--- a/cadence/review/task_review.py\n+++ b/cadence/review/task_review.py\n@@ -1,11 +1,21 @@\n import logging\n+from typing import Any, Dict, List, Optional\n \n logger = logging.getLogger(__name__)\n \n class PatchReviewError(Exception):\n     pass\n \n class TaskReviewer:\n-    def __init__(self, ruleset=None, agent=\"reasoning\"):\n-        self.ruleset = ruleset or []\n-        self.agent = agent\n+    def __init__(self, ruleset: Optional[List[Dict[str, Any]]] = None, agent=\"reasoning\", strict: bool = True):\n+        self.ruleset = ruleset or []\n+        self.agent = agent\n+        self.strict = strict\n         self._parsed_rules = self._load_ruleset(self.ruleset)\n \n-    def _load_ruleset(self, ruleset):\n-        # parse rules for later\n-        parsed = []\n-        for rule in ruleset:\n-            # TODO: Real validation, multiple types\n-            if rule.get(\"type\") == \"diff_contains\":\n-                parsed.append(rule)\n-            # Could extend here...\n-        return parsed\n+    def _load_ruleset(self, ruleset):\n+        parsed = []\n+        allowed_types = {\"diff_contains\"}\n+        for rule in ruleset:\n+            rtype = rule.get(\"type\")\n+            if rtype in allowed_types:\n+                parsed.append(rule)\n+            else:\n+                msg = f\"Unknown rule type: {rtype!r} in ruleset\"\n+                if self.strict:\n+                    logger.error(msg)\n+                    raise PatchReviewError(msg)\n+                else:\n+                    logger.warning(msg)\n+        return parsed\ndiff --git a/cadence/review/tests/test_task_review.py b/cadence/review/tests/test_task_review.py\nindex 9570e0f..d0b73dc 100644\n--- a/cadence/review/tests/test_task_review.py\n+++ b/cadence/review/tests/test_task_review.py\n@@ -1,5 +1,29 @@\n import pytest\n-from cadence.review.task_review import TaskReviewer, PatchReviewError\n+import logging\n+from cadence.review.task_review import TaskReviewer, PatchReviewError\n+\n+\n+def test_invalid_rule_type_raises_by_default():\n+    bad_ruleset = [\n+        {\"type\": \"diff_contains\", \"match\": \"foo\"},\n+        {\"type\": \"totally_fake_rule\", \"abc\": \"123\"}\n+    ]\n+    with pytest.raises(PatchReviewError) as excinfo:\n+        TaskReviewer(ruleset=bad_ruleset)\n+    assert \"Unknown rule type\" in str(excinfo.value)\n+\n+\n+def test_invalid_rule_type_logs_warning_if_not_strict(caplog):\n+    bad_ruleset = [\n+        {\"type\": \"diff_contains\", \"match\": \"foo\"},\n+        {\"type\": \"nonesuch\", \"foobar\": \"yes\"}\n+    ]\n+    caplog.set_level(logging.WARNING)\n+    # Should only log warning, not raise\n+    reviewer = TaskReviewer(ruleset=bad_ruleset, strict=False)\n+    warnings = [r for r in caplog.records if r.levelno >= logging.WARNING]\n+    assert any(\"Unknown rule type\" in r.msg for r in warnings)\n+    # Only first rule accepted\n+    assert len(reviewer._parsed_rules) == 1"
  },
  {
    "title": "TASK-5 Commit guard review flags",
    "description": "Title: Expand enforce_phase \u2192 include review guards\nGoal: Prevent any commit unless **`\"review_passed\"`** *and* **`\"efficiency_passed\"`** flags exist.\nImplementation Steps:\n\n1. Add new decorator usage or explicit check in\u00a0**`ShellRunner.git_commit`**:\u00a0required = [\"patch_applied\", \"tests_passed\", \"review_passed\", \"efficiency_passed\"]\n2. Set those flags inside DevOrchestrator right after each successful review.\n3. Update tests in test_phase_ordering_and_precheck.py to assert commit fails without both review flags.\n\nAcceptance: New tests pass; existing tests updated to set the new flags on the happy path.",
    "status": "open",
    "id": "4a9b332c-0bfc-4d85-a732-c70338cb00cb",
    "type": "micro",
    "created_at": "2025-06-21T23:48:17.394482",
    "diff": {
      "file": "<TBD>",
      "before": "",
      "after": ""
    },
    "generated_patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex fe6fabd..e887a92 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -82,10 +82,19 @@ class DevOrchestrator(BaseOrchestrator):\n             snapshot(state=\"patch_reviewed_reasoning\", extra={\"success\": reasoning_result.success, \"message\": reasoning_result.message})\n             if not reasoning_result.success:\n                 run_summary[\"failure\"] = \"reasoning_review\"\n                 logger.info(\"Reasoning review failed.\")\n                 raise RuntimeError(\"Reasoning review failed.\")\n             efficiency_result = reviewer.run_review(patch, task, agent=\"efficiency\")\n             run_summary[\"efficiency_result\"] = {\"success\": efficiency_result.success, \"message\": efficiency_result.message}\n             snapshot(state=\"patch_reviewed_efficiency\", extra={\"success\": efficiency_result.success, \"message\": efficiency_result.message})\n             if not efficiency_result.success:\n                 run_summary[\"failure\"] = \"efficiency_review\"\n                 logger.info(\"Efficiency review failed.\")\n                 raise RuntimeError(\"Efficiency review failed.\")\n-            setattr(self, \"reasoning_passed\", True)\n-            setattr(self, \"efficiency_passed\", True)\n-            run_summary[\"reasoning_passed\"] = True\n-            run_summary[\"efficiency_passed\"] = True\n+            setattr(self, \"reasoning_passed\", True)\n+            setattr(self, \"efficiency_passed\", True)\n+            # Set commit guard flags as required by ShellRunner.git_commit\n+            self.set_flag(\"review_passed\")\n+            self.set_flag(\"efficiency_passed\")\n+            run_summary[\"reasoning_passed\"] = True\n+            run_summary[\"efficiency_passed\"] = True\n+            run_summary[\"review_passed\"] = True\n+            run_summary[\"efficiency_passed_flag\"] = True\n             # [ ... further steps ... ]\n             # Simulate post-review/completion: success\n             run_summary[\"success\"] = True\n             raise NotImplementedError()\ndiff --git a/cadence/shell/shell_runner.py b/cadence/shell/shell_runner.py\nindex b55e875..f52e4ca 100644\n--- a/cadence/shell/shell_runner.py\n+++ b/cadence/shell/shell_runner.py\n@@ -200,10 +200,21 @@ class ShellRunner:\n     def git_commit(self, *args, **kwargs):\n-        self.enforce_phase(\"git_commit\")\n+        # Explicit enforce required flags before allowing commit.\n+        required = [\"patch_applied\", \"tests_passed\", \"review_passed\", \"efficiency_passed\"]\n+        for flag in required:\n+            if not self.has_flag(flag):\n+                raise RuntimeError(\n+                    f\"Cannot commit: required review/test flag missing: {flag}\"\n+                )\n+        self.enforce_phase(\"git_commit\")\n         # ... the actual commit shell op ...\n         raise NotImplementedError(\"Commit flow not implemented\")\ndiff --git a/cadence/orchestrator/tests/test_phase_ordering_and_precheck.py b/cadence/orchestrator/tests/test_phase_ordering_and_precheck.py\nindex 3c8e601..af5eea1 100644\n--- a/cadence/orchestrator/tests/test_phase_ordering_and_precheck.py\n+++ b/cadence/orchestrator/tests/test_phase_ordering_and_precheck.py\n@@ -54,7 +54,33 @@ def test_git_commit_rejects_without_passed_phases(monkeypatch):\n-    r.set_flag(\"patch_applied\")\n-    # missing tests_passed\n-    with pytest.raises(RuntimeError, match=\"tests_passed\"):\n-        r.git_commit()\n+    r.set_flag(\"patch_applied\")\n+    # missing tests_passed\n+    with pytest.raises(RuntimeError, match=\"tests_passed\"):\n+        r.git_commit()\n+    # set tests_passed, missing review_passed, efficiency_passed\n+    r.set_flag(\"tests_passed\")\n+    with pytest.raises(RuntimeError, match=\"review_passed\"):\n+        r.git_commit()\n+    # review_passed set, but missing efficiency_passed\n+    r.set_flag(\"review_passed\")\n+    with pytest.raises(RuntimeError, match=\"efficiency_passed\"):\n+        r.git_commit()\n+    # Only after all present does it proceed\n+    r.set_flag(\"efficiency_passed\")\n+    # Now commit proceeds to NotImplementedError\n+    with pytest.raises(NotImplementedError):\n+        r.git_commit()\n@@ -65,12 +91,16 @@ def test_git_commit_accepts_all_flags(monkeypatch):\n     r = DummyShellRunner()\n-    r.set_flag(\"patch_applied\")\n-    r.set_flag(\"tests_passed\")\n-    r.set_flag(\"review_passed\")\n-    # If missing efficiency_passed, should not pass\n-    with pytest.raises(RuntimeError, match=\"efficiency_passed\"):\n-        r.git_commit()\n-    r.set_flag(\"efficiency_passed\")\n-    with pytest.raises(NotImplementedError):\n-        r.git_commit()\n+    r.set_flag(\"patch_applied\")\n+    r.set_flag(\"tests_passed\")\n+    r.set_flag(\"review_passed\")\n+    # If missing efficiency_passed, should not pass\n+    with pytest.raises(RuntimeError, match=\"efficiency_passed\"):\n+        r.git_commit()\n+    r.set_flag(\"efficiency_passed\")\n+    with pytest.raises(NotImplementedError):\n+        r.git_commit()",
    "patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex fe6fabd..e887a92 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -82,10 +82,19 @@ class DevOrchestrator(BaseOrchestrator):\n             snapshot(state=\"patch_reviewed_reasoning\", extra={\"success\": reasoning_result.success, \"message\": reasoning_result.message})\n             if not reasoning_result.success:\n                 run_summary[\"failure\"] = \"reasoning_review\"\n                 logger.info(\"Reasoning review failed.\")\n                 raise RuntimeError(\"Reasoning review failed.\")\n             efficiency_result = reviewer.run_review(patch, task, agent=\"efficiency\")\n             run_summary[\"efficiency_result\"] = {\"success\": efficiency_result.success, \"message\": efficiency_result.message}\n             snapshot(state=\"patch_reviewed_efficiency\", extra={\"success\": efficiency_result.success, \"message\": efficiency_result.message})\n             if not efficiency_result.success:\n                 run_summary[\"failure\"] = \"efficiency_review\"\n                 logger.info(\"Efficiency review failed.\")\n                 raise RuntimeError(\"Efficiency review failed.\")\n-            setattr(self, \"reasoning_passed\", True)\n-            setattr(self, \"efficiency_passed\", True)\n-            run_summary[\"reasoning_passed\"] = True\n-            run_summary[\"efficiency_passed\"] = True\n+            setattr(self, \"reasoning_passed\", True)\n+            setattr(self, \"efficiency_passed\", True)\n+            # Set commit guard flags as required by ShellRunner.git_commit\n+            self.set_flag(\"review_passed\")\n+            self.set_flag(\"efficiency_passed\")\n+            run_summary[\"reasoning_passed\"] = True\n+            run_summary[\"efficiency_passed\"] = True\n+            run_summary[\"review_passed\"] = True\n+            run_summary[\"efficiency_passed_flag\"] = True\n             # [ ... further steps ... ]\n             # Simulate post-review/completion: success\n             run_summary[\"success\"] = True\n             raise NotImplementedError()\ndiff --git a/cadence/shell/shell_runner.py b/cadence/shell/shell_runner.py\nindex b55e875..f52e4ca 100644\n--- a/cadence/shell/shell_runner.py\n+++ b/cadence/shell/shell_runner.py\n@@ -200,10 +200,21 @@ class ShellRunner:\n     def git_commit(self, *args, **kwargs):\n-        self.enforce_phase(\"git_commit\")\n+        # Explicit enforce required flags before allowing commit.\n+        required = [\"patch_applied\", \"tests_passed\", \"review_passed\", \"efficiency_passed\"]\n+        for flag in required:\n+            if not self.has_flag(flag):\n+                raise RuntimeError(\n+                    f\"Cannot commit: required review/test flag missing: {flag}\"\n+                )\n+        self.enforce_phase(\"git_commit\")\n         # ... the actual commit shell op ...\n         raise NotImplementedError(\"Commit flow not implemented\")\ndiff --git a/cadence/orchestrator/tests/test_phase_ordering_and_precheck.py b/cadence/orchestrator/tests/test_phase_ordering_and_precheck.py\nindex 3c8e601..af5eea1 100644\n--- a/cadence/orchestrator/tests/test_phase_ordering_and_precheck.py\n+++ b/cadence/orchestrator/tests/test_phase_ordering_and_precheck.py\n@@ -54,7 +54,33 @@ def test_git_commit_rejects_without_passed_phases(monkeypatch):\n-    r.set_flag(\"patch_applied\")\n-    # missing tests_passed\n-    with pytest.raises(RuntimeError, match=\"tests_passed\"):\n-        r.git_commit()\n+    r.set_flag(\"patch_applied\")\n+    # missing tests_passed\n+    with pytest.raises(RuntimeError, match=\"tests_passed\"):\n+        r.git_commit()\n+    # set tests_passed, missing review_passed, efficiency_passed\n+    r.set_flag(\"tests_passed\")\n+    with pytest.raises(RuntimeError, match=\"review_passed\"):\n+        r.git_commit()\n+    # review_passed set, but missing efficiency_passed\n+    r.set_flag(\"review_passed\")\n+    with pytest.raises(RuntimeError, match=\"efficiency_passed\"):\n+        r.git_commit()\n+    # Only after all present does it proceed\n+    r.set_flag(\"efficiency_passed\")\n+    # Now commit proceeds to NotImplementedError\n+    with pytest.raises(NotImplementedError):\n+        r.git_commit()\n@@ -65,12 +91,16 @@ def test_git_commit_accepts_all_flags(monkeypatch):\n     r = DummyShellRunner()\n-    r.set_flag(\"patch_applied\")\n-    r.set_flag(\"tests_passed\")\n-    r.set_flag(\"review_passed\")\n-    # If missing efficiency_passed, should not pass\n-    with pytest.raises(RuntimeError, match=\"efficiency_passed\"):\n-        r.git_commit()\n-    r.set_flag(\"efficiency_passed\")\n-    with pytest.raises(NotImplementedError):\n-        r.git_commit()\n+    r.set_flag(\"patch_applied\")\n+    r.set_flag(\"tests_passed\")\n+    r.set_flag(\"review_passed\")\n+    # If missing efficiency_passed, should not pass\n+    with pytest.raises(RuntimeError, match=\"efficiency_passed\"):\n+        r.git_commit()\n+    r.set_flag(\"efficiency_passed\")\n+    with pytest.raises(NotImplementedError):\n+        r.git_commit()"
  },
  {
    "title": "TASK-6 Cross-process file locks",
    "description": "Title: Cross-process file-locking for backlog & record\nGoal: Prevent two orchestrators on the same repo from racing.\nImplementation Steps:\n\n1. Add lightweight cross-process lock via\u00a0**`filelock`**\u00a0(pip-light) or portalocker.\n2. Acquire the lock in\u00a0**`.save()`**\u00a0and\u00a0**`.load()`**\u00a0of BacklogManager & TaskRecord\u00a0*in addition*\u00a0to the existing RLock.\u00a0Lock file path =\u00a0**`<jsonfile>.lock`**.\n3. Time-out (e.g., 10 s) then raise custom\u00a0**`FileLockTimeoutError`**; caller should retry or alert.\n4. Add smoke test: spawn two\u00a0**`multiprocessing.Process`**\u00a0objects that hammer\u00a0**`.add_item`**; assert no JSON corruption.\n\nAcceptance: Concurrency test passes; manual ctrl-C leaves **`.lock`** cleaned up.",
    "status": "open",
    "id": "977b4250-4360-4f55-9bf8-2bc9bedcd897",
    "type": "micro",
    "created_at": "2025-06-21T23:48:17.394698",
    "diff": {
      "file": "<TBD>",
      "before": "",
      "after": ""
    },
    "generated_patch": "diff --git a/cadence/backlog/manager.py b/cadence/backlog/manager.py\nindex 848dfad..c3f98e7 100644\n--- a/cadence/backlog/manager.py\n+++ b/cadence/backlog/manager.py\n@@ -1,9 +1,32 @@\n-import threading\n+import threading\n+import os\n+import time\n+from contextlib import contextmanager\n+from filelock import Timeout, FileLock\n \n class BacklogManager:\n-    def __init__(self, path):\n-        self.path = path\n-        self._lock = threading.RLock()\n-        self.items = []\n+    LOCK_TIMEOUT_SECONDS = 10\n+\n+    class FileLockTimeoutError(Exception):\n+        pass\n+\n+    def __init__(self, path):\n+        self.path = path\n+        self._lock = threading.RLock()\n+        self.items = []\n+        self.lockfile = self.path + \".lock\"\n+\n+    @contextmanager\n+    def _crossproc_lock(self):\n+        lock = FileLock(self.lockfile, timeout=self.LOCK_TIMEOUT_SECONDS)\n+        try:\n+            lock.acquire()\n+            try:\n+                yield\n+            finally:\n+                lock.release()\n+        except Timeout:\n+            raise BacklogManager.FileLockTimeoutError(\n+                f\"Timeout: unable to acquire file lock on {self.lockfile}\", \n+            )\n \n     def save(self):\n-        with self._lock:\n-            with open(self.path, \"w\") as f:\n-                json.dump(self.items, f)\n+        with self._lock:\n+            with self._crossproc_lock():\n+                with open(self.path, \"w\") as f:\n+                    json.dump(self.items, f)\n \n     def load(self):\n-        with self._lock:\n-            with open(self.path) as f:\n-                self.items = json.load(f)\n+        with self._lock:\n+            with self._crossproc_lock():\n+                if os.path.exists(self.path):\n+                    with open(self.path) as f:\n+                        self.items = json.load(f)\n+                else:\n+                    self.items = []\n \n     def add_item(self, item):\n-        with self._lock:\n-            self.items.append(item)\n-            self.save()\n+        with self._lock:\n+            self.items.append(item)\n+            self.save()\ndiff --git a/cadence/record/record.py b/cadence/record/record.py\nindex 5c0de57..5d231f1 100644\n--- a/cadence/record/record.py\n+++ b/cadence/record/record.py\n@@ -1,10 +1,34 @@\n-import threading\n+import threading\n+import os\n+from contextlib import contextmanager\n+from filelock import FileLock, Timeout\n \n class TaskRecord:\n-    def __init__(self, path):\n-        self.path = path\n-        self._lock = threading.RLock()\n-        self.entries = []\n+    LOCK_TIMEOUT_SECONDS = 10\n+\n+    class FileLockTimeoutError(Exception):\n+        pass\n+\n+    def __init__(self, path):\n+        self.path = path\n+        self._lock = threading.RLock()\n+        self.entries = []\n+        self.lockfile = self.path + \".lock\"\n+\n+    @contextmanager\n+    def _crossproc_lock(self):\n+        lock = FileLock(self.lockfile, timeout=self.LOCK_TIMEOUT_SECONDS)\n+        try:\n+            lock.acquire()\n+            try:\n+                yield\n+            finally:\n+                lock.release()\n+        except Timeout:\n+            raise TaskRecord.FileLockTimeoutError(\n+                f\"Timeout: unable to acquire file lock on {self.lockfile}\"\n+            )\n \n     def save(self):\n-        with self._lock:\n-            with open(self.path, \"w\") as f:\n-                json.dump(self.entries, f)\n+        with self._lock:\n+            with self._crossproc_lock():\n+                with open(self.path, \"w\") as f:\n+                    json.dump(self.entries, f)\n \n     def load(self):\n-        with self._lock:\n-            with open(self.path) as f:\n-                self.entries = json.load(f)\n+        with self._lock:\n+            with self._crossproc_lock():\n+                if os.path.exists(self.path):\n+                    with open(self.path) as f:\n+                        self.entries = json.load(f)\n+                else:\n+                    self.entries = []\n \n     def append(self, entry):\n-        with self._lock:\n-            self.entries.append(entry)\n-            self.save()\n+        with self._lock:\n+            self.entries.append(entry)\n+            self.save()\ndiff --git a/requirements.txt b/requirements.txt\nindex 7e3b864..fe85e6a 100644\n--- a/requirements.txt\n+++ b/requirements.txt\n@@ -1,3 +1,4 @@\n+filelock\n pytest\n requests\n pydantic\ndiff --git a/cadence/backlog/tests/test_backlog_concurrency.py b/cadence/backlog/tests/test_backlog_concurrency.py\nnew file mode 100644\nindex 0000000..b9878de\n--- /dev/null\n+++ b/cadence/backlog/tests/test_backlog_concurrency.py\n@@ -0,0 +1,64 @@\n+import os\n+import time\n+import tempfile\n+import json\n+import shutil\n+import pytest\n+\n+from multiprocessing import Process, Queue\n+\n+from cadence.backlog.manager import BacklogManager\n+\n+def worker(backlog_path, start_val, nitems, queue=None):\n+    mgr = BacklogManager(backlog_path)\n+    for i in range(nitems):\n+        item = {\"id\": f\"worker-{start_val+i}\", \"val\": start_val+i}\n+        mgr.load()  # make sure we pull other's work\n+        mgr.add_item(item)\n+        mgr.save()\n+        time.sleep(0.05)\n+    if queue:\n+        mgr.load()\n+        queue.put(len(mgr.items))\n+\n+def test_backlog_filelock_concurrency(tmp_path):\n+    # Uses temp file; two processes hammer add_item at same time, multiple rounds\n+    backlog_file = tmp_path / \"shared_backlog.json\"\n+    start = [{\"id\": \"zero\", \"val\": 0}]\n+    with open(backlog_file, \"w\") as f:\n+        json.dump(start, f)\n+    nitems = 5\n+    q1, q2 = Queue(), Queue()\n+    # Process A and B each add nitems, at slightly different values\n+    p1 = Process(target=worker, args=(str(backlog_file), 1000, nitems, q1))\n+    p2 = Process(target=worker, args=(str(backlog_file), 2000, nitems, q2))\n+    p1.start(); p2.start()\n+    p1.join(); p2.join()\n+    # Now, no .lock exists\n+    assert not os.path.exists(str(backlog_file) + \".lock\")\n+    # The file is valid JSON and contains all items\n+    mgr = BacklogManager(str(backlog_file))\n+    mgr.load()\n+    expected = 1 + 2 * nitems  # 1 starter + 2x nitems\n+    assert len(mgr.items) == expected\n+    # All ids distinct\n+    ids = {it[\"id\"] for it in mgr.items}\n+    assert len(ids) == expected\n+    # The processes also saw a complete view each\n+    got1 = q1.get()\n+    got2 = q2.get()\n+    assert got1 == expected\n+    assert got2 == expected\n+\n+\n+def test_filelock_timeout(tmp_path):\n+    backlog_file = tmp_path / \"tlock.json\"\n+    mgr = BacklogManager(str(backlog_file))\n+    # Simulate another process holding the lock forever\n+    from filelock import FileLock\n+    lockfile = str(backlog_file)+\".lock\"\n+    lock = FileLock(lockfile, timeout=0.1)\n+    lock.acquire()\n+    try:\n+        with pytest.raises(BacklogManager.FileLockTimeoutError):\n+            mgr.load()\n+    finally:\n+        lock.release()",
    "patch": "diff --git a/cadence/backlog/manager.py b/cadence/backlog/manager.py\nindex 41c5b78..a5c3177 100644\n--- a/cadence/backlog/manager.py\n+++ b/cadence/backlog/manager.py\n@@ -1,15 +1,50 @@\n-import threading\n-import json\n+import threading\n+import os\n+import time\n+import json\n+from contextlib import contextmanager\n+from filelock import Timeout, FileLock\n+\n \n class BacklogManager:\n-    def __init__(self, path):\n-        self.path = path\n-        self._lock = threading.RLock()\n-        self.items = []\n-\n-    def save(self):\n-        with self._lock:\n-            with open(self.path, \"w\") as f:\n-                json.dump(self.items, f)\n-\n-    def load(self):\n-        with self._lock:\n-            with open(self.path) as f:\n-                self.items = json.load(f)\n-\n-    def add_item(self, item):\n-        with self._lock:\n-            self.items.append(item)\n-            self.save()\n+    LOCK_TIMEOUT_SECONDS = 10\n+\n+    class FileLockTimeoutError(Exception):\n+        pass\n+\n+    def __init__(self, path):\n+        self.path = path\n+        self._lock = threading.RLock()\n+        self.items = []\n+        self.lockfile = self.path + \".lock\"\n+\n+    @contextmanager\n+    def _crossproc_lock(self):\n+        lock = FileLock(self.lockfile, timeout=self.LOCK_TIMEOUT_SECONDS)\n+        try:\n+            lock.acquire()\n+            try:\n+                yield\n+            finally:\n+                lock.release()\n+        except Timeout:\n+            raise BacklogManager.FileLockTimeoutError(\n+                f\"Timeout: unable to acquire file lock on {self.lockfile}\", \n+            )\n+\n+    def save(self):\n+        with self._lock:\n+            with self._crossproc_lock():\n+                with open(self.path, \"w\") as f:\n+                    json.dump(self.items, f)\n+\n+    def load(self):\n+        with self._lock:\n+            with self._crossproc_lock():\n+                if os.path.exists(self.path):\n+                    with open(self.path) as f:\n+                        self.items = json.load(f)\n+                else:\n+                    self.items = []\n+\n+    def add_item(self, item):\n+        with self._lock:\n+            self.items.append(item)\n+            self.save()\ndiff --git a/cadence/record/record.py b/cadence/record/record.py\nindex c9554c7..6b7c0f1 100644\n--- a/cadence/record/record.py\n+++ b/cadence/record/record.py\n@@ -1,15 +1,50 @@\n-import threading\n-import json\n+import threading\n+import os\n+from contextlib import contextmanager\n+import json\n+from filelock import FileLock, Timeout\n+\n \n class TaskRecord:\n-    def __init__(self, path):\n-        self.path = path\n-        self._lock = threading.RLock()\n-        self.entries = []\n-\n-    def save(self):\n-        with self._lock:\n-            with open(self.path, \"w\") as f:\n-                json.dump(self.entries, f)\n-\n-    def load(self):\n-        with self._lock:\n-            with open(self.path) as f:\n-                self.entries = json.load(f)\n-\n-    def append(self, entry):\n-        with self._lock:\n-            self.entries.append(entry)\n-            self.save()\n+    LOCK_TIMEOUT_SECONDS = 10\n+\n+    class FileLockTimeoutError(Exception):\n+        pass\n+\n+    def __init__(self, path):\n+        self.path = path\n+        self._lock = threading.RLock()\n+        self.entries = []\n+        self.lockfile = self.path + \".lock\"\n+\n+    @contextmanager\n+    def _crossproc_lock(self):\n+        lock = FileLock(self.lockfile, timeout=self.LOCK_TIMEOUT_SECONDS)\n+        try:\n+            lock.acquire()\n+            try:\n+                yield\n+            finally:\n+                lock.release()\n+        except Timeout:\n+            raise TaskRecord.FileLockTimeoutError(\n+                f\"Timeout: unable to acquire file lock on {self.lockfile}\"\n+            )\n+\n+    def save(self):\n+        with self._lock:\n+            with self._crossproc_lock():\n+                with open(self.path, \"w\") as f:\n+                    json.dump(self.entries, f)\n+\n+    def load(self):\n+        with self._lock:\n+            with self._crossproc_lock():\n+                if os.path.exists(self.path):\n+                    with open(self.path) as f:\n+                        self.entries = json.load(f)\n+                else:\n+                    self.entries = []\n+\n+    def append(self, entry):\n+        with self._lock:\n+            self.entries.append(entry)\n+            self.save()\ndiff --git a/requirements.txt b/requirements.txt\nindex 7e3b864..fe85e6a 100644\n--- a/requirements.txt\n+++ b/requirements.txt\n@@ -1,3 +1,4 @@\n+filelock\n pytest\n requests\n pydantic\ndiff --git a/cadence/backlog/tests/test_backlog_concurrency.py b/cadence/backlog/tests/test_backlog_concurrency.py\nnew file mode 100644\nindex 0000000..b9878de\n--- /dev/null\n+++ b/cadence/backlog/tests/test_backlog_concurrency.py\n@@ -0,0 +1,64 @@\n+import os\n+import time\n+import tempfile\n+import json\n+import shutil\n+import pytest\n+\n+from multiprocessing import Process, Queue\n+\n+from cadence.backlog.manager import BacklogManager\n+\n+def worker(backlog_path, start_val, nitems, queue=None):\n+    mgr = BacklogManager(backlog_path)\n+    for i in range(nitems):\n+        item = {\"id\": f\"worker-{start_val+i}\", \"val\": start_val+i}\n+        mgr.load()  # make sure we pull other's work\n+        mgr.add_item(item)\n+        mgr.save()\n+        time.sleep(0.05)\n+    if queue:\n+        mgr.load()\n+        queue.put(len(mgr.items))\n+\n+def test_backlog_filelock_concurrency(tmp_path):\n+    # Uses temp file; two processes hammer add_item at same time, multiple rounds\n+    backlog_file = tmp_path / \"shared_backlog.json\"\n+    start = [{\"id\": \"zero\", \"val\": 0}]\n+    with open(backlog_file, \"w\") as f:\n+        json.dump(start, f)\n+    nitems = 5\n+    q1, q2 = Queue(), Queue()\n+    # Process A and B each add nitems, at slightly different values\n+    p1 = Process(target=worker, args=(str(backlog_file), 1000, nitems, q1))\n+    p2 = Process(target=worker, args=(str(backlog_file), 2000, nitems, q2))\n+    p1.start(); p2.start()\n+    p1.join(); p2.join()\n+    # Now, no .lock exists\n+    assert not os.path.exists(str(backlog_file) + \".lock\")\n+    # The file is valid JSON and contains all items\n+    mgr = BacklogManager(str(backlog_file))\n+    mgr.load()\n+    expected = 1 + 2 * nitems  # 1 starter + 2x nitems\n+    assert len(mgr.items) == expected\n+    # All ids distinct\n+    ids = {it[\"id\"] for it in mgr.items}\n+    assert len(ids) == expected\n+    # The processes also saw a complete view each\n+    got1 = q1.get()\n+    got2 = q2.get()\n+    assert got1 == expected\n+    assert got2 == expected\n+\n+\n+def test_filelock_timeout(tmp_path):\n+    backlog_file = tmp_path / \"tlock.json\"\n+    mgr = BacklogManager(str(backlog_file))\n+    # Simulate another process holding the lock forever\n+    from filelock import FileLock\n+    lockfile = str(backlog_file)+\".lock\"\n+    lock = FileLock(lockfile, timeout=0.1)\n+    lock.acquire()\n+    try:\n+        with pytest.raises(BacklogManager.FileLockTimeoutError):\n+            mgr.load()\n+    finally:\n+        lock.release()"
  },
  {
    "title": "TASK-7 LLMClient stub mode",
    "description": "Title: Graceful LLMClient fallback when env is missing\nGoal: Allow offline/CI runs without exporting OPENAI_API_KEY.\nImplementation Steps:\n\n1. In\u00a0**`LLMClient.__init__`**, if api_key is missing:\u00a0\u2013 log a\u00a0**warning**;\u00a0\u2013 enter \u201cstub-mode\u201d:\u00a0**`.call()`**\u00a0and\u00a0**`.acall()`**\u00a0return a canned message (e.g.,\u00a0**`\"LLM unavailable\"`**).\n2. Add\u00a0**`self.stub = True`**\u00a0flag; tests can assert behaviour.\n3. Update existing CI tests to expect stub-mode (they already monkey-patch OpenAI).\n\nAcceptance: Running orchestrator without the env var no longer crashes; warning is emitted exactly once per process.",
    "status": "open",
    "id": "67b8abd4-c51b-4c6b-a191-ae0c44bea123",
    "type": "micro",
    "created_at": "2025-06-21T23:48:17.394912",
    "diff": {
      "file": "<TBD>",
      "before": "",
      "after": ""
    },
    "generated_patch": "diff --git a/cadence/llm/llm_client.py b/cadence/llm/llm_client.py\nindex 192b2b3..dd2a7e6 100644\n--- a/cadence/llm/llm_client.py\n+++ b/cadence/llm/llm_client.py\n@@ -1,6 +1,26 @@\n import os\n import logging\n+import asyncio\n \n logger = logging.getLogger(__name__)\n \n class LLMClient:\n-    def __init__(self, api_key=None, **kwargs):\n-        self.api_key = api_key or os.environ.get(\"OPENAI_API_KEY\")\n-        self.kwargs = kwargs\n-        # ...rest of initialization...\n+    _stub_warned = False\n+\n+    def __init__(self, api_key=None, **kwargs):\n+        self.api_key = api_key or os.environ.get(\"OPENAI_API_KEY\")\n+        self.kwargs = kwargs\n+        self.stub = False\n+        if not self.api_key:\n+            self.stub = True\n+            if not LLMClient._stub_warned:\n+                logger.warning(\"No OPENAI_API_KEY found, LLMClient entering stub mode (LLM unavailable).\")\n+                LLMClient._stub_warned = True\n+        # ...rest of initialization...\n+\n+    def call(self, *a, **k):\n+        if self.stub:\n+            return \"LLM unavailable\"\n+        # ... actual call code ...\n+        raise NotImplementedError()\n+\n+    async def acall(self, *a, **k):\n+        if self.stub:\n+            return \"LLM unavailable\"\n+        # ... actual async call code ...\n+        raise NotImplementedError()\ndiff --git a/cadence/llm/tests/test_llm_client.py b/cadence/llm/tests/test_llm_client.py\nnew file mode 100644\nindex 0000000..e041a49\n--- /dev/null\n+++ b/cadence/llm/tests/test_llm_client.py\n@@ -0,0 +1,33 @@\n+import os\n+import logging\n+import pytest\n+\n+from cadence.llm.llm_client import LLMClient\n+\n+def test_stub_mode_triggers_on_missing_env(monkeypatch, caplog):\n+    # Remove OPENAI_API_KEY if exists\n+    monkeypatch.delenv(\"OPENAI_API_KEY\", raising=False)\n+    caplog.set_level(logging.WARNING)\n+    cli = LLMClient()\n+    # Should be in stub mode\n+    assert cli.stub is True\n+    # Warns exactly once\n+    wmsgs = [r for r in caplog.records if \"LLMClient entering stub mode\" in r.getMessage()]\n+    assert len(wmsgs) == 1\n+    # call() returns canned msg\n+    assert cli.call(\"whatever\") == \"LLM unavailable\"\n+    # acall returns canned as well\n+    import asyncio\n+    result = asyncio.get_event_loop().run_until_complete(cli.acall(\"blorp\"))\n+    assert result == \"LLM unavailable\"\n+\n+\n+def test_stub_mode_only_warns_once(monkeypatch, caplog):\n+    monkeypatch.delenv(\"OPENAI_API_KEY\", raising=False)\n+    caplog.set_level(logging.WARNING)\n+    cli1 = LLMClient()\n+    cli2 = LLMClient()\n+    assert cli1.stub is True and cli2.stub is True\n+    wmsgs = [r for r in caplog.records if \"LLMClient entering stub mode\" in r.getMessage()]\n+    assert len(wmsgs) == 1\n+\ndiff --git a/requirements.txt b/requirements.txt\nindex fe85e6a..0c1b01f 100644\n--- a/requirements.txt\n+++ b/requirements.txt\n@@ -1,4 +1,5 @@\n filelock\n+pytest-asyncio\n pytest\n requests\n pydantic",
    "patch": "diff --git a/cadence/llm/llm_client.py b/cadence/llm/llm_client.py\nindex 192b2b3..dd2a7e6 100644\n--- a/cadence/llm/llm_client.py\n+++ b/cadence/llm/llm_client.py\n@@ -1,6 +1,26 @@\n import os\n import logging\n+import asyncio\n \n logger = logging.getLogger(__name__)\n \n class LLMClient:\n-    def __init__(self, api_key=None, **kwargs):\n-        self.api_key = api_key or os.environ.get(\"OPENAI_API_KEY\")\n-        self.kwargs = kwargs\n-        # ...rest of initialization...\n+    _stub_warned = False\n+\n+    def __init__(self, api_key=None, **kwargs):\n+        self.api_key = api_key or os.environ.get(\"OPENAI_API_KEY\")\n+        self.kwargs = kwargs\n+        self.stub = False\n+        if not self.api_key:\n+            self.stub = True\n+            if not LLMClient._stub_warned:\n+                logger.warning(\"No OPENAI_API_KEY found, LLMClient entering stub mode (LLM unavailable).\")\n+                LLMClient._stub_warned = True\n+        # ...rest of initialization...\n+\n+    def call(self, *a, **k):\n+        if self.stub:\n+            return \"LLM unavailable\"\n+        # ... actual call code ...\n+        raise NotImplementedError()\n+\n+    async def acall(self, *a, **k):\n+        if self.stub:\n+            return \"LLM unavailable\"\n+        # ... actual async call code ...\n+        raise NotImplementedError()\ndiff --git a/cadence/llm/tests/test_llm_client.py b/cadence/llm/tests/test_llm_client.py\nnew file mode 100644\nindex 0000000..e041a49\n--- /dev/null\n+++ b/cadence/llm/tests/test_llm_client.py\n@@ -0,0 +1,33 @@\n+import os\n+import logging\n+import pytest\n+\n+from cadence.llm.llm_client import LLMClient\n+\n+def test_stub_mode_triggers_on_missing_env(monkeypatch, caplog):\n+    # Remove OPENAI_API_KEY if exists\n+    monkeypatch.delenv(\"OPENAI_API_KEY\", raising=False)\n+    caplog.set_level(logging.WARNING)\n+    cli = LLMClient()\n+    # Should be in stub mode\n+    assert cli.stub is True\n+    # Warns exactly once\n+    wmsgs = [r for r in caplog.records if \"LLMClient entering stub mode\" in r.getMessage()]\n+    assert len(wmsgs) == 1\n+    # call() returns canned msg\n+    assert cli.call(\"whatever\") == \"LLM unavailable\"\n+    # acall returns canned as well\n+    import asyncio\n+    result = asyncio.get_event_loop().run_until_complete(cli.acall(\"blorp\"))\n+    assert result == \"LLM unavailable\"\n+\n+\n+def test_stub_mode_only_warns_once(monkeypatch, caplog):\n+    monkeypatch.delenv(\"OPENAI_API_KEY\", raising=False)\n+    caplog.set_level(logging.WARNING)\n+    cli1 = LLMClient()\n+    cli2 = LLMClient()\n+    assert cli1.stub is True and cli2.stub is True\n+    wmsgs = [r for r in caplog.records if \"LLMClient entering stub mode\" in r.getMessage()]\n+    assert len(wmsgs) == 1\n+\ndiff --git a/requirements.txt b/requirements.txt\nindex fe85e6a..0c1b01f 100644\n--- a/requirements.txt\n+++ b/requirements.txt\n@@ -1,4 +1,5 @@\n filelock\n+pytest-asyncio\n pytest\n requests\n pydantic"
  }
]