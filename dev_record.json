[
  {
    "task_id": "bug-fix-add-001",
    "created_at": "2025-06-20T21:52:36.761759",
    "history": [
      {
        "state": "build_patch",
        "timestamp": "2025-06-20T21:52:36.761766",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    return x + y\\n"
          }
        },
        "extra": {}
      },
      {
        "state": "patch_built",
        "timestamp": "2025-06-20T21:52:36.761923",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    return x + y\\n"
          }
        },
        "extra": {
          "patch": "--- a/cadence/utils/add.py\n+++ b/cadence/utils/add.py\n@@ -1 +1 @@\n-def add(x: int, y: int) -> int:\\n    return x - 1 + y\\n\n+def add(x: int, y: int) -> int:\\n    return x + y\\n\n"
        }
      },
      {
        "state": "patch_reviewed",
        "timestamp": "2025-06-20T21:52:36.762137",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    return x + y\\n"
          }
        },
        "extra": {
          "review": {
            "pass": true,
            "comments": ""
          }
        }
      },
      {
        "state": "build_patch",
        "timestamp": "2025-06-20T21:55:11.177818",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    return x + y\\n"
          }
        },
        "extra": {}
      },
      {
        "state": "patch_built",
        "timestamp": "2025-06-20T21:55:11.178063",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    return x + y\\n"
          }
        },
        "extra": {
          "patch": "--- a/src/cadence/utils/add.py\n+++ b/src/cadence/utils/add.py\n@@ -1 +1 @@\n-def add(x: int, y: int) -> int:\\n    return x - 1 + y\\n\n+def add(x: int, y: int) -> int:\\n    return x + y\\n\n"
        }
      },
      {
        "state": "patch_reviewed",
        "timestamp": "2025-06-20T21:55:11.188615",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    return x + y\\n"
          }
        },
        "extra": {
          "review": {
            "pass": true,
            "comments": ""
          }
        }
      },
      {
        "state": "build_patch",
        "timestamp": "2025-06-20T21:55:36.587853",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    return x + y\\n"
          }
        },
        "extra": {}
      },
      {
        "state": "patch_built",
        "timestamp": "2025-06-20T21:55:36.588143",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    return x + y\\n"
          }
        },
        "extra": {
          "patch": "--- a/src/cadence/utils/add.py\n+++ b/src/cadence/utils/add.py\n@@ -1 +1 @@\n-def add(x: int, y: int) -> int:\\n    return x - 1 + y\\n\n+def add(x: int, y: int) -> int:\\n    return x + y\\n\n"
        }
      },
      {
        "state": "patch_reviewed",
        "timestamp": "2025-06-20T21:55:36.598634",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    return x + y\\n"
          }
        },
        "extra": {
          "review": {
            "pass": true,
            "comments": ""
          }
        }
      },
      {
        "state": "build_patch",
        "timestamp": "2025-06-20T22:02:10.188189",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x + y\\n"
          }
        },
        "extra": {}
      },
      {
        "state": "patch_built",
        "timestamp": "2025-06-20T22:02:10.189080",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x + y\\n"
          }
        },
        "extra": {
          "patch": "--- a/src/cadence/utils/add.py\n+++ b/src/cadence/utils/add.py\n@@ -1 +1 @@\n-def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x - 1 + y\\n\n+def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x + y\\n\n"
        }
      },
      {
        "state": "patch_reviewed",
        "timestamp": "2025-06-20T22:02:10.189362",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x + y\\n"
          }
        },
        "extra": {
          "review": {
            "pass": true,
            "comments": ""
          }
        }
      },
      {
        "state": "build_patch",
        "timestamp": "2025-06-20T22:03:11.993539",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x + y\\n"
          }
        },
        "extra": {}
      },
      {
        "state": "patch_built",
        "timestamp": "2025-06-20T22:03:11.994096",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x + y\\n"
          }
        },
        "extra": {
          "patch": "--- a/src/cadence/utils/add.py\n+++ b/src/cadence/utils/add.py\n@@ -1 +1 @@\n-def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x - 1 + y\\n\n+def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x + y\\n\n"
        }
      },
      {
        "state": "patch_reviewed",
        "timestamp": "2025-06-20T22:03:12.005239",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x + y\\n"
          }
        },
        "extra": {
          "review": {
            "pass": true,
            "comments": ""
          }
        }
      },
      {
        "state": "build_patch",
        "timestamp": "2025-06-20T22:03:57.311713",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x + y\\n"
          }
        },
        "extra": {}
      },
      {
        "state": "patch_built",
        "timestamp": "2025-06-20T22:03:57.312115",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x + y\\n"
          }
        },
        "extra": {
          "patch": "--- a/src/cadence/utils/add.py\n+++ b/src/cadence/utils/add.py\n@@ -1 +1 @@\n-def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x - 1 + y\\n\n+def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x + y\\n\n"
        }
      },
      {
        "state": "patch_reviewed",
        "timestamp": "2025-06-20T22:03:57.312699",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x - 1 + y\\n",
            "after": "def add(x: int, y: int) -> int:\\n    \\\"\\\"\\\"Intentionally wrong implementation for MVP red\u2192green demo.\\\"\\\"\\\"\\n    return x + y\\n"
          }
        },
        "extra": {
          "review": {
            "pass": true,
            "comments": ""
          }
        }
      },
      {
        "state": "build_patch",
        "timestamp": "2025-06-20T22:06:21.022518",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\n    \"\"\"Intentionally wrong implementation for MVP red\u2192green demo.\"\"\"\n    return x - 1 + y\n",
            "after": "def add(x: int, y: int) -> int:\n    \"\"\"Intentionally wrong implementation for MVP red\u2192green demo.\"\"\"\n    return x + y\n"
          }
        },
        "extra": {}
      },
      {
        "state": "patch_built",
        "timestamp": "2025-06-20T22:06:21.022938",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\n    \"\"\"Intentionally wrong implementation for MVP red\u2192green demo.\"\"\"\n    return x - 1 + y\n",
            "after": "def add(x: int, y: int) -> int:\n    \"\"\"Intentionally wrong implementation for MVP red\u2192green demo.\"\"\"\n    return x + y\n"
          }
        },
        "extra": {
          "patch": "--- a/src/cadence/utils/add.py\n+++ b/src/cadence/utils/add.py\n@@ -1,3 +1,3 @@\n def add(x: int, y: int) -> int:\n     \"\"\"Intentionally wrong implementation for MVP red\u2192green demo.\"\"\"\n-    return x - 1 + y\n+    return x + y\n"
        }
      },
      {
        "state": "patch_reviewed",
        "timestamp": "2025-06-20T22:06:21.033349",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\n    \"\"\"Intentionally wrong implementation for MVP red\u2192green demo.\"\"\"\n    return x - 1 + y\n",
            "after": "def add(x: int, y: int) -> int:\n    \"\"\"Intentionally wrong implementation for MVP red\u2192green demo.\"\"\"\n    return x + y\n"
          }
        },
        "extra": {
          "review": {
            "pass": true,
            "comments": ""
          }
        }
      },
      {
        "state": "patch_applied",
        "timestamp": "2025-06-20T22:06:21.034925",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\n    \"\"\"Intentionally wrong implementation for MVP red\u2192green demo.\"\"\"\n    return x - 1 + y\n",
            "after": "def add(x: int, y: int) -> int:\n    \"\"\"Intentionally wrong implementation for MVP red\u2192green demo.\"\"\"\n    return x + y\n"
          }
        },
        "extra": {}
      },
      {
        "state": "pytest_run",
        "timestamp": "2025-06-20T22:06:21.219907",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\n    \"\"\"Intentionally wrong implementation for MVP red\u2192green demo.\"\"\"\n    return x - 1 + y\n",
            "after": "def add(x: int, y: int) -> int:\n    \"\"\"Intentionally wrong implementation for MVP red\u2192green demo.\"\"\"\n    return x + y\n"
          }
        },
        "extra": {
          "pytest": {
            "success": true,
            "output": ".                                                                        [100%]\n1 passed in 0.00s"
          }
        }
      },
      {
        "state": "committed",
        "timestamp": "2025-06-20T22:06:21.263065",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "open",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\n    \"\"\"Intentionally wrong implementation for MVP red\u2192green demo.\"\"\"\n    return x - 1 + y\n",
            "after": "def add(x: int, y: int) -> int:\n    \"\"\"Intentionally wrong implementation for MVP red\u2192green demo.\"\"\"\n    return x + y\n"
          }
        },
        "extra": {
          "commit_sha": "7649f3a1d1cedb2ecc4dbc528b471431c3467a87"
        }
      },
      {
        "state": "archived",
        "timestamp": "2025-06-20T22:06:21.263745",
        "task": {
          "id": "bug-fix-add-001",
          "title": "Fix utils.add.add() so that add(2,3)==5",
          "type": "micro",
          "status": "archived",
          "created_at": "2025-06-21T00:00:00Z",
          "diff": {
            "file": "src/cadence/utils/add.py",
            "before": "def add(x: int, y: int) -> int:\n    \"\"\"Intentionally wrong implementation for MVP red\u2192green demo.\"\"\"\n    return x - 1 + y\n",
            "after": "def add(x: int, y: int) -> int:\n    \"\"\"Intentionally wrong implementation for MVP red\u2192green demo.\"\"\"\n    return x + y\n"
          }
        },
        "extra": {}
      }
    ],
    "iterations": []
  },
  {
    "task_id": "ba002f7b-742f-4dce-911f-175c455bd673",
    "created_at": "2025-06-22T00:00:35.554557+00:00",
    "history": [
      {
        "state": "build_patch",
        "timestamp": "2025-06-22T00:00:35.554566+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "diff": {
            "file": "<TBD>",
            "before": "",
            "after": ""
          },
          "generated_patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e8be57..8e85f70 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -1,7 +1,10 @@\n import logging\n+from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n+from cadence.backlog.manager import BacklogManager\n+from cadence.tasks.generator import TaskGenerator\n \n logger = logging.getLogger(__name__)\n \n@@ -29,10 +32,54 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self.backlog: BacklogManager  # type: ignore[attr-defined]\n+        self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n+        # backlog_autoreplenish_count may be set by CLI/global env\n+        self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n \n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n+            new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            snapshot(\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks}\n+            )\n+            logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n+        else:\n+            logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+        raise NotImplementedError()\n \n+\ndiff --git a/cadence/cli.py b/cadence/cli.py\nindex 92bc3fc..3ef930f 100644\n--- a/cadence/cli.py\n+++ b/cadence/cli.py\n@@ -64,6 +64,12 @@ def main():\n+    parser.add_argument(\n+        \"--backlog-autoreplenish-count\",\n+        type=int,\n+        default=3,\n+        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\"\n+    )\n@@ -131,6 +137,9 @@ def main():\n     if \"dev-orchestrator\" in args.orchestrator:\n         from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n         orchestrator = DevOrchestrator(\n             *orchestrator_args,\n             **orchestrator_kwargs,\n         )\n+        if hasattr(args, \"backlog_autoreplenish_count\"):\n+            orchestrator.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n@@ -155,6 +164,7 @@ def main():\n     try:\n         orchestrator.run_task_cycle(\n             interactive=args.interactive,\n         )\n     except RuntimeError as exc:\n         if \"No tasks exist\" in str(exc):\n-            print(\"ERROR: No tasks available.\", file=sys.stderr)\n+            print(\"ERROR: No tasks available.\", file=sys.stderr)\n         raise\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nnew file mode 100644\nindex 0000000..96b5837\n--- /dev/null\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -0,0 +1,54 @@\n+import tempfile\n+import shutil\n+import os\n+import pytest\n+\n+from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n+\n+class DummyTask:\n+    def __init__(self, desc):\n+        self.description = desc\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [i for i in self._items if getattr(i, \"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(task)\n+\n+class DummyTaskGen:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        return [DummyTask(f\"TASK-{i+1}\") for i in range(count)]\n+\n+\n+class DummySnapshotCtx:\n+    \"\"\"\n+    For monkeypatching the snapshot function used by ._ensure_backlog\n+    \"\"\"\n+    def __init__(self):\n+        self.calls = []\n+    def __call__(self, state, extra):\n+        self.calls.append((state, dict(extra)))\n+\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    # Patch out snapshot\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 3\n+    # Pre-condition: empty backlog\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    # Should auto-populate with 3 tasks, and snapshot\n+    orch._ensure_backlog()\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == 3\n+    assert snapctx.calls[-1][0] == \"backlog_replenished\"\n+    assert snapctx.calls[-1][1][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"count\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, count):\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 9  # should be overridden by param\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(count)\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == count\n+    assert snapctx.calls[-1][1][\"count\"] == count"
        },
        "extra": {}
      },
      {
        "state": "failed_build_patch",
        "timestamp": "2025-06-22T00:00:35.555785+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "diff": {
            "file": "<TBD>",
            "before": "",
            "after": ""
          },
          "generated_patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e8be57..8e85f70 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -1,7 +1,10 @@\n import logging\n+from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n+from cadence.backlog.manager import BacklogManager\n+from cadence.tasks.generator import TaskGenerator\n \n logger = logging.getLogger(__name__)\n \n@@ -29,10 +32,54 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self.backlog: BacklogManager  # type: ignore[attr-defined]\n+        self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n+        # backlog_autoreplenish_count may be set by CLI/global env\n+        self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n \n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n+            new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            snapshot(\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks}\n+            )\n+            logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n+        else:\n+            logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+        raise NotImplementedError()\n \n+\ndiff --git a/cadence/cli.py b/cadence/cli.py\nindex 92bc3fc..3ef930f 100644\n--- a/cadence/cli.py\n+++ b/cadence/cli.py\n@@ -64,6 +64,12 @@ def main():\n+    parser.add_argument(\n+        \"--backlog-autoreplenish-count\",\n+        type=int,\n+        default=3,\n+        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\"\n+    )\n@@ -131,6 +137,9 @@ def main():\n     if \"dev-orchestrator\" in args.orchestrator:\n         from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n         orchestrator = DevOrchestrator(\n             *orchestrator_args,\n             **orchestrator_kwargs,\n         )\n+        if hasattr(args, \"backlog_autoreplenish_count\"):\n+            orchestrator.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n@@ -155,6 +164,7 @@ def main():\n     try:\n         orchestrator.run_task_cycle(\n             interactive=args.interactive,\n         )\n     except RuntimeError as exc:\n         if \"No tasks exist\" in str(exc):\n-            print(\"ERROR: No tasks available.\", file=sys.stderr)\n+            print(\"ERROR: No tasks available.\", file=sys.stderr)\n         raise\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nnew file mode 100644\nindex 0000000..96b5837\n--- /dev/null\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -0,0 +1,54 @@\n+import tempfile\n+import shutil\n+import os\n+import pytest\n+\n+from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n+\n+class DummyTask:\n+    def __init__(self, desc):\n+        self.description = desc\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [i for i in self._items if getattr(i, \"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(task)\n+\n+class DummyTaskGen:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        return [DummyTask(f\"TASK-{i+1}\") for i in range(count)]\n+\n+\n+class DummySnapshotCtx:\n+    \"\"\"\n+    For monkeypatching the snapshot function used by ._ensure_backlog\n+    \"\"\"\n+    def __init__(self):\n+        self.calls = []\n+    def __call__(self, state, extra):\n+        self.calls.append((state, dict(extra)))\n+\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    # Patch out snapshot\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 3\n+    # Pre-condition: empty backlog\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    # Should auto-populate with 3 tasks, and snapshot\n+    orch._ensure_backlog()\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == 3\n+    assert snapctx.calls[-1][0] == \"backlog_replenished\"\n+    assert snapctx.calls[-1][1][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"count\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, count):\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 9  # should be overridden by param\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(count)\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == count\n+    assert snapctx.calls[-1][1][\"count\"] == count"
        },
        "extra": {
          "error": "Failed to build patch: Generated patch is empty."
        }
      },
      {
        "state": "build_patch",
        "timestamp": "2025-06-22T03:39:36.749612+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "diff": {
            "file": "<TBD>",
            "before": "",
            "after": ""
          },
          "generated_patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e8be57..8e85f70 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -1,7 +1,10 @@\n import logging\n+from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n+from cadence.backlog.manager import BacklogManager\n+from cadence.tasks.generator import TaskGenerator\n \n logger = logging.getLogger(__name__)\n \n@@ -29,10 +32,54 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self.backlog: BacklogManager  # type: ignore[attr-defined]\n+        self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n+        # backlog_autoreplenish_count may be set by CLI/global env\n+        self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n \n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n+            new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            snapshot(\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks}\n+            )\n+            logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n+        else:\n+            logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+        raise NotImplementedError()\n \n+\ndiff --git a/cadence/cli.py b/cadence/cli.py\nindex 92bc3fc..3ef930f 100644\n--- a/cadence/cli.py\n+++ b/cadence/cli.py\n@@ -64,6 +64,12 @@ def main():\n+    parser.add_argument(\n+        \"--backlog-autoreplenish-count\",\n+        type=int,\n+        default=3,\n+        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\"\n+    )\n@@ -131,6 +137,9 @@ def main():\n     if \"dev-orchestrator\" in args.orchestrator:\n         from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n         orchestrator = DevOrchestrator(\n             *orchestrator_args,\n             **orchestrator_kwargs,\n         )\n+        if hasattr(args, \"backlog_autoreplenish_count\"):\n+            orchestrator.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n@@ -155,6 +164,7 @@ def main():\n     try:\n         orchestrator.run_task_cycle(\n             interactive=args.interactive,\n         )\n     except RuntimeError as exc:\n         if \"No tasks exist\" in str(exc):\n-            print(\"ERROR: No tasks available.\", file=sys.stderr)\n+            print(\"ERROR: No tasks available.\", file=sys.stderr)\n         raise\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nnew file mode 100644\nindex 0000000..96b5837\n--- /dev/null\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -0,0 +1,54 @@\n+import tempfile\n+import shutil\n+import os\n+import pytest\n+\n+from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n+\n+class DummyTask:\n+    def __init__(self, desc):\n+        self.description = desc\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [i for i in self._items if getattr(i, \"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(task)\n+\n+class DummyTaskGen:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        return [DummyTask(f\"TASK-{i+1}\") for i in range(count)]\n+\n+\n+class DummySnapshotCtx:\n+    \"\"\"\n+    For monkeypatching the snapshot function used by ._ensure_backlog\n+    \"\"\"\n+    def __init__(self):\n+        self.calls = []\n+    def __call__(self, state, extra):\n+        self.calls.append((state, dict(extra)))\n+\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    # Patch out snapshot\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 3\n+    # Pre-condition: empty backlog\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    # Should auto-populate with 3 tasks, and snapshot\n+    orch._ensure_backlog()\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == 3\n+    assert snapctx.calls[-1][0] == \"backlog_replenished\"\n+    assert snapctx.calls[-1][1][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"count\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, count):\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 9  # should be overridden by param\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(count)\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == count\n+    assert snapctx.calls[-1][1][\"count\"] == count",
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -1,6 +1,8 @@\n-# src/cadence/dev/orchestrator.py\n+# src/cadence/dev/orchestrator.py\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n Now wires ShellRunner with TaskRecord and attaches the *current* task\n before any shell operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n \n from .backlog import BacklogManager\n from .generator import TaskGenerator\n from .executor import TaskExecutor, PatchBuildError\n from .reviewer import TaskReviewer\n from .shell import ShellRunner, ShellCommandError\n from .record import TaskRecord, TaskRecordError\n-\n-import sys\n-from typing import Any, Dict\n+import sys\n+from typing import Any, Dict, Optional\n@@ class DevOrchestrator:\n     def __init__(self, config: dict):\n         self.backlog = BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n         # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n+        # For auto-replenish count, allow config or default to 3\n+        self.backlog_autoreplenish_count: int = config.get(\"backlog_autoreplenish_count\", 3)\n+\n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            # Generate microtasks\n+            new_tasks = self.generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            # Record snapshot of replenishment\n+            self._record(\n+                {\"id\": \"autoreplenish\", \"title\": \"Auto-backlog replenish\"},  # Dummy, for audit\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks},\n+            )\n+        # else: already open tasks, do nothing\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n     # ------------------------------------------------------------------ #\n     def _record(self, task: dict, state: str, extra: Dict[str, Any] | None = None) -> None:\n         try:\n             self.record.save(task, state=state, extra=extra or {})\n         except TaskRecordError as e:\n             print(f\"[Record-Error] {e}\", file=sys.stderr)\n@@ class DevOrchestrator:\n-    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n-        \"\"\"\n-        End-to-end flow for ONE micro-task with auto-rollback on failure.\n-        \"\"\"\n-        rollback_patch: str | None = None\n-        task: dict | None = None\n-\n-        try:\n-            # 1. Select Task --------------------------------------------------\n-            open_tasks = self.backlog.list_items(status=\"open\")\n-            if not open_tasks:\n-                raise RuntimeError(\"No open tasks in backlog.\")\n+    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n+        \"\"\"\n+        End-to-end flow for ONE micro-task with auto-rollback on failure.\n+        \"\"\"\n+        # At the very top, auto-replenish backlog if empty\n+        self._ensure_backlog()\n+        rollback_patch: str | None = None\n+        task: dict | None = None\n+\n+        try:\n+            # 1. Select Task --------------------------------------------------\n+            open_tasks = self.backlog.list_items(status=\"open\")\n+            if not open_tasks:\n+                raise RuntimeError(\"No open tasks in backlog.\")\n@@ class DevOrchestrator:\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n     CONFIG = dict(\n         backlog_path=\"dev_backlog.json\",\n         template_file=\"dev_templates.json\",\n         src_root=\"cadence\",\n         ruleset_file=None,\n         repo_dir=\".\",\n         record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=3,\n     )\n     orch = DevOrchestrator(CONFIG)\n \n     import argparse\n \n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n+    parser.add_argument(\"--backlog-autoreplenish-count\", type=int, default=3,\n+                        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\")\n     args = parser.parse_args()\n-\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n+    orch.backlog_autoreplenish_count = getattr(args, \"backlog_autoreplenish_count\", 3)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n@@\n+# --------------------------------------------------------------------------- #\n+# TEST: test_orchestrator_auto_replenishment.py\n+# --------------------------------------------------------------------------- #\n+import pytest\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [t for t in self._items if t.get(\"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(dict(task))\n+\n+class DummyTaskGenerator:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        # Simple tasks with id/title\n+        return [{\"id\": f\"t{i+1}\", \"title\": f\"task-{i+1}\", \"type\": \"micro\", \"status\": \"open\", \"created_at\": \"now\"} for i in range(count)]\n+\n+class DummyRecord:\n+    def __init__(self):\n+        self.snaps = []\n+    def save(self, task, state, extra=None):\n+        self.snaps.append((task, state, dict(extra) if extra else {}))\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 3\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    # Pre-condition: empty\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog()\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == 3\n+    snap = orch.record.snaps[-1]\n+    assert snap[1] == \"backlog_replenished\"\n+    assert snap[2][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"n\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, n):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 9  # will be overridden\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(n)\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == n\n+    snap = orch.record.snaps[-1]\n+    assert snap[2][\"count\"] == n"
        },
        "extra": {}
      },
      {
        "state": "patch_built",
        "timestamp": "2025-06-22T03:39:36.750344+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "diff": {
            "file": "<TBD>",
            "before": "",
            "after": ""
          },
          "generated_patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e8be57..8e85f70 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -1,7 +1,10 @@\n import logging\n+from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n+from cadence.backlog.manager import BacklogManager\n+from cadence.tasks.generator import TaskGenerator\n \n logger = logging.getLogger(__name__)\n \n@@ -29,10 +32,54 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self.backlog: BacklogManager  # type: ignore[attr-defined]\n+        self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n+        # backlog_autoreplenish_count may be set by CLI/global env\n+        self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n \n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n+            new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            snapshot(\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks}\n+            )\n+            logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n+        else:\n+            logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+        raise NotImplementedError()\n \n+\ndiff --git a/cadence/cli.py b/cadence/cli.py\nindex 92bc3fc..3ef930f 100644\n--- a/cadence/cli.py\n+++ b/cadence/cli.py\n@@ -64,6 +64,12 @@ def main():\n+    parser.add_argument(\n+        \"--backlog-autoreplenish-count\",\n+        type=int,\n+        default=3,\n+        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\"\n+    )\n@@ -131,6 +137,9 @@ def main():\n     if \"dev-orchestrator\" in args.orchestrator:\n         from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n         orchestrator = DevOrchestrator(\n             *orchestrator_args,\n             **orchestrator_kwargs,\n         )\n+        if hasattr(args, \"backlog_autoreplenish_count\"):\n+            orchestrator.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n@@ -155,6 +164,7 @@ def main():\n     try:\n         orchestrator.run_task_cycle(\n             interactive=args.interactive,\n         )\n     except RuntimeError as exc:\n         if \"No tasks exist\" in str(exc):\n-            print(\"ERROR: No tasks available.\", file=sys.stderr)\n+            print(\"ERROR: No tasks available.\", file=sys.stderr)\n         raise\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nnew file mode 100644\nindex 0000000..96b5837\n--- /dev/null\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -0,0 +1,54 @@\n+import tempfile\n+import shutil\n+import os\n+import pytest\n+\n+from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n+\n+class DummyTask:\n+    def __init__(self, desc):\n+        self.description = desc\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [i for i in self._items if getattr(i, \"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(task)\n+\n+class DummyTaskGen:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        return [DummyTask(f\"TASK-{i+1}\") for i in range(count)]\n+\n+\n+class DummySnapshotCtx:\n+    \"\"\"\n+    For monkeypatching the snapshot function used by ._ensure_backlog\n+    \"\"\"\n+    def __init__(self):\n+        self.calls = []\n+    def __call__(self, state, extra):\n+        self.calls.append((state, dict(extra)))\n+\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    # Patch out snapshot\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 3\n+    # Pre-condition: empty backlog\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    # Should auto-populate with 3 tasks, and snapshot\n+    orch._ensure_backlog()\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == 3\n+    assert snapctx.calls[-1][0] == \"backlog_replenished\"\n+    assert snapctx.calls[-1][1][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"count\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, count):\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 9  # should be overridden by param\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(count)\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == count\n+    assert snapctx.calls[-1][1][\"count\"] == count",
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -1,6 +1,8 @@\n-# src/cadence/dev/orchestrator.py\n+# src/cadence/dev/orchestrator.py\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n Now wires ShellRunner with TaskRecord and attaches the *current* task\n before any shell operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n \n from .backlog import BacklogManager\n from .generator import TaskGenerator\n from .executor import TaskExecutor, PatchBuildError\n from .reviewer import TaskReviewer\n from .shell import ShellRunner, ShellCommandError\n from .record import TaskRecord, TaskRecordError\n-\n-import sys\n-from typing import Any, Dict\n+import sys\n+from typing import Any, Dict, Optional\n@@ class DevOrchestrator:\n     def __init__(self, config: dict):\n         self.backlog = BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n         # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n+        # For auto-replenish count, allow config or default to 3\n+        self.backlog_autoreplenish_count: int = config.get(\"backlog_autoreplenish_count\", 3)\n+\n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            # Generate microtasks\n+            new_tasks = self.generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            # Record snapshot of replenishment\n+            self._record(\n+                {\"id\": \"autoreplenish\", \"title\": \"Auto-backlog replenish\"},  # Dummy, for audit\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks},\n+            )\n+        # else: already open tasks, do nothing\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n     # ------------------------------------------------------------------ #\n     def _record(self, task: dict, state: str, extra: Dict[str, Any] | None = None) -> None:\n         try:\n             self.record.save(task, state=state, extra=extra or {})\n         except TaskRecordError as e:\n             print(f\"[Record-Error] {e}\", file=sys.stderr)\n@@ class DevOrchestrator:\n-    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n-        \"\"\"\n-        End-to-end flow for ONE micro-task with auto-rollback on failure.\n-        \"\"\"\n-        rollback_patch: str | None = None\n-        task: dict | None = None\n-\n-        try:\n-            # 1. Select Task --------------------------------------------------\n-            open_tasks = self.backlog.list_items(status=\"open\")\n-            if not open_tasks:\n-                raise RuntimeError(\"No open tasks in backlog.\")\n+    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n+        \"\"\"\n+        End-to-end flow for ONE micro-task with auto-rollback on failure.\n+        \"\"\"\n+        # At the very top, auto-replenish backlog if empty\n+        self._ensure_backlog()\n+        rollback_patch: str | None = None\n+        task: dict | None = None\n+\n+        try:\n+            # 1. Select Task --------------------------------------------------\n+            open_tasks = self.backlog.list_items(status=\"open\")\n+            if not open_tasks:\n+                raise RuntimeError(\"No open tasks in backlog.\")\n@@ class DevOrchestrator:\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n     CONFIG = dict(\n         backlog_path=\"dev_backlog.json\",\n         template_file=\"dev_templates.json\",\n         src_root=\"cadence\",\n         ruleset_file=None,\n         repo_dir=\".\",\n         record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=3,\n     )\n     orch = DevOrchestrator(CONFIG)\n \n     import argparse\n \n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n+    parser.add_argument(\"--backlog-autoreplenish-count\", type=int, default=3,\n+                        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\")\n     args = parser.parse_args()\n-\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n+    orch.backlog_autoreplenish_count = getattr(args, \"backlog_autoreplenish_count\", 3)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n@@\n+# --------------------------------------------------------------------------- #\n+# TEST: test_orchestrator_auto_replenishment.py\n+# --------------------------------------------------------------------------- #\n+import pytest\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [t for t in self._items if t.get(\"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(dict(task))\n+\n+class DummyTaskGenerator:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        # Simple tasks with id/title\n+        return [{\"id\": f\"t{i+1}\", \"title\": f\"task-{i+1}\", \"type\": \"micro\", \"status\": \"open\", \"created_at\": \"now\"} for i in range(count)]\n+\n+class DummyRecord:\n+    def __init__(self):\n+        self.snaps = []\n+    def save(self, task, state, extra=None):\n+        self.snaps.append((task, state, dict(extra) if extra else {}))\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 3\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    # Pre-condition: empty\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog()\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == 3\n+    snap = orch.record.snaps[-1]\n+    assert snap[1] == \"backlog_replenished\"\n+    assert snap[2][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"n\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, n):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 9  # will be overridden\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(n)\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == n\n+    snap = orch.record.snaps[-1]\n+    assert snap[2][\"count\"] == n"
        },
        "extra": {
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -1,6 +1,8 @@\n-# src/cadence/dev/orchestrator.py\n+# src/cadence/dev/orchestrator.py\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n Now wires ShellRunner with TaskRecord and attaches the *current* task\n before any shell operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n \n from .backlog import BacklogManager\n from .generator import TaskGenerator\n from .executor import TaskExecutor, PatchBuildError\n from .reviewer import TaskReviewer\n from .shell import ShellRunner, ShellCommandError\n from .record import TaskRecord, TaskRecordError\n-\n-import sys\n-from typing import Any, Dict\n+import sys\n+from typing import Any, Dict, Optional\n@@ class DevOrchestrator:\n     def __init__(self, config: dict):\n         self.backlog = BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n         # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n+        # For auto-replenish count, allow config or default to 3\n+        self.backlog_autoreplenish_count: int = config.get(\"backlog_autoreplenish_count\", 3)\n+\n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            # Generate microtasks\n+            new_tasks = self.generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            # Record snapshot of replenishment\n+            self._record(\n+                {\"id\": \"autoreplenish\", \"title\": \"Auto-backlog replenish\"},  # Dummy, for audit\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks},\n+            )\n+        # else: already open tasks, do nothing\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n     # ------------------------------------------------------------------ #\n     def _record(self, task: dict, state: str, extra: Dict[str, Any] | None = None) -> None:\n         try:\n             self.record.save(task, state=state, extra=extra or {})\n         except TaskRecordError as e:\n             print(f\"[Record-Error] {e}\", file=sys.stderr)\n@@ class DevOrchestrator:\n-    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n-        \"\"\"\n-        End-to-end flow for ONE micro-task with auto-rollback on failure.\n-        \"\"\"\n-        rollback_patch: str | None = None\n-        task: dict | None = None\n-\n-        try:\n-            # 1. Select Task --------------------------------------------------\n-            open_tasks = self.backlog.list_items(status=\"open\")\n-            if not open_tasks:\n-                raise RuntimeError(\"No open tasks in backlog.\")\n+    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n+        \"\"\"\n+        End-to-end flow for ONE micro-task with auto-rollback on failure.\n+        \"\"\"\n+        # At the very top, auto-replenish backlog if empty\n+        self._ensure_backlog()\n+        rollback_patch: str | None = None\n+        task: dict | None = None\n+\n+        try:\n+            # 1. Select Task --------------------------------------------------\n+            open_tasks = self.backlog.list_items(status=\"open\")\n+            if not open_tasks:\n+                raise RuntimeError(\"No open tasks in backlog.\")\n@@ class DevOrchestrator:\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n     CONFIG = dict(\n         backlog_path=\"dev_backlog.json\",\n         template_file=\"dev_templates.json\",\n         src_root=\"cadence\",\n         ruleset_file=None,\n         repo_dir=\".\",\n         record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=3,\n     )\n     orch = DevOrchestrator(CONFIG)\n \n     import argparse\n \n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n+    parser.add_argument(\"--backlog-autoreplenish-count\", type=int, default=3,\n+                        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\")\n     args = parser.parse_args()\n-\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n+    orch.backlog_autoreplenish_count = getattr(args, \"backlog_autoreplenish_count\", 3)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n@@\n+# --------------------------------------------------------------------------- #\n+# TEST: test_orchestrator_auto_replenishment.py\n+# --------------------------------------------------------------------------- #\n+import pytest\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [t for t in self._items if t.get(\"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(dict(task))\n+\n+class DummyTaskGenerator:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        # Simple tasks with id/title\n+        return [{\"id\": f\"t{i+1}\", \"title\": f\"task-{i+1}\", \"type\": \"micro\", \"status\": \"open\", \"created_at\": \"now\"} for i in range(count)]\n+\n+class DummyRecord:\n+    def __init__(self):\n+        self.snaps = []\n+    def save(self, task, state, extra=None):\n+        self.snaps.append((task, state, dict(extra) if extra else {}))\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 3\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    # Pre-condition: empty\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog()\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == 3\n+    snap = orch.record.snaps[-1]\n+    assert snap[1] == \"backlog_replenished\"\n+    assert snap[2][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"n\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, n):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 9  # will be overridden\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(n)\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == n\n+    snap = orch.record.snaps[-1]\n+    assert snap[2][\"count\"] == n\n"
        }
      },
      {
        "state": "patch_reviewed",
        "timestamp": "2025-06-22T03:39:36.751091+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "diff": {
            "file": "<TBD>",
            "before": "",
            "after": ""
          },
          "generated_patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e8be57..8e85f70 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -1,7 +1,10 @@\n import logging\n+from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n+from cadence.backlog.manager import BacklogManager\n+from cadence.tasks.generator import TaskGenerator\n \n logger = logging.getLogger(__name__)\n \n@@ -29,10 +32,54 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self.backlog: BacklogManager  # type: ignore[attr-defined]\n+        self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n+        # backlog_autoreplenish_count may be set by CLI/global env\n+        self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n \n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n+            new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            snapshot(\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks}\n+            )\n+            logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n+        else:\n+            logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+        raise NotImplementedError()\n \n+\ndiff --git a/cadence/cli.py b/cadence/cli.py\nindex 92bc3fc..3ef930f 100644\n--- a/cadence/cli.py\n+++ b/cadence/cli.py\n@@ -64,6 +64,12 @@ def main():\n+    parser.add_argument(\n+        \"--backlog-autoreplenish-count\",\n+        type=int,\n+        default=3,\n+        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\"\n+    )\n@@ -131,6 +137,9 @@ def main():\n     if \"dev-orchestrator\" in args.orchestrator:\n         from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n         orchestrator = DevOrchestrator(\n             *orchestrator_args,\n             **orchestrator_kwargs,\n         )\n+        if hasattr(args, \"backlog_autoreplenish_count\"):\n+            orchestrator.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n@@ -155,6 +164,7 @@ def main():\n     try:\n         orchestrator.run_task_cycle(\n             interactive=args.interactive,\n         )\n     except RuntimeError as exc:\n         if \"No tasks exist\" in str(exc):\n-            print(\"ERROR: No tasks available.\", file=sys.stderr)\n+            print(\"ERROR: No tasks available.\", file=sys.stderr)\n         raise\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nnew file mode 100644\nindex 0000000..96b5837\n--- /dev/null\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -0,0 +1,54 @@\n+import tempfile\n+import shutil\n+import os\n+import pytest\n+\n+from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n+\n+class DummyTask:\n+    def __init__(self, desc):\n+        self.description = desc\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [i for i in self._items if getattr(i, \"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(task)\n+\n+class DummyTaskGen:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        return [DummyTask(f\"TASK-{i+1}\") for i in range(count)]\n+\n+\n+class DummySnapshotCtx:\n+    \"\"\"\n+    For monkeypatching the snapshot function used by ._ensure_backlog\n+    \"\"\"\n+    def __init__(self):\n+        self.calls = []\n+    def __call__(self, state, extra):\n+        self.calls.append((state, dict(extra)))\n+\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    # Patch out snapshot\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 3\n+    # Pre-condition: empty backlog\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    # Should auto-populate with 3 tasks, and snapshot\n+    orch._ensure_backlog()\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == 3\n+    assert snapctx.calls[-1][0] == \"backlog_replenished\"\n+    assert snapctx.calls[-1][1][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"count\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, count):\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 9  # should be overridden by param\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(count)\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == count\n+    assert snapctx.calls[-1][1][\"count\"] == count",
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -1,6 +1,8 @@\n-# src/cadence/dev/orchestrator.py\n+# src/cadence/dev/orchestrator.py\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n Now wires ShellRunner with TaskRecord and attaches the *current* task\n before any shell operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n \n from .backlog import BacklogManager\n from .generator import TaskGenerator\n from .executor import TaskExecutor, PatchBuildError\n from .reviewer import TaskReviewer\n from .shell import ShellRunner, ShellCommandError\n from .record import TaskRecord, TaskRecordError\n-\n-import sys\n-from typing import Any, Dict\n+import sys\n+from typing import Any, Dict, Optional\n@@ class DevOrchestrator:\n     def __init__(self, config: dict):\n         self.backlog = BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n         # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n+        # For auto-replenish count, allow config or default to 3\n+        self.backlog_autoreplenish_count: int = config.get(\"backlog_autoreplenish_count\", 3)\n+\n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            # Generate microtasks\n+            new_tasks = self.generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            # Record snapshot of replenishment\n+            self._record(\n+                {\"id\": \"autoreplenish\", \"title\": \"Auto-backlog replenish\"},  # Dummy, for audit\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks},\n+            )\n+        # else: already open tasks, do nothing\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n     # ------------------------------------------------------------------ #\n     def _record(self, task: dict, state: str, extra: Dict[str, Any] | None = None) -> None:\n         try:\n             self.record.save(task, state=state, extra=extra or {})\n         except TaskRecordError as e:\n             print(f\"[Record-Error] {e}\", file=sys.stderr)\n@@ class DevOrchestrator:\n-    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n-        \"\"\"\n-        End-to-end flow for ONE micro-task with auto-rollback on failure.\n-        \"\"\"\n-        rollback_patch: str | None = None\n-        task: dict | None = None\n-\n-        try:\n-            # 1. Select Task --------------------------------------------------\n-            open_tasks = self.backlog.list_items(status=\"open\")\n-            if not open_tasks:\n-                raise RuntimeError(\"No open tasks in backlog.\")\n+    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n+        \"\"\"\n+        End-to-end flow for ONE micro-task with auto-rollback on failure.\n+        \"\"\"\n+        # At the very top, auto-replenish backlog if empty\n+        self._ensure_backlog()\n+        rollback_patch: str | None = None\n+        task: dict | None = None\n+\n+        try:\n+            # 1. Select Task --------------------------------------------------\n+            open_tasks = self.backlog.list_items(status=\"open\")\n+            if not open_tasks:\n+                raise RuntimeError(\"No open tasks in backlog.\")\n@@ class DevOrchestrator:\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n     CONFIG = dict(\n         backlog_path=\"dev_backlog.json\",\n         template_file=\"dev_templates.json\",\n         src_root=\"cadence\",\n         ruleset_file=None,\n         repo_dir=\".\",\n         record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=3,\n     )\n     orch = DevOrchestrator(CONFIG)\n \n     import argparse\n \n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n+    parser.add_argument(\"--backlog-autoreplenish-count\", type=int, default=3,\n+                        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\")\n     args = parser.parse_args()\n-\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n+    orch.backlog_autoreplenish_count = getattr(args, \"backlog_autoreplenish_count\", 3)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n@@\n+# --------------------------------------------------------------------------- #\n+# TEST: test_orchestrator_auto_replenishment.py\n+# --------------------------------------------------------------------------- #\n+import pytest\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [t for t in self._items if t.get(\"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(dict(task))\n+\n+class DummyTaskGenerator:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        # Simple tasks with id/title\n+        return [{\"id\": f\"t{i+1}\", \"title\": f\"task-{i+1}\", \"type\": \"micro\", \"status\": \"open\", \"created_at\": \"now\"} for i in range(count)]\n+\n+class DummyRecord:\n+    def __init__(self):\n+        self.snaps = []\n+    def save(self, task, state, extra=None):\n+        self.snaps.append((task, state, dict(extra) if extra else {}))\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 3\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    # Pre-condition: empty\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog()\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == 3\n+    snap = orch.record.snaps[-1]\n+    assert snap[1] == \"backlog_replenished\"\n+    assert snap[2][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"n\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, n):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 9  # will be overridden\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(n)\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == n\n+    snap = orch.record.snaps[-1]\n+    assert snap[2][\"count\"] == n"
        },
        "extra": {
          "review": {
            "pass": true,
            "comments": ""
          }
        }
      },
      {
        "state": "failed_git_apply",
        "timestamp": "2025-06-22T03:39:36.761738+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "diff": {
            "file": "<TBD>",
            "before": "",
            "after": ""
          },
          "generated_patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e8be57..8e85f70 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -1,7 +1,10 @@\n import logging\n+from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n+from cadence.backlog.manager import BacklogManager\n+from cadence.tasks.generator import TaskGenerator\n \n logger = logging.getLogger(__name__)\n \n@@ -29,10 +32,54 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self.backlog: BacklogManager  # type: ignore[attr-defined]\n+        self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n+        # backlog_autoreplenish_count may be set by CLI/global env\n+        self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n \n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n+            new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            snapshot(\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks}\n+            )\n+            logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n+        else:\n+            logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+        raise NotImplementedError()\n \n+\ndiff --git a/cadence/cli.py b/cadence/cli.py\nindex 92bc3fc..3ef930f 100644\n--- a/cadence/cli.py\n+++ b/cadence/cli.py\n@@ -64,6 +64,12 @@ def main():\n+    parser.add_argument(\n+        \"--backlog-autoreplenish-count\",\n+        type=int,\n+        default=3,\n+        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\"\n+    )\n@@ -131,6 +137,9 @@ def main():\n     if \"dev-orchestrator\" in args.orchestrator:\n         from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n         orchestrator = DevOrchestrator(\n             *orchestrator_args,\n             **orchestrator_kwargs,\n         )\n+        if hasattr(args, \"backlog_autoreplenish_count\"):\n+            orchestrator.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n@@ -155,6 +164,7 @@ def main():\n     try:\n         orchestrator.run_task_cycle(\n             interactive=args.interactive,\n         )\n     except RuntimeError as exc:\n         if \"No tasks exist\" in str(exc):\n-            print(\"ERROR: No tasks available.\", file=sys.stderr)\n+            print(\"ERROR: No tasks available.\", file=sys.stderr)\n         raise\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nnew file mode 100644\nindex 0000000..96b5837\n--- /dev/null\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -0,0 +1,54 @@\n+import tempfile\n+import shutil\n+import os\n+import pytest\n+\n+from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n+\n+class DummyTask:\n+    def __init__(self, desc):\n+        self.description = desc\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [i for i in self._items if getattr(i, \"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(task)\n+\n+class DummyTaskGen:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        return [DummyTask(f\"TASK-{i+1}\") for i in range(count)]\n+\n+\n+class DummySnapshotCtx:\n+    \"\"\"\n+    For monkeypatching the snapshot function used by ._ensure_backlog\n+    \"\"\"\n+    def __init__(self):\n+        self.calls = []\n+    def __call__(self, state, extra):\n+        self.calls.append((state, dict(extra)))\n+\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    # Patch out snapshot\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 3\n+    # Pre-condition: empty backlog\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    # Should auto-populate with 3 tasks, and snapshot\n+    orch._ensure_backlog()\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == 3\n+    assert snapctx.calls[-1][0] == \"backlog_replenished\"\n+    assert snapctx.calls[-1][1][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"count\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, count):\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 9  # should be overridden by param\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(count)\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == count\n+    assert snapctx.calls[-1][1][\"count\"] == count",
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -1,6 +1,8 @@\n-# src/cadence/dev/orchestrator.py\n+# src/cadence/dev/orchestrator.py\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n Now wires ShellRunner with TaskRecord and attaches the *current* task\n before any shell operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n \n from .backlog import BacklogManager\n from .generator import TaskGenerator\n from .executor import TaskExecutor, PatchBuildError\n from .reviewer import TaskReviewer\n from .shell import ShellRunner, ShellCommandError\n from .record import TaskRecord, TaskRecordError\n-\n-import sys\n-from typing import Any, Dict\n+import sys\n+from typing import Any, Dict, Optional\n@@ class DevOrchestrator:\n     def __init__(self, config: dict):\n         self.backlog = BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n         # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n+        # For auto-replenish count, allow config or default to 3\n+        self.backlog_autoreplenish_count: int = config.get(\"backlog_autoreplenish_count\", 3)\n+\n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            # Generate microtasks\n+            new_tasks = self.generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            # Record snapshot of replenishment\n+            self._record(\n+                {\"id\": \"autoreplenish\", \"title\": \"Auto-backlog replenish\"},  # Dummy, for audit\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks},\n+            )\n+        # else: already open tasks, do nothing\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n     # ------------------------------------------------------------------ #\n     def _record(self, task: dict, state: str, extra: Dict[str, Any] | None = None) -> None:\n         try:\n             self.record.save(task, state=state, extra=extra or {})\n         except TaskRecordError as e:\n             print(f\"[Record-Error] {e}\", file=sys.stderr)\n@@ class DevOrchestrator:\n-    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n-        \"\"\"\n-        End-to-end flow for ONE micro-task with auto-rollback on failure.\n-        \"\"\"\n-        rollback_patch: str | None = None\n-        task: dict | None = None\n-\n-        try:\n-            # 1. Select Task --------------------------------------------------\n-            open_tasks = self.backlog.list_items(status=\"open\")\n-            if not open_tasks:\n-                raise RuntimeError(\"No open tasks in backlog.\")\n+    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n+        \"\"\"\n+        End-to-end flow for ONE micro-task with auto-rollback on failure.\n+        \"\"\"\n+        # At the very top, auto-replenish backlog if empty\n+        self._ensure_backlog()\n+        rollback_patch: str | None = None\n+        task: dict | None = None\n+\n+        try:\n+            # 1. Select Task --------------------------------------------------\n+            open_tasks = self.backlog.list_items(status=\"open\")\n+            if not open_tasks:\n+                raise RuntimeError(\"No open tasks in backlog.\")\n@@ class DevOrchestrator:\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n     CONFIG = dict(\n         backlog_path=\"dev_backlog.json\",\n         template_file=\"dev_templates.json\",\n         src_root=\"cadence\",\n         ruleset_file=None,\n         repo_dir=\".\",\n         record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=3,\n     )\n     orch = DevOrchestrator(CONFIG)\n \n     import argparse\n \n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n+    parser.add_argument(\"--backlog-autoreplenish-count\", type=int, default=3,\n+                        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\")\n     args = parser.parse_args()\n-\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n+    orch.backlog_autoreplenish_count = getattr(args, \"backlog_autoreplenish_count\", 3)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n@@\n+# --------------------------------------------------------------------------- #\n+# TEST: test_orchestrator_auto_replenishment.py\n+# --------------------------------------------------------------------------- #\n+import pytest\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [t for t in self._items if t.get(\"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(dict(task))\n+\n+class DummyTaskGenerator:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        # Simple tasks with id/title\n+        return [{\"id\": f\"t{i+1}\", \"title\": f\"task-{i+1}\", \"type\": \"micro\", \"status\": \"open\", \"created_at\": \"now\"} for i in range(count)]\n+\n+class DummyRecord:\n+    def __init__(self):\n+        self.snaps = []\n+    def save(self, task, state, extra=None):\n+        self.snaps.append((task, state, dict(extra) if extra else {}))\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 3\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    # Pre-condition: empty\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog()\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == 3\n+    snap = orch.record.snaps[-1]\n+    assert snap[1] == \"backlog_replenished\"\n+    assert snap[2][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"n\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, n):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 9  # will be overridden\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(n)\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == n\n+    snap = orch.record.snaps[-1]\n+    assert snap[2][\"count\"] == n"
        },
        "extra": {
          "error": "Patch pre-check failed: error: corrupt patch at line 26",
          "output": "error: corrupt patch at line 26",
          "cmd": "git apply --check /var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpkwnyqtxw.patch"
        }
      },
      {
        "state": "failed_patch_apply",
        "timestamp": "2025-06-22T03:39:36.762750+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "diff": {
            "file": "<TBD>",
            "before": "",
            "after": ""
          },
          "generated_patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e8be57..8e85f70 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -1,7 +1,10 @@\n import logging\n+from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n+from cadence.backlog.manager import BacklogManager\n+from cadence.tasks.generator import TaskGenerator\n \n logger = logging.getLogger(__name__)\n \n@@ -29,10 +32,54 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self.backlog: BacklogManager  # type: ignore[attr-defined]\n+        self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n+        # backlog_autoreplenish_count may be set by CLI/global env\n+        self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n \n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n+            new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            snapshot(\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks}\n+            )\n+            logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n+        else:\n+            logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+        raise NotImplementedError()\n \n+\ndiff --git a/cadence/cli.py b/cadence/cli.py\nindex 92bc3fc..3ef930f 100644\n--- a/cadence/cli.py\n+++ b/cadence/cli.py\n@@ -64,6 +64,12 @@ def main():\n+    parser.add_argument(\n+        \"--backlog-autoreplenish-count\",\n+        type=int,\n+        default=3,\n+        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\"\n+    )\n@@ -131,6 +137,9 @@ def main():\n     if \"dev-orchestrator\" in args.orchestrator:\n         from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n         orchestrator = DevOrchestrator(\n             *orchestrator_args,\n             **orchestrator_kwargs,\n         )\n+        if hasattr(args, \"backlog_autoreplenish_count\"):\n+            orchestrator.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n@@ -155,6 +164,7 @@ def main():\n     try:\n         orchestrator.run_task_cycle(\n             interactive=args.interactive,\n         )\n     except RuntimeError as exc:\n         if \"No tasks exist\" in str(exc):\n-            print(\"ERROR: No tasks available.\", file=sys.stderr)\n+            print(\"ERROR: No tasks available.\", file=sys.stderr)\n         raise\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nnew file mode 100644\nindex 0000000..96b5837\n--- /dev/null\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -0,0 +1,54 @@\n+import tempfile\n+import shutil\n+import os\n+import pytest\n+\n+from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n+\n+class DummyTask:\n+    def __init__(self, desc):\n+        self.description = desc\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [i for i in self._items if getattr(i, \"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(task)\n+\n+class DummyTaskGen:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        return [DummyTask(f\"TASK-{i+1}\") for i in range(count)]\n+\n+\n+class DummySnapshotCtx:\n+    \"\"\"\n+    For monkeypatching the snapshot function used by ._ensure_backlog\n+    \"\"\"\n+    def __init__(self):\n+        self.calls = []\n+    def __call__(self, state, extra):\n+        self.calls.append((state, dict(extra)))\n+\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    # Patch out snapshot\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 3\n+    # Pre-condition: empty backlog\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    # Should auto-populate with 3 tasks, and snapshot\n+    orch._ensure_backlog()\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == 3\n+    assert snapctx.calls[-1][0] == \"backlog_replenished\"\n+    assert snapctx.calls[-1][1][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"count\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, count):\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 9  # should be overridden by param\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(count)\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == count\n+    assert snapctx.calls[-1][1][\"count\"] == count",
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -1,6 +1,8 @@\n-# src/cadence/dev/orchestrator.py\n+# src/cadence/dev/orchestrator.py\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n Now wires ShellRunner with TaskRecord and attaches the *current* task\n before any shell operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n \n from .backlog import BacklogManager\n from .generator import TaskGenerator\n from .executor import TaskExecutor, PatchBuildError\n from .reviewer import TaskReviewer\n from .shell import ShellRunner, ShellCommandError\n from .record import TaskRecord, TaskRecordError\n-\n-import sys\n-from typing import Any, Dict\n+import sys\n+from typing import Any, Dict, Optional\n@@ class DevOrchestrator:\n     def __init__(self, config: dict):\n         self.backlog = BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n         # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n+        # For auto-replenish count, allow config or default to 3\n+        self.backlog_autoreplenish_count: int = config.get(\"backlog_autoreplenish_count\", 3)\n+\n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            # Generate microtasks\n+            new_tasks = self.generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            # Record snapshot of replenishment\n+            self._record(\n+                {\"id\": \"autoreplenish\", \"title\": \"Auto-backlog replenish\"},  # Dummy, for audit\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks},\n+            )\n+        # else: already open tasks, do nothing\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n     # ------------------------------------------------------------------ #\n     def _record(self, task: dict, state: str, extra: Dict[str, Any] | None = None) -> None:\n         try:\n             self.record.save(task, state=state, extra=extra or {})\n         except TaskRecordError as e:\n             print(f\"[Record-Error] {e}\", file=sys.stderr)\n@@ class DevOrchestrator:\n-    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n-        \"\"\"\n-        End-to-end flow for ONE micro-task with auto-rollback on failure.\n-        \"\"\"\n-        rollback_patch: str | None = None\n-        task: dict | None = None\n-\n-        try:\n-            # 1. Select Task --------------------------------------------------\n-            open_tasks = self.backlog.list_items(status=\"open\")\n-            if not open_tasks:\n-                raise RuntimeError(\"No open tasks in backlog.\")\n+    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n+        \"\"\"\n+        End-to-end flow for ONE micro-task with auto-rollback on failure.\n+        \"\"\"\n+        # At the very top, auto-replenish backlog if empty\n+        self._ensure_backlog()\n+        rollback_patch: str | None = None\n+        task: dict | None = None\n+\n+        try:\n+            # 1. Select Task --------------------------------------------------\n+            open_tasks = self.backlog.list_items(status=\"open\")\n+            if not open_tasks:\n+                raise RuntimeError(\"No open tasks in backlog.\")\n@@ class DevOrchestrator:\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n     CONFIG = dict(\n         backlog_path=\"dev_backlog.json\",\n         template_file=\"dev_templates.json\",\n         src_root=\"cadence\",\n         ruleset_file=None,\n         repo_dir=\".\",\n         record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=3,\n     )\n     orch = DevOrchestrator(CONFIG)\n \n     import argparse\n \n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n+    parser.add_argument(\"--backlog-autoreplenish-count\", type=int, default=3,\n+                        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\")\n     args = parser.parse_args()\n-\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n+    orch.backlog_autoreplenish_count = getattr(args, \"backlog_autoreplenish_count\", 3)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n@@\n+# --------------------------------------------------------------------------- #\n+# TEST: test_orchestrator_auto_replenishment.py\n+# --------------------------------------------------------------------------- #\n+import pytest\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [t for t in self._items if t.get(\"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(dict(task))\n+\n+class DummyTaskGenerator:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        # Simple tasks with id/title\n+        return [{\"id\": f\"t{i+1}\", \"title\": f\"task-{i+1}\", \"type\": \"micro\", \"status\": \"open\", \"created_at\": \"now\"} for i in range(count)]\n+\n+class DummyRecord:\n+    def __init__(self):\n+        self.snaps = []\n+    def save(self, task, state, extra=None):\n+        self.snaps.append((task, state, dict(extra) if extra else {}))\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 3\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    # Pre-condition: empty\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog()\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == 3\n+    snap = orch.record.snaps[-1]\n+    assert snap[1] == \"backlog_replenished\"\n+    assert snap[2][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"n\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, n):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 9  # will be overridden\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(n)\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == n\n+    snap = orch.record.snaps[-1]\n+    assert snap[2][\"count\"] == n"
        },
        "extra": {
          "error": "Patch pre-check failed: error: corrupt patch at line 26"
        }
      },
      {
        "state": "build_patch",
        "timestamp": "2025-06-22T04:29:20.205781+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "diff": {
            "file": "<TBD>",
            "before": "",
            "after": ""
          },
          "generated_patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e8be57..8e85f70 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -1,7 +1,10 @@\n import logging\n+from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n+from cadence.backlog.manager import BacklogManager\n+from cadence.tasks.generator import TaskGenerator\n \n logger = logging.getLogger(__name__)\n \n@@ -29,10 +32,54 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self.backlog: BacklogManager  # type: ignore[attr-defined]\n+        self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n+        # backlog_autoreplenish_count may be set by CLI/global env\n+        self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n \n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n+            new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            snapshot(\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks}\n+            )\n+            logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n+        else:\n+            logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+        raise NotImplementedError()\n \n+\ndiff --git a/cadence/cli.py b/cadence/cli.py\nindex 92bc3fc..3ef930f 100644\n--- a/cadence/cli.py\n+++ b/cadence/cli.py\n@@ -64,6 +64,12 @@ def main():\n+    parser.add_argument(\n+        \"--backlog-autoreplenish-count\",\n+        type=int,\n+        default=3,\n+        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\"\n+    )\n@@ -131,6 +137,9 @@ def main():\n     if \"dev-orchestrator\" in args.orchestrator:\n         from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n         orchestrator = DevOrchestrator(\n             *orchestrator_args,\n             **orchestrator_kwargs,\n         )\n+        if hasattr(args, \"backlog_autoreplenish_count\"):\n+            orchestrator.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n@@ -155,6 +164,7 @@ def main():\n     try:\n         orchestrator.run_task_cycle(\n             interactive=args.interactive,\n         )\n     except RuntimeError as exc:\n         if \"No tasks exist\" in str(exc):\n-            print(\"ERROR: No tasks available.\", file=sys.stderr)\n+            print(\"ERROR: No tasks available.\", file=sys.stderr)\n         raise\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nnew file mode 100644\nindex 0000000..96b5837\n--- /dev/null\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -0,0 +1,54 @@\n+import tempfile\n+import shutil\n+import os\n+import pytest\n+\n+from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n+\n+class DummyTask:\n+    def __init__(self, desc):\n+        self.description = desc\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [i for i in self._items if getattr(i, \"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(task)\n+\n+class DummyTaskGen:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        return [DummyTask(f\"TASK-{i+1}\") for i in range(count)]\n+\n+\n+class DummySnapshotCtx:\n+    \"\"\"\n+    For monkeypatching the snapshot function used by ._ensure_backlog\n+    \"\"\"\n+    def __init__(self):\n+        self.calls = []\n+    def __call__(self, state, extra):\n+        self.calls.append((state, dict(extra)))\n+\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    # Patch out snapshot\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 3\n+    # Pre-condition: empty backlog\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    # Should auto-populate with 3 tasks, and snapshot\n+    orch._ensure_backlog()\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == 3\n+    assert snapctx.calls[-1][0] == \"backlog_replenished\"\n+    assert snapctx.calls[-1][1][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"count\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, count):\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 9  # should be overridden by param\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(count)\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == count\n+    assert snapctx.calls[-1][1][\"count\"] == count",
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -1,6 +1,8 @@\n-# src/cadence/dev/orchestrator.py\n+# src/cadence/dev/orchestrator.py\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n Now wires ShellRunner with TaskRecord and attaches the *current* task\n before any shell operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n \n from .backlog import BacklogManager\n from .generator import TaskGenerator\n from .executor import TaskExecutor, PatchBuildError\n from .reviewer import TaskReviewer\n from .shell import ShellRunner, ShellCommandError\n from .record import TaskRecord, TaskRecordError\n-\n-import sys\n-from typing import Any, Dict\n+import sys\n+from typing import Any, Dict, Optional\n@@ class DevOrchestrator:\n     def __init__(self, config: dict):\n         self.backlog = BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n         # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n+        # For auto-replenish count, allow config or default to 3\n+        self.backlog_autoreplenish_count: int = config.get(\"backlog_autoreplenish_count\", 3)\n+\n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            # Generate microtasks\n+            new_tasks = self.generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            # Record snapshot of replenishment\n+            self._record(\n+                {\"id\": \"autoreplenish\", \"title\": \"Auto-backlog replenish\"},  # Dummy, for audit\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks},\n+            )\n+        # else: already open tasks, do nothing\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n     # ------------------------------------------------------------------ #\n     def _record(self, task: dict, state: str, extra: Dict[str, Any] | None = None) -> None:\n         try:\n             self.record.save(task, state=state, extra=extra or {})\n         except TaskRecordError as e:\n             print(f\"[Record-Error] {e}\", file=sys.stderr)\n@@ class DevOrchestrator:\n-    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n-        \"\"\"\n-        End-to-end flow for ONE micro-task with auto-rollback on failure.\n-        \"\"\"\n-        rollback_patch: str | None = None\n-        task: dict | None = None\n-\n-        try:\n-            # 1. Select Task --------------------------------------------------\n-            open_tasks = self.backlog.list_items(status=\"open\")\n-            if not open_tasks:\n-                raise RuntimeError(\"No open tasks in backlog.\")\n+    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n+        \"\"\"\n+        End-to-end flow for ONE micro-task with auto-rollback on failure.\n+        \"\"\"\n+        # At the very top, auto-replenish backlog if empty\n+        self._ensure_backlog()\n+        rollback_patch: str | None = None\n+        task: dict | None = None\n+\n+        try:\n+            # 1. Select Task --------------------------------------------------\n+            open_tasks = self.backlog.list_items(status=\"open\")\n+            if not open_tasks:\n+                raise RuntimeError(\"No open tasks in backlog.\")\n@@ class DevOrchestrator:\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n     CONFIG = dict(\n         backlog_path=\"dev_backlog.json\",\n         template_file=\"dev_templates.json\",\n         src_root=\"cadence\",\n         ruleset_file=None,\n         repo_dir=\".\",\n         record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=3,\n     )\n     orch = DevOrchestrator(CONFIG)\n \n     import argparse\n \n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n+    parser.add_argument(\"--backlog-autoreplenish-count\", type=int, default=3,\n+                        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\")\n     args = parser.parse_args()\n-\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n+    orch.backlog_autoreplenish_count = getattr(args, \"backlog_autoreplenish_count\", 3)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n@@\n+# --------------------------------------------------------------------------- #\n+# TEST: test_orchestrator_auto_replenishment.py\n+# --------------------------------------------------------------------------- #\n+import pytest\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [t for t in self._items if t.get(\"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(dict(task))\n+\n+class DummyTaskGenerator:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        # Simple tasks with id/title\n+        return [{\"id\": f\"t{i+1}\", \"title\": f\"task-{i+1}\", \"type\": \"micro\", \"status\": \"open\", \"created_at\": \"now\"} for i in range(count)]\n+\n+class DummyRecord:\n+    def __init__(self):\n+        self.snaps = []\n+    def save(self, task, state, extra=None):\n+        self.snaps.append((task, state, dict(extra) if extra else {}))\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 3\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    # Pre-condition: empty\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog()\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == 3\n+    snap = orch.record.snaps[-1]\n+    assert snap[1] == \"backlog_replenished\"\n+    assert snap[2][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"n\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, n):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 9  # will be overridden\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(n)\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == n\n+    snap = orch.record.snaps[-1]\n+    assert snap[2][\"count\"] == n"
        },
        "extra": {}
      },
      {
        "state": "patch_built",
        "timestamp": "2025-06-22T04:29:20.207063+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "diff": {
            "file": "<TBD>",
            "before": "",
            "after": ""
          },
          "generated_patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e8be57..8e85f70 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -1,7 +1,10 @@\n import logging\n+from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n+from cadence.backlog.manager import BacklogManager\n+from cadence.tasks.generator import TaskGenerator\n \n logger = logging.getLogger(__name__)\n \n@@ -29,10 +32,54 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self.backlog: BacklogManager  # type: ignore[attr-defined]\n+        self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n+        # backlog_autoreplenish_count may be set by CLI/global env\n+        self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n \n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n+            new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            snapshot(\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks}\n+            )\n+            logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n+        else:\n+            logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+        raise NotImplementedError()\n \n+\ndiff --git a/cadence/cli.py b/cadence/cli.py\nindex 92bc3fc..3ef930f 100644\n--- a/cadence/cli.py\n+++ b/cadence/cli.py\n@@ -64,6 +64,12 @@ def main():\n+    parser.add_argument(\n+        \"--backlog-autoreplenish-count\",\n+        type=int,\n+        default=3,\n+        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\"\n+    )\n@@ -131,6 +137,9 @@ def main():\n     if \"dev-orchestrator\" in args.orchestrator:\n         from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n         orchestrator = DevOrchestrator(\n             *orchestrator_args,\n             **orchestrator_kwargs,\n         )\n+        if hasattr(args, \"backlog_autoreplenish_count\"):\n+            orchestrator.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n@@ -155,6 +164,7 @@ def main():\n     try:\n         orchestrator.run_task_cycle(\n             interactive=args.interactive,\n         )\n     except RuntimeError as exc:\n         if \"No tasks exist\" in str(exc):\n-            print(\"ERROR: No tasks available.\", file=sys.stderr)\n+            print(\"ERROR: No tasks available.\", file=sys.stderr)\n         raise\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nnew file mode 100644\nindex 0000000..96b5837\n--- /dev/null\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -0,0 +1,54 @@\n+import tempfile\n+import shutil\n+import os\n+import pytest\n+\n+from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n+\n+class DummyTask:\n+    def __init__(self, desc):\n+        self.description = desc\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [i for i in self._items if getattr(i, \"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(task)\n+\n+class DummyTaskGen:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        return [DummyTask(f\"TASK-{i+1}\") for i in range(count)]\n+\n+\n+class DummySnapshotCtx:\n+    \"\"\"\n+    For monkeypatching the snapshot function used by ._ensure_backlog\n+    \"\"\"\n+    def __init__(self):\n+        self.calls = []\n+    def __call__(self, state, extra):\n+        self.calls.append((state, dict(extra)))\n+\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    # Patch out snapshot\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 3\n+    # Pre-condition: empty backlog\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    # Should auto-populate with 3 tasks, and snapshot\n+    orch._ensure_backlog()\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == 3\n+    assert snapctx.calls[-1][0] == \"backlog_replenished\"\n+    assert snapctx.calls[-1][1][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"count\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, count):\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 9  # should be overridden by param\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(count)\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == count\n+    assert snapctx.calls[-1][1][\"count\"] == count",
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -1,6 +1,8 @@\n-# src/cadence/dev/orchestrator.py\n+# src/cadence/dev/orchestrator.py\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n Now wires ShellRunner with TaskRecord and attaches the *current* task\n before any shell operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n \n from .backlog import BacklogManager\n from .generator import TaskGenerator\n from .executor import TaskExecutor, PatchBuildError\n from .reviewer import TaskReviewer\n from .shell import ShellRunner, ShellCommandError\n from .record import TaskRecord, TaskRecordError\n-\n-import sys\n-from typing import Any, Dict\n+import sys\n+from typing import Any, Dict, Optional\n@@ class DevOrchestrator:\n     def __init__(self, config: dict):\n         self.backlog = BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n         # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n+        # For auto-replenish count, allow config or default to 3\n+        self.backlog_autoreplenish_count: int = config.get(\"backlog_autoreplenish_count\", 3)\n+\n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            # Generate microtasks\n+            new_tasks = self.generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            # Record snapshot of replenishment\n+            self._record(\n+                {\"id\": \"autoreplenish\", \"title\": \"Auto-backlog replenish\"},  # Dummy, for audit\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks},\n+            )\n+        # else: already open tasks, do nothing\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n     # ------------------------------------------------------------------ #\n     def _record(self, task: dict, state: str, extra: Dict[str, Any] | None = None) -> None:\n         try:\n             self.record.save(task, state=state, extra=extra or {})\n         except TaskRecordError as e:\n             print(f\"[Record-Error] {e}\", file=sys.stderr)\n@@ class DevOrchestrator:\n-    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n-        \"\"\"\n-        End-to-end flow for ONE micro-task with auto-rollback on failure.\n-        \"\"\"\n-        rollback_patch: str | None = None\n-        task: dict | None = None\n-\n-        try:\n-            # 1. Select Task --------------------------------------------------\n-            open_tasks = self.backlog.list_items(status=\"open\")\n-            if not open_tasks:\n-                raise RuntimeError(\"No open tasks in backlog.\")\n+    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n+        \"\"\"\n+        End-to-end flow for ONE micro-task with auto-rollback on failure.\n+        \"\"\"\n+        # At the very top, auto-replenish backlog if empty\n+        self._ensure_backlog()\n+        rollback_patch: str | None = None\n+        task: dict | None = None\n+\n+        try:\n+            # 1. Select Task --------------------------------------------------\n+            open_tasks = self.backlog.list_items(status=\"open\")\n+            if not open_tasks:\n+                raise RuntimeError(\"No open tasks in backlog.\")\n@@ class DevOrchestrator:\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n     CONFIG = dict(\n         backlog_path=\"dev_backlog.json\",\n         template_file=\"dev_templates.json\",\n         src_root=\"cadence\",\n         ruleset_file=None,\n         repo_dir=\".\",\n         record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=3,\n     )\n     orch = DevOrchestrator(CONFIG)\n \n     import argparse\n \n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n+    parser.add_argument(\"--backlog-autoreplenish-count\", type=int, default=3,\n+                        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\")\n     args = parser.parse_args()\n-\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n+    orch.backlog_autoreplenish_count = getattr(args, \"backlog_autoreplenish_count\", 3)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n@@\n+# --------------------------------------------------------------------------- #\n+# TEST: test_orchestrator_auto_replenishment.py\n+# --------------------------------------------------------------------------- #\n+import pytest\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [t for t in self._items if t.get(\"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(dict(task))\n+\n+class DummyTaskGenerator:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        # Simple tasks with id/title\n+        return [{\"id\": f\"t{i+1}\", \"title\": f\"task-{i+1}\", \"type\": \"micro\", \"status\": \"open\", \"created_at\": \"now\"} for i in range(count)]\n+\n+class DummyRecord:\n+    def __init__(self):\n+        self.snaps = []\n+    def save(self, task, state, extra=None):\n+        self.snaps.append((task, state, dict(extra) if extra else {}))\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 3\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    # Pre-condition: empty\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog()\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == 3\n+    snap = orch.record.snaps[-1]\n+    assert snap[1] == \"backlog_replenished\"\n+    assert snap[2][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"n\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, n):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 9  # will be overridden\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(n)\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == n\n+    snap = orch.record.snaps[-1]\n+    assert snap[2][\"count\"] == n"
        },
        "extra": {
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -1,6 +1,8 @@\n-# src/cadence/dev/orchestrator.py\n+# src/cadence/dev/orchestrator.py\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n Now wires ShellRunner with TaskRecord and attaches the *current* task\n before any shell operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n \n from .backlog import BacklogManager\n from .generator import TaskGenerator\n from .executor import TaskExecutor, PatchBuildError\n from .reviewer import TaskReviewer\n from .shell import ShellRunner, ShellCommandError\n from .record import TaskRecord, TaskRecordError\n-\n-import sys\n-from typing import Any, Dict\n+import sys\n+from typing import Any, Dict, Optional\n@@ class DevOrchestrator:\n     def __init__(self, config: dict):\n         self.backlog = BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n         # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n+        # For auto-replenish count, allow config or default to 3\n+        self.backlog_autoreplenish_count: int = config.get(\"backlog_autoreplenish_count\", 3)\n+\n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            # Generate microtasks\n+            new_tasks = self.generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            # Record snapshot of replenishment\n+            self._record(\n+                {\"id\": \"autoreplenish\", \"title\": \"Auto-backlog replenish\"},  # Dummy, for audit\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks},\n+            )\n+        # else: already open tasks, do nothing\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n     # ------------------------------------------------------------------ #\n     def _record(self, task: dict, state: str, extra: Dict[str, Any] | None = None) -> None:\n         try:\n             self.record.save(task, state=state, extra=extra or {})\n         except TaskRecordError as e:\n             print(f\"[Record-Error] {e}\", file=sys.stderr)\n@@ class DevOrchestrator:\n-    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n-        \"\"\"\n-        End-to-end flow for ONE micro-task with auto-rollback on failure.\n-        \"\"\"\n-        rollback_patch: str | None = None\n-        task: dict | None = None\n-\n-        try:\n-            # 1. Select Task --------------------------------------------------\n-            open_tasks = self.backlog.list_items(status=\"open\")\n-            if not open_tasks:\n-                raise RuntimeError(\"No open tasks in backlog.\")\n+    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n+        \"\"\"\n+        End-to-end flow for ONE micro-task with auto-rollback on failure.\n+        \"\"\"\n+        # At the very top, auto-replenish backlog if empty\n+        self._ensure_backlog()\n+        rollback_patch: str | None = None\n+        task: dict | None = None\n+\n+        try:\n+            # 1. Select Task --------------------------------------------------\n+            open_tasks = self.backlog.list_items(status=\"open\")\n+            if not open_tasks:\n+                raise RuntimeError(\"No open tasks in backlog.\")\n@@ class DevOrchestrator:\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n     CONFIG = dict(\n         backlog_path=\"dev_backlog.json\",\n         template_file=\"dev_templates.json\",\n         src_root=\"cadence\",\n         ruleset_file=None,\n         repo_dir=\".\",\n         record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=3,\n     )\n     orch = DevOrchestrator(CONFIG)\n \n     import argparse\n \n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n+    parser.add_argument(\"--backlog-autoreplenish-count\", type=int, default=3,\n+                        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\")\n     args = parser.parse_args()\n-\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n+    orch.backlog_autoreplenish_count = getattr(args, \"backlog_autoreplenish_count\", 3)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n@@\n+# --------------------------------------------------------------------------- #\n+# TEST: test_orchestrator_auto_replenishment.py\n+# --------------------------------------------------------------------------- #\n+import pytest\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [t for t in self._items if t.get(\"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(dict(task))\n+\n+class DummyTaskGenerator:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        # Simple tasks with id/title\n+        return [{\"id\": f\"t{i+1}\", \"title\": f\"task-{i+1}\", \"type\": \"micro\", \"status\": \"open\", \"created_at\": \"now\"} for i in range(count)]\n+\n+class DummyRecord:\n+    def __init__(self):\n+        self.snaps = []\n+    def save(self, task, state, extra=None):\n+        self.snaps.append((task, state, dict(extra) if extra else {}))\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 3\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    # Pre-condition: empty\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog()\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == 3\n+    snap = orch.record.snaps[-1]\n+    assert snap[1] == \"backlog_replenished\"\n+    assert snap[2][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"n\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, n):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 9  # will be overridden\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(n)\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == n\n+    snap = orch.record.snaps[-1]\n+    assert snap[2][\"count\"] == n\n"
        }
      },
      {
        "state": "patch_reviewed",
        "timestamp": "2025-06-22T04:29:20.208120+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "diff": {
            "file": "<TBD>",
            "before": "",
            "after": ""
          },
          "generated_patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e8be57..8e85f70 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -1,7 +1,10 @@\n import logging\n+from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n+from cadence.backlog.manager import BacklogManager\n+from cadence.tasks.generator import TaskGenerator\n \n logger = logging.getLogger(__name__)\n \n@@ -29,10 +32,54 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self.backlog: BacklogManager  # type: ignore[attr-defined]\n+        self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n+        # backlog_autoreplenish_count may be set by CLI/global env\n+        self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n \n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n+            new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            snapshot(\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks}\n+            )\n+            logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n+        else:\n+            logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+        raise NotImplementedError()\n \n+\ndiff --git a/cadence/cli.py b/cadence/cli.py\nindex 92bc3fc..3ef930f 100644\n--- a/cadence/cli.py\n+++ b/cadence/cli.py\n@@ -64,6 +64,12 @@ def main():\n+    parser.add_argument(\n+        \"--backlog-autoreplenish-count\",\n+        type=int,\n+        default=3,\n+        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\"\n+    )\n@@ -131,6 +137,9 @@ def main():\n     if \"dev-orchestrator\" in args.orchestrator:\n         from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n         orchestrator = DevOrchestrator(\n             *orchestrator_args,\n             **orchestrator_kwargs,\n         )\n+        if hasattr(args, \"backlog_autoreplenish_count\"):\n+            orchestrator.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n@@ -155,6 +164,7 @@ def main():\n     try:\n         orchestrator.run_task_cycle(\n             interactive=args.interactive,\n         )\n     except RuntimeError as exc:\n         if \"No tasks exist\" in str(exc):\n-            print(\"ERROR: No tasks available.\", file=sys.stderr)\n+            print(\"ERROR: No tasks available.\", file=sys.stderr)\n         raise\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nnew file mode 100644\nindex 0000000..96b5837\n--- /dev/null\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -0,0 +1,54 @@\n+import tempfile\n+import shutil\n+import os\n+import pytest\n+\n+from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n+\n+class DummyTask:\n+    def __init__(self, desc):\n+        self.description = desc\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [i for i in self._items if getattr(i, \"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(task)\n+\n+class DummyTaskGen:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        return [DummyTask(f\"TASK-{i+1}\") for i in range(count)]\n+\n+\n+class DummySnapshotCtx:\n+    \"\"\"\n+    For monkeypatching the snapshot function used by ._ensure_backlog\n+    \"\"\"\n+    def __init__(self):\n+        self.calls = []\n+    def __call__(self, state, extra):\n+        self.calls.append((state, dict(extra)))\n+\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    # Patch out snapshot\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 3\n+    # Pre-condition: empty backlog\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    # Should auto-populate with 3 tasks, and snapshot\n+    orch._ensure_backlog()\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == 3\n+    assert snapctx.calls[-1][0] == \"backlog_replenished\"\n+    assert snapctx.calls[-1][1][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"count\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, count):\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 9  # should be overridden by param\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(count)\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == count\n+    assert snapctx.calls[-1][1][\"count\"] == count",
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -1,6 +1,8 @@\n-# src/cadence/dev/orchestrator.py\n+# src/cadence/dev/orchestrator.py\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n Now wires ShellRunner with TaskRecord and attaches the *current* task\n before any shell operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n \n from .backlog import BacklogManager\n from .generator import TaskGenerator\n from .executor import TaskExecutor, PatchBuildError\n from .reviewer import TaskReviewer\n from .shell import ShellRunner, ShellCommandError\n from .record import TaskRecord, TaskRecordError\n-\n-import sys\n-from typing import Any, Dict\n+import sys\n+from typing import Any, Dict, Optional\n@@ class DevOrchestrator:\n     def __init__(self, config: dict):\n         self.backlog = BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n         # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n+        # For auto-replenish count, allow config or default to 3\n+        self.backlog_autoreplenish_count: int = config.get(\"backlog_autoreplenish_count\", 3)\n+\n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            # Generate microtasks\n+            new_tasks = self.generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            # Record snapshot of replenishment\n+            self._record(\n+                {\"id\": \"autoreplenish\", \"title\": \"Auto-backlog replenish\"},  # Dummy, for audit\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks},\n+            )\n+        # else: already open tasks, do nothing\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n     # ------------------------------------------------------------------ #\n     def _record(self, task: dict, state: str, extra: Dict[str, Any] | None = None) -> None:\n         try:\n             self.record.save(task, state=state, extra=extra or {})\n         except TaskRecordError as e:\n             print(f\"[Record-Error] {e}\", file=sys.stderr)\n@@ class DevOrchestrator:\n-    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n-        \"\"\"\n-        End-to-end flow for ONE micro-task with auto-rollback on failure.\n-        \"\"\"\n-        rollback_patch: str | None = None\n-        task: dict | None = None\n-\n-        try:\n-            # 1. Select Task --------------------------------------------------\n-            open_tasks = self.backlog.list_items(status=\"open\")\n-            if not open_tasks:\n-                raise RuntimeError(\"No open tasks in backlog.\")\n+    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n+        \"\"\"\n+        End-to-end flow for ONE micro-task with auto-rollback on failure.\n+        \"\"\"\n+        # At the very top, auto-replenish backlog if empty\n+        self._ensure_backlog()\n+        rollback_patch: str | None = None\n+        task: dict | None = None\n+\n+        try:\n+            # 1. Select Task --------------------------------------------------\n+            open_tasks = self.backlog.list_items(status=\"open\")\n+            if not open_tasks:\n+                raise RuntimeError(\"No open tasks in backlog.\")\n@@ class DevOrchestrator:\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n     CONFIG = dict(\n         backlog_path=\"dev_backlog.json\",\n         template_file=\"dev_templates.json\",\n         src_root=\"cadence\",\n         ruleset_file=None,\n         repo_dir=\".\",\n         record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=3,\n     )\n     orch = DevOrchestrator(CONFIG)\n \n     import argparse\n \n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n+    parser.add_argument(\"--backlog-autoreplenish-count\", type=int, default=3,\n+                        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\")\n     args = parser.parse_args()\n-\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n+    orch.backlog_autoreplenish_count = getattr(args, \"backlog_autoreplenish_count\", 3)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n@@\n+# --------------------------------------------------------------------------- #\n+# TEST: test_orchestrator_auto_replenishment.py\n+# --------------------------------------------------------------------------- #\n+import pytest\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [t for t in self._items if t.get(\"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(dict(task))\n+\n+class DummyTaskGenerator:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        # Simple tasks with id/title\n+        return [{\"id\": f\"t{i+1}\", \"title\": f\"task-{i+1}\", \"type\": \"micro\", \"status\": \"open\", \"created_at\": \"now\"} for i in range(count)]\n+\n+class DummyRecord:\n+    def __init__(self):\n+        self.snaps = []\n+    def save(self, task, state, extra=None):\n+        self.snaps.append((task, state, dict(extra) if extra else {}))\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 3\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    # Pre-condition: empty\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog()\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == 3\n+    snap = orch.record.snaps[-1]\n+    assert snap[1] == \"backlog_replenished\"\n+    assert snap[2][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"n\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, n):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 9  # will be overridden\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(n)\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == n\n+    snap = orch.record.snaps[-1]\n+    assert snap[2][\"count\"] == n"
        },
        "extra": {
          "review": {
            "pass": true,
            "comments": ""
          }
        }
      },
      {
        "state": "failed_git_apply",
        "timestamp": "2025-06-22T04:29:20.219107+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "diff": {
            "file": "<TBD>",
            "before": "",
            "after": ""
          },
          "generated_patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e8be57..8e85f70 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -1,7 +1,10 @@\n import logging\n+from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n+from cadence.backlog.manager import BacklogManager\n+from cadence.tasks.generator import TaskGenerator\n \n logger = logging.getLogger(__name__)\n \n@@ -29,10 +32,54 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self.backlog: BacklogManager  # type: ignore[attr-defined]\n+        self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n+        # backlog_autoreplenish_count may be set by CLI/global env\n+        self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n \n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n+            new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            snapshot(\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks}\n+            )\n+            logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n+        else:\n+            logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+        raise NotImplementedError()\n \n+\ndiff --git a/cadence/cli.py b/cadence/cli.py\nindex 92bc3fc..3ef930f 100644\n--- a/cadence/cli.py\n+++ b/cadence/cli.py\n@@ -64,6 +64,12 @@ def main():\n+    parser.add_argument(\n+        \"--backlog-autoreplenish-count\",\n+        type=int,\n+        default=3,\n+        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\"\n+    )\n@@ -131,6 +137,9 @@ def main():\n     if \"dev-orchestrator\" in args.orchestrator:\n         from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n         orchestrator = DevOrchestrator(\n             *orchestrator_args,\n             **orchestrator_kwargs,\n         )\n+        if hasattr(args, \"backlog_autoreplenish_count\"):\n+            orchestrator.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n@@ -155,6 +164,7 @@ def main():\n     try:\n         orchestrator.run_task_cycle(\n             interactive=args.interactive,\n         )\n     except RuntimeError as exc:\n         if \"No tasks exist\" in str(exc):\n-            print(\"ERROR: No tasks available.\", file=sys.stderr)\n+            print(\"ERROR: No tasks available.\", file=sys.stderr)\n         raise\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nnew file mode 100644\nindex 0000000..96b5837\n--- /dev/null\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -0,0 +1,54 @@\n+import tempfile\n+import shutil\n+import os\n+import pytest\n+\n+from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n+\n+class DummyTask:\n+    def __init__(self, desc):\n+        self.description = desc\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [i for i in self._items if getattr(i, \"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(task)\n+\n+class DummyTaskGen:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        return [DummyTask(f\"TASK-{i+1}\") for i in range(count)]\n+\n+\n+class DummySnapshotCtx:\n+    \"\"\"\n+    For monkeypatching the snapshot function used by ._ensure_backlog\n+    \"\"\"\n+    def __init__(self):\n+        self.calls = []\n+    def __call__(self, state, extra):\n+        self.calls.append((state, dict(extra)))\n+\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    # Patch out snapshot\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 3\n+    # Pre-condition: empty backlog\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    # Should auto-populate with 3 tasks, and snapshot\n+    orch._ensure_backlog()\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == 3\n+    assert snapctx.calls[-1][0] == \"backlog_replenished\"\n+    assert snapctx.calls[-1][1][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"count\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, count):\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 9  # should be overridden by param\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(count)\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == count\n+    assert snapctx.calls[-1][1][\"count\"] == count",
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -1,6 +1,8 @@\n-# src/cadence/dev/orchestrator.py\n+# src/cadence/dev/orchestrator.py\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n Now wires ShellRunner with TaskRecord and attaches the *current* task\n before any shell operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n \n from .backlog import BacklogManager\n from .generator import TaskGenerator\n from .executor import TaskExecutor, PatchBuildError\n from .reviewer import TaskReviewer\n from .shell import ShellRunner, ShellCommandError\n from .record import TaskRecord, TaskRecordError\n-\n-import sys\n-from typing import Any, Dict\n+import sys\n+from typing import Any, Dict, Optional\n@@ class DevOrchestrator:\n     def __init__(self, config: dict):\n         self.backlog = BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n         # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n+        # For auto-replenish count, allow config or default to 3\n+        self.backlog_autoreplenish_count: int = config.get(\"backlog_autoreplenish_count\", 3)\n+\n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            # Generate microtasks\n+            new_tasks = self.generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            # Record snapshot of replenishment\n+            self._record(\n+                {\"id\": \"autoreplenish\", \"title\": \"Auto-backlog replenish\"},  # Dummy, for audit\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks},\n+            )\n+        # else: already open tasks, do nothing\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n     # ------------------------------------------------------------------ #\n     def _record(self, task: dict, state: str, extra: Dict[str, Any] | None = None) -> None:\n         try:\n             self.record.save(task, state=state, extra=extra or {})\n         except TaskRecordError as e:\n             print(f\"[Record-Error] {e}\", file=sys.stderr)\n@@ class DevOrchestrator:\n-    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n-        \"\"\"\n-        End-to-end flow for ONE micro-task with auto-rollback on failure.\n-        \"\"\"\n-        rollback_patch: str | None = None\n-        task: dict | None = None\n-\n-        try:\n-            # 1. Select Task --------------------------------------------------\n-            open_tasks = self.backlog.list_items(status=\"open\")\n-            if not open_tasks:\n-                raise RuntimeError(\"No open tasks in backlog.\")\n+    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n+        \"\"\"\n+        End-to-end flow for ONE micro-task with auto-rollback on failure.\n+        \"\"\"\n+        # At the very top, auto-replenish backlog if empty\n+        self._ensure_backlog()\n+        rollback_patch: str | None = None\n+        task: dict | None = None\n+\n+        try:\n+            # 1. Select Task --------------------------------------------------\n+            open_tasks = self.backlog.list_items(status=\"open\")\n+            if not open_tasks:\n+                raise RuntimeError(\"No open tasks in backlog.\")\n@@ class DevOrchestrator:\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n     CONFIG = dict(\n         backlog_path=\"dev_backlog.json\",\n         template_file=\"dev_templates.json\",\n         src_root=\"cadence\",\n         ruleset_file=None,\n         repo_dir=\".\",\n         record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=3,\n     )\n     orch = DevOrchestrator(CONFIG)\n \n     import argparse\n \n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n+    parser.add_argument(\"--backlog-autoreplenish-count\", type=int, default=3,\n+                        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\")\n     args = parser.parse_args()\n-\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n+    orch.backlog_autoreplenish_count = getattr(args, \"backlog_autoreplenish_count\", 3)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n@@\n+# --------------------------------------------------------------------------- #\n+# TEST: test_orchestrator_auto_replenishment.py\n+# --------------------------------------------------------------------------- #\n+import pytest\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [t for t in self._items if t.get(\"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(dict(task))\n+\n+class DummyTaskGenerator:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        # Simple tasks with id/title\n+        return [{\"id\": f\"t{i+1}\", \"title\": f\"task-{i+1}\", \"type\": \"micro\", \"status\": \"open\", \"created_at\": \"now\"} for i in range(count)]\n+\n+class DummyRecord:\n+    def __init__(self):\n+        self.snaps = []\n+    def save(self, task, state, extra=None):\n+        self.snaps.append((task, state, dict(extra) if extra else {}))\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 3\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    # Pre-condition: empty\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog()\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == 3\n+    snap = orch.record.snaps[-1]\n+    assert snap[1] == \"backlog_replenished\"\n+    assert snap[2][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"n\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, n):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 9  # will be overridden\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(n)\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == n\n+    snap = orch.record.snaps[-1]\n+    assert snap[2][\"count\"] == n"
        },
        "extra": {
          "error": "Patch pre-check failed: error: corrupt patch at line 26",
          "output": "error: corrupt patch at line 26",
          "cmd": "git apply --check /var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpw9r6jacc.patch"
        }
      },
      {
        "state": "failed_patch_apply",
        "timestamp": "2025-06-22T04:29:20.220255+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "diff": {
            "file": "<TBD>",
            "before": "",
            "after": ""
          },
          "generated_patch": "diff --git a/cadence/orchestrator/dev_orchestrator.py b/cadence/orchestrator/dev_orchestrator.py\nindex 8e8be57..8e85f70 100644\n--- a/cadence/orchestrator/dev_orchestrator.py\n+++ b/cadence/orchestrator/dev_orchestrator.py\n@@ -1,7 +1,10 @@\n import logging\n+from typing import Optional\n \n from .utils import snapshot\n from .base_orchestrator import BaseOrchestrator\n+from cadence.backlog.manager import BacklogManager\n+from cadence.tasks.generator import TaskGenerator\n \n logger = logging.getLogger(__name__)\n \n@@ -29,10 +32,54 @@ class DevOrchestrator(BaseOrchestrator):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n+        self.backlog: BacklogManager  # type: ignore[attr-defined]\n+        self.task_generator: TaskGenerator  # type: ignore[attr-defined]\n+        # backlog_autoreplenish_count may be set by CLI/global env\n+        self.backlog_autoreplenish_count: int = getattr(self, \"backlog_autoreplenish_count\", 3)\n \n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            logger.info(f\"Backlog empty, auto-generating {num_tasks} microtasks...\")\n+            new_tasks = self.task_generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            snapshot(\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks}\n+            )\n+            logger.info(f\"Replenished backlog with {num_tasks} new item(s).\")\n+        else:\n+            logger.debug(\"Backlog has open items, not replenishing.\")\n \n     def run_task_cycle(self, *args, interactive=True, **kwargs):\n-        # Main task pipeline, schedules, tracks, etc.\n-        raise NotImplementedError()\n+        # At the very top, auto-replenish backlog if needed\n+        self._ensure_backlog()\n+        # Main task pipeline, schedules, tracks, etc.\n+        raise NotImplementedError()\n \n+\ndiff --git a/cadence/cli.py b/cadence/cli.py\nindex 92bc3fc..3ef930f 100644\n--- a/cadence/cli.py\n+++ b/cadence/cli.py\n@@ -64,6 +64,12 @@ def main():\n+    parser.add_argument(\n+        \"--backlog-autoreplenish-count\",\n+        type=int,\n+        default=3,\n+        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\"\n+    )\n@@ -131,6 +137,9 @@ def main():\n     if \"dev-orchestrator\" in args.orchestrator:\n         from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n         orchestrator = DevOrchestrator(\n             *orchestrator_args,\n             **orchestrator_kwargs,\n         )\n+        if hasattr(args, \"backlog_autoreplenish_count\"):\n+            orchestrator.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n@@ -155,6 +164,7 @@ def main():\n     try:\n         orchestrator.run_task_cycle(\n             interactive=args.interactive,\n         )\n     except RuntimeError as exc:\n         if \"No tasks exist\" in str(exc):\n-            print(\"ERROR: No tasks available.\", file=sys.stderr)\n+            print(\"ERROR: No tasks available.\", file=sys.stderr)\n         raise\ndiff --git a/cadence/orchestrator/tests/test_dev_orchestrator.py b/cadence/orchestrator/tests/test_dev_orchestrator.py\nnew file mode 100644\nindex 0000000..96b5837\n--- /dev/null\n+++ b/cadence/orchestrator/tests/test_dev_orchestrator.py\n@@ -0,0 +1,54 @@\n+import tempfile\n+import shutil\n+import os\n+import pytest\n+\n+from cadence.orchestrator.dev_orchestrator import DevOrchestrator\n+\n+class DummyTask:\n+    def __init__(self, desc):\n+        self.description = desc\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [i for i in self._items if getattr(i, \"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(task)\n+\n+class DummyTaskGen:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        return [DummyTask(f\"TASK-{i+1}\") for i in range(count)]\n+\n+\n+class DummySnapshotCtx:\n+    \"\"\"\n+    For monkeypatching the snapshot function used by ._ensure_backlog\n+    \"\"\"\n+    def __init__(self):\n+        self.calls = []\n+    def __call__(self, state, extra):\n+        self.calls.append((state, dict(extra)))\n+\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    # Patch out snapshot\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 3\n+    # Pre-condition: empty backlog\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    # Should auto-populate with 3 tasks, and snapshot\n+    orch._ensure_backlog()\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == 3\n+    assert snapctx.calls[-1][0] == \"backlog_replenished\"\n+    assert snapctx.calls[-1][1][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"count\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, count):\n+    snapctx = DummySnapshotCtx()\n+    monkeypatch.setattr(\"cadence.orchestrator.dev_orchestrator.snapshot\", snapctx)\n+    orch = DevOrchestrator()\n+    orch.backlog = DummyBacklog()\n+    orch.task_generator = DummyTaskGen()\n+    orch.backlog_autoreplenish_count = 9  # should be overridden by param\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(count)\n+    tasks = orch.backlog.list_items(\"open\")\n+    assert len(tasks) == count\n+    assert snapctx.calls[-1][1][\"count\"] == count",
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -1,6 +1,8 @@\n-# src/cadence/dev/orchestrator.py\n+# src/cadence/dev/orchestrator.py\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n Now wires ShellRunner with TaskRecord and attaches the *current* task\n before any shell operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n \n from .backlog import BacklogManager\n from .generator import TaskGenerator\n from .executor import TaskExecutor, PatchBuildError\n from .reviewer import TaskReviewer\n from .shell import ShellRunner, ShellCommandError\n from .record import TaskRecord, TaskRecordError\n-\n-import sys\n-from typing import Any, Dict\n+import sys\n+from typing import Any, Dict, Optional\n@@ class DevOrchestrator:\n     def __init__(self, config: dict):\n         self.backlog = BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n         # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n+        # For auto-replenish count, allow config or default to 3\n+        self.backlog_autoreplenish_count: int = config.get(\"backlog_autoreplenish_count\", 3)\n+\n+    def _ensure_backlog(self, count: Optional[int] = None):\n+        \"\"\"\n+        Ensures the backlog is not empty. If empty, generates and adds new tasks.\n+        Records a snapshot when it replenishes.\n+        \"\"\"\n+        open_items = self.backlog.list_items(\"open\")\n+        if not open_items:\n+            num_tasks = count if count is not None else self.backlog_autoreplenish_count\n+            # Generate microtasks\n+            new_tasks = self.generator.generate_tasks(mode=\"micro\", count=num_tasks)\n+            for t in new_tasks:\n+                self.backlog.add_item(t)\n+            # Record snapshot of replenishment\n+            self._record(\n+                {\"id\": \"autoreplenish\", \"title\": \"Auto-backlog replenish\"},  # Dummy, for audit\n+                state=\"backlog_replenished\",\n+                extra={\"count\": num_tasks},\n+            )\n+        # else: already open tasks, do nothing\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n     # ------------------------------------------------------------------ #\n     def _record(self, task: dict, state: str, extra: Dict[str, Any] | None = None) -> None:\n         try:\n             self.record.save(task, state=state, extra=extra or {})\n         except TaskRecordError as e:\n             print(f\"[Record-Error] {e}\", file=sys.stderr)\n@@ class DevOrchestrator:\n-    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n-        \"\"\"\n-        End-to-end flow for ONE micro-task with auto-rollback on failure.\n-        \"\"\"\n-        rollback_patch: str | None = None\n-        task: dict | None = None\n-\n-        try:\n-            # 1. Select Task --------------------------------------------------\n-            open_tasks = self.backlog.list_items(status=\"open\")\n-            if not open_tasks:\n-                raise RuntimeError(\"No open tasks in backlog.\")\n+    def run_task_cycle(self, select_id: str | None = None, *, interactive: bool = True):\n+        \"\"\"\n+        End-to-end flow for ONE micro-task with auto-rollback on failure.\n+        \"\"\"\n+        # At the very top, auto-replenish backlog if empty\n+        self._ensure_backlog()\n+        rollback_patch: str | None = None\n+        task: dict | None = None\n+\n+        try:\n+            # 1. Select Task --------------------------------------------------\n+            open_tasks = self.backlog.list_items(status=\"open\")\n+            if not open_tasks:\n+                raise RuntimeError(\"No open tasks in backlog.\")\n@@ class DevOrchestrator:\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n     CONFIG = dict(\n         backlog_path=\"dev_backlog.json\",\n         template_file=\"dev_templates.json\",\n         src_root=\"cadence\",\n         ruleset_file=None,\n         repo_dir=\".\",\n         record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=3,\n     )\n     orch = DevOrchestrator(CONFIG)\n \n     import argparse\n \n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n+    parser.add_argument(\"--backlog-autoreplenish-count\", type=int, default=3,\n+                        help=\"Number of microtasks to auto-generate if backlog is empty (default: 3)\")\n     args = parser.parse_args()\n-\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n+    orch.backlog_autoreplenish_count = getattr(args, \"backlog_autoreplenish_count\", 3)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n@@\n+# --------------------------------------------------------------------------- #\n+# TEST: test_orchestrator_auto_replenishment.py\n+# --------------------------------------------------------------------------- #\n+import pytest\n+\n+class DummyBacklog:\n+    def __init__(self):\n+        self._items = []\n+    def list_items(self, status):\n+        if status == \"open\":\n+            return [t for t in self._items if t.get(\"status\", \"open\") == \"open\"]\n+        return []\n+    def add_item(self, task):\n+        self._items.append(dict(task))\n+\n+class DummyTaskGenerator:\n+    def __init__(self):\n+        self.calls = []\n+    def generate_tasks(self, mode, count):\n+        assert mode == \"micro\"\n+        self.calls.append(count)\n+        # Simple tasks with id/title\n+        return [{\"id\": f\"t{i+1}\", \"title\": f\"task-{i+1}\", \"type\": \"micro\", \"status\": \"open\", \"created_at\": \"now\"} for i in range(count)]\n+\n+class DummyRecord:\n+    def __init__(self):\n+        self.snaps = []\n+    def save(self, task, state, extra=None):\n+        self.snaps.append((task, state, dict(extra) if extra else {}))\n+\n+def test_ensure_backlog_autopopulates(monkeypatch):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 3\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    # Pre-condition: empty\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog()\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == 3\n+    snap = orch.record.snaps[-1]\n+    assert snap[1] == \"backlog_replenished\"\n+    assert snap[2][\"count\"] == 3\n+\n+@pytest.mark.parametrize(\"n\", [2, 5])\n+def test_ensure_backlog_respects_count(monkeypatch, n):\n+    from src.cadence.dev.orchestrator import DevOrchestrator\n+    orch = DevOrchestrator.__new__(DevOrchestrator)\n+    orch.backlog = DummyBacklog()\n+    orch.generator = DummyTaskGenerator()\n+    orch.backlog_autoreplenish_count = 9  # will be overridden\n+    orch.record = DummyRecord()\n+    orch._record = lambda task, state, extra=None: orch.record.save(task, state, extra)\n+    assert len(orch.backlog.list_items(\"open\")) == 0\n+    orch._ensure_backlog(n)\n+    open_now = orch.backlog.list_items(\"open\")\n+    assert len(open_now) == n\n+    snap = orch.record.snaps[-1]\n+    assert snap[2][\"count\"] == n"
        },
        "extra": {
          "error": "Patch pre-check failed: error: corrupt patch at line 26"
        }
      },
      {
        "state": "build_patch",
        "timestamp": "2025-06-22T05:40:44.956588+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,8 +2,23 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n"
        },
        "extra": {}
      },
      {
        "state": "patch_built",
        "timestamp": "2025-06-22T05:40:44.958032+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,8 +2,23 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n"
        },
        "extra": {
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,8 +2,23 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations"
        }
      },
      {
        "state": "patch_reviewed",
        "timestamp": "2025-06-22T05:40:44.959099+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,8 +2,23 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n"
        },
        "extra": {
          "review": {
            "pass": true,
            "comments": ""
          }
        }
      },
      {
        "state": "failed_git_apply",
        "timestamp": "2025-06-22T05:40:44.969548+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,8 +2,23 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n"
        },
        "extra": {
          "error": "Patch pre-check failed: error: corrupt patch at line 28",
          "output": "error: corrupt patch at line 28",
          "cmd": "git apply --check /var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmp7zfs_dt4.patch"
        }
      },
      {
        "state": "failed_patch_apply",
        "timestamp": "2025-06-22T05:40:44.970743+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,8 +2,23 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n"
        },
        "extra": {
          "error": "Patch pre-check failed: error: corrupt patch at line 28"
        }
      },
      {
        "state": "build_patch",
        "timestamp": "2025-06-22T06:11:30.214162+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "diff --git a/src/cadence/dev/orchestrator.py b/src/cadence/dev/orchestrator.py\n--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,8 +2,23 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n@@ -33,7 +48,7 @@\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n"
        },
        "extra": {}
      },
      {
        "state": "patch_built",
        "timestamp": "2025-06-22T06:11:30.215668+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "diff --git a/src/cadence/dev/orchestrator.py b/src/cadence/dev/orchestrator.py\n--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,8 +2,23 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n@@ -33,7 +48,7 @@\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n"
        },
        "extra": {
          "patch": "diff --git a/src/cadence/dev/orchestrator.py b/src/cadence/dev/orchestrator.py\n--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,8 +2,23 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n@@ -33,7 +48,7 @@\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #"
        }
      },
      {
        "state": "patch_reviewed",
        "timestamp": "2025-06-22T06:11:30.216970+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "diff --git a/src/cadence/dev/orchestrator.py b/src/cadence/dev/orchestrator.py\n--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,8 +2,23 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n@@ -33,7 +48,7 @@\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n"
        },
        "extra": {
          "review": {
            "pass": true,
            "comments": ""
          }
        }
      },
      {
        "state": "failed_git_apply",
        "timestamp": "2025-06-22T06:11:30.227523+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "diff --git a/src/cadence/dev/orchestrator.py b/src/cadence/dev/orchestrator.py\n--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,8 +2,23 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n@@ -33,7 +48,7 @@\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n"
        },
        "extra": {
          "error": "Patch pre-check failed: error: corrupt patch at line 38",
          "output": "error: corrupt patch at line 38",
          "cmd": "git apply --check /var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpw61bx_i2.patch"
        }
      },
      {
        "state": "failed_patch_apply",
        "timestamp": "2025-06-22T06:11:30.228897+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "diff --git a/src/cadence/dev/orchestrator.py b/src/cadence/dev/orchestrator.py\n--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,8 +2,23 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n@@ -33,7 +48,7 @@\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n"
        },
        "extra": {
          "error": "Patch pre-check failed: error: corrupt patch at line 38"
        }
      },
      {
        "state": "build_patch",
        "timestamp": "2025-06-22T06:24:32.371937+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "diff --git aa/src/cadence/dev/orchestrator.py ba/src/cadence/dev/orchestrator.py.after\nindex bbffce2..a58dbf1 100644\n--- aa/src/cadence/dev/orchestrator.py\n+++ ba/src/cadence/dev/orchestrator.py.after\n@@ -2,59 +2,70 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n-\n-from .backlog import BacklogManager\n-from .generator import TaskGenerator\n-from .executor import TaskExecutor, PatchBuildError\n-from .reviewer import TaskReviewer\n-from .shell import ShellRunner, ShellCommandError\n-from .record import TaskRecord, TaskRecordError\n-\n+import os\n import sys\n-from typing import Any, Dict, Optional\n-\n+import tempfile\n+from typing import Any, Dict, Optional, List\n+\n+from cadence.dev.backlog import BacklogManager\n+from cadence.dev.generator import TaskGenerator\n+from cadence.dev.record import TaskRecord\n+from cadence.dev.shell import ShellRunner\n+from cadence.dev.executor import TaskExecutor, PatchBuildError\n+from cadence.dev.reviewer import TaskReviewer\n+from cadence.dev.shell import ShellCommandError\n+from cadence.dev.record import TaskRecordError\n \n class DevOrchestrator:\n-    def __init__(self, config: dict):\n-        self.backlog = BacklogManager(config[\"backlog_path\"])\n+    def __init__(self, config: dict, *, backlog: Optional[BacklogManager] = None):\n+        self.config: dict = config\n+        self.backlog: BacklogManager = backlog or BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n-        # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n-        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n-        # ADD the 3-line attribute directly below this comment:\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n     def _ensure_backlog(self, count: Optional[int] = None) -> None:\n-        \"\"\"\n-        If no open tasks exist, generate *count* micro-tasks (default:\n-        self.backlog_autoreplenish_count) and record a snapshot\n-        ``state=\"backlog_replenished\"``.\n-        \"\"\"\n-        if self.backlog.list_items(\"open\"):\n-            return                                      # already populated\n-\n-        n = count if count is not None else self.backlog_autoreplenish_count\n-        for t in self.generator.generate_tasks(mode=\"micro\", count=n):\n-            self.backlog.add_item(t)\n-\n-        self._record(\n-            {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n-            state=\"backlog_replenished\",\n-            extra={\"count\": n},\n-        )\n+        \"\"\"Auto-populate microtask backlog if empty.\"\"\"\n+        mode = \"micro\"\n+        count = count if count is not None else self.backlog_autoreplenish_count\n+        open_items = list(self.backlog.list_items(\"open\"))\n+        if not open_items:\n+            tasks = self.generator.generate_tasks(mode=mode, count=count)\n+            for task in tasks:\n+                self.backlog.add_item(task)\n+            self.record.save(\n+                {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n+                state=\"backlog_replenished\",\n+                extra={\"count\": count},\n+            )\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n@@ -261,23 +272,11 @@ class DevOrchestrator:\n                 pass\n             print(\"Invalid. Try again.\")\n \n-\n # --------------------------------------------------------------------------- #\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n-    CONFIG = dict(\n-        backlog_path=\"dev_backlog.json\",\n-        template_file=\"dev_templates.json\",\n-        src_root=\"cadence\",\n-        ruleset_file=None,\n-        repo_dir=\".\",\n-        record_file=\"dev_record.json\",\n-    )\n-    orch = DevOrchestrator(CONFIG)\n-\n     import argparse\n-\n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n@@ -288,6 +287,14 @@ if __name__ == \"__main__\":\n         help=\"Number of micro-tasks to auto-generate when backlog is empty.\",\n     )\n     args = parser.parse_args()\n-\n-    orch.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n\\ No newline at end of file\n+    CONFIG = dict(\n+        backlog_path=\"dev_backlog.json\",\n+        template_file=\"dev_templates.json\",\n+        src_root=\"cadence\",\n+        ruleset_file=None,\n+        repo_dir=\".\",\n+        record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=args.backlog_autoreplenish_count\n+    )\n+    orch = DevOrchestrator(CONFIG)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n"
        },
        "extra": {}
      },
      {
        "state": "patch_built",
        "timestamp": "2025-06-22T06:24:32.373973+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "diff --git aa/src/cadence/dev/orchestrator.py ba/src/cadence/dev/orchestrator.py.after\nindex bbffce2..a58dbf1 100644\n--- aa/src/cadence/dev/orchestrator.py\n+++ ba/src/cadence/dev/orchestrator.py.after\n@@ -2,59 +2,70 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n-\n-from .backlog import BacklogManager\n-from .generator import TaskGenerator\n-from .executor import TaskExecutor, PatchBuildError\n-from .reviewer import TaskReviewer\n-from .shell import ShellRunner, ShellCommandError\n-from .record import TaskRecord, TaskRecordError\n-\n+import os\n import sys\n-from typing import Any, Dict, Optional\n-\n+import tempfile\n+from typing import Any, Dict, Optional, List\n+\n+from cadence.dev.backlog import BacklogManager\n+from cadence.dev.generator import TaskGenerator\n+from cadence.dev.record import TaskRecord\n+from cadence.dev.shell import ShellRunner\n+from cadence.dev.executor import TaskExecutor, PatchBuildError\n+from cadence.dev.reviewer import TaskReviewer\n+from cadence.dev.shell import ShellCommandError\n+from cadence.dev.record import TaskRecordError\n \n class DevOrchestrator:\n-    def __init__(self, config: dict):\n-        self.backlog = BacklogManager(config[\"backlog_path\"])\n+    def __init__(self, config: dict, *, backlog: Optional[BacklogManager] = None):\n+        self.config: dict = config\n+        self.backlog: BacklogManager = backlog or BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n-        # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n-        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n-        # ADD the 3-line attribute directly below this comment:\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n     def _ensure_backlog(self, count: Optional[int] = None) -> None:\n-        \"\"\"\n-        If no open tasks exist, generate *count* micro-tasks (default:\n-        self.backlog_autoreplenish_count) and record a snapshot\n-        ``state=\"backlog_replenished\"``.\n-        \"\"\"\n-        if self.backlog.list_items(\"open\"):\n-            return                                      # already populated\n-\n-        n = count if count is not None else self.backlog_autoreplenish_count\n-        for t in self.generator.generate_tasks(mode=\"micro\", count=n):\n-            self.backlog.add_item(t)\n-\n-        self._record(\n-            {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n-            state=\"backlog_replenished\",\n-            extra={\"count\": n},\n-        )\n+        \"\"\"Auto-populate microtask backlog if empty.\"\"\"\n+        mode = \"micro\"\n+        count = count if count is not None else self.backlog_autoreplenish_count\n+        open_items = list(self.backlog.list_items(\"open\"))\n+        if not open_items:\n+            tasks = self.generator.generate_tasks(mode=mode, count=count)\n+            for task in tasks:\n+                self.backlog.add_item(task)\n+            self.record.save(\n+                {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n+                state=\"backlog_replenished\",\n+                extra={\"count\": count},\n+            )\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n@@ -261,23 +272,11 @@ class DevOrchestrator:\n                 pass\n             print(\"Invalid. Try again.\")\n \n-\n # --------------------------------------------------------------------------- #\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n-    CONFIG = dict(\n-        backlog_path=\"dev_backlog.json\",\n-        template_file=\"dev_templates.json\",\n-        src_root=\"cadence\",\n-        ruleset_file=None,\n-        repo_dir=\".\",\n-        record_file=\"dev_record.json\",\n-    )\n-    orch = DevOrchestrator(CONFIG)\n-\n     import argparse\n-\n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n@@ -288,6 +287,14 @@ if __name__ == \"__main__\":\n         help=\"Number of micro-tasks to auto-generate when backlog is empty.\",\n     )\n     args = parser.parse_args()\n-\n-    orch.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n\\ No newline at end of file\n+    CONFIG = dict(\n+        backlog_path=\"dev_backlog.json\",\n+        template_file=\"dev_templates.json\",\n+        src_root=\"cadence\",\n+        ruleset_file=None,\n+        repo_dir=\".\",\n+        record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=args.backlog_autoreplenish_count\n+    )\n+    orch = DevOrchestrator(CONFIG)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n"
        },
        "extra": {
          "patch": "diff --git aa/src/cadence/dev/orchestrator.py ba/src/cadence/dev/orchestrator.py.after\nindex bbffce2..a58dbf1 100644\n--- aa/src/cadence/dev/orchestrator.py\n+++ ba/src/cadence/dev/orchestrator.py.after\n@@ -2,59 +2,70 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n-\n-from .backlog import BacklogManager\n-from .generator import TaskGenerator\n-from .executor import TaskExecutor, PatchBuildError\n-from .reviewer import TaskReviewer\n-from .shell import ShellRunner, ShellCommandError\n-from .record import TaskRecord, TaskRecordError\n-\n+import os\n import sys\n-from typing import Any, Dict, Optional\n-\n+import tempfile\n+from typing import Any, Dict, Optional, List\n+\n+from cadence.dev.backlog import BacklogManager\n+from cadence.dev.generator import TaskGenerator\n+from cadence.dev.record import TaskRecord\n+from cadence.dev.shell import ShellRunner\n+from cadence.dev.executor import TaskExecutor, PatchBuildError\n+from cadence.dev.reviewer import TaskReviewer\n+from cadence.dev.shell import ShellCommandError\n+from cadence.dev.record import TaskRecordError\n \n class DevOrchestrator:\n-    def __init__(self, config: dict):\n-        self.backlog = BacklogManager(config[\"backlog_path\"])\n+    def __init__(self, config: dict, *, backlog: Optional[BacklogManager] = None):\n+        self.config: dict = config\n+        self.backlog: BacklogManager = backlog or BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n-        # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n-        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n-        # ADD the 3-line attribute directly below this comment:\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n     def _ensure_backlog(self, count: Optional[int] = None) -> None:\n-        \"\"\"\n-        If no open tasks exist, generate *count* micro-tasks (default:\n-        self.backlog_autoreplenish_count) and record a snapshot\n-        ``state=\"backlog_replenished\"``.\n-        \"\"\"\n-        if self.backlog.list_items(\"open\"):\n-            return                                      # already populated\n-\n-        n = count if count is not None else self.backlog_autoreplenish_count\n-        for t in self.generator.generate_tasks(mode=\"micro\", count=n):\n-            self.backlog.add_item(t)\n-\n-        self._record(\n-            {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n-            state=\"backlog_replenished\",\n-            extra={\"count\": n},\n-        )\n+        \"\"\"Auto-populate microtask backlog if empty.\"\"\"\n+        mode = \"micro\"\n+        count = count if count is not None else self.backlog_autoreplenish_count\n+        open_items = list(self.backlog.list_items(\"open\"))\n+        if not open_items:\n+            tasks = self.generator.generate_tasks(mode=mode, count=count)\n+            for task in tasks:\n+                self.backlog.add_item(task)\n+            self.record.save(\n+                {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n+                state=\"backlog_replenished\",\n+                extra={\"count\": count},\n+            )\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n@@ -261,23 +272,11 @@ class DevOrchestrator:\n                 pass\n             print(\"Invalid. Try again.\")\n \n-\n # --------------------------------------------------------------------------- #\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n-    CONFIG = dict(\n-        backlog_path=\"dev_backlog.json\",\n-        template_file=\"dev_templates.json\",\n-        src_root=\"cadence\",\n-        ruleset_file=None,\n-        repo_dir=\".\",\n-        record_file=\"dev_record.json\",\n-    )\n-    orch = DevOrchestrator(CONFIG)\n-\n     import argparse\n-\n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n@@ -288,6 +287,14 @@ if __name__ == \"__main__\":\n         help=\"Number of micro-tasks to auto-generate when backlog is empty.\",\n     )\n     args = parser.parse_args()\n-\n-    orch.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n\\ No newline at end of file\n+    CONFIG = dict(\n+        backlog_path=\"dev_backlog.json\",\n+        template_file=\"dev_templates.json\",\n+        src_root=\"cadence\",\n+        ruleset_file=None,\n+        repo_dir=\".\",\n+        record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=args.backlog_autoreplenish_count\n+    )\n+    orch = DevOrchestrator(CONFIG)\n+    orch.cli_entry(args.command or \"show\", id=args.id)"
        }
      },
      {
        "state": "patch_reviewed",
        "timestamp": "2025-06-22T06:24:32.375514+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "diff --git aa/src/cadence/dev/orchestrator.py ba/src/cadence/dev/orchestrator.py.after\nindex bbffce2..a58dbf1 100644\n--- aa/src/cadence/dev/orchestrator.py\n+++ ba/src/cadence/dev/orchestrator.py.after\n@@ -2,59 +2,70 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n-\n-from .backlog import BacklogManager\n-from .generator import TaskGenerator\n-from .executor import TaskExecutor, PatchBuildError\n-from .reviewer import TaskReviewer\n-from .shell import ShellRunner, ShellCommandError\n-from .record import TaskRecord, TaskRecordError\n-\n+import os\n import sys\n-from typing import Any, Dict, Optional\n-\n+import tempfile\n+from typing import Any, Dict, Optional, List\n+\n+from cadence.dev.backlog import BacklogManager\n+from cadence.dev.generator import TaskGenerator\n+from cadence.dev.record import TaskRecord\n+from cadence.dev.shell import ShellRunner\n+from cadence.dev.executor import TaskExecutor, PatchBuildError\n+from cadence.dev.reviewer import TaskReviewer\n+from cadence.dev.shell import ShellCommandError\n+from cadence.dev.record import TaskRecordError\n \n class DevOrchestrator:\n-    def __init__(self, config: dict):\n-        self.backlog = BacklogManager(config[\"backlog_path\"])\n+    def __init__(self, config: dict, *, backlog: Optional[BacklogManager] = None):\n+        self.config: dict = config\n+        self.backlog: BacklogManager = backlog or BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n-        # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n-        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n-        # ADD the 3-line attribute directly below this comment:\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n     def _ensure_backlog(self, count: Optional[int] = None) -> None:\n-        \"\"\"\n-        If no open tasks exist, generate *count* micro-tasks (default:\n-        self.backlog_autoreplenish_count) and record a snapshot\n-        ``state=\"backlog_replenished\"``.\n-        \"\"\"\n-        if self.backlog.list_items(\"open\"):\n-            return                                      # already populated\n-\n-        n = count if count is not None else self.backlog_autoreplenish_count\n-        for t in self.generator.generate_tasks(mode=\"micro\", count=n):\n-            self.backlog.add_item(t)\n-\n-        self._record(\n-            {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n-            state=\"backlog_replenished\",\n-            extra={\"count\": n},\n-        )\n+        \"\"\"Auto-populate microtask backlog if empty.\"\"\"\n+        mode = \"micro\"\n+        count = count if count is not None else self.backlog_autoreplenish_count\n+        open_items = list(self.backlog.list_items(\"open\"))\n+        if not open_items:\n+            tasks = self.generator.generate_tasks(mode=mode, count=count)\n+            for task in tasks:\n+                self.backlog.add_item(task)\n+            self.record.save(\n+                {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n+                state=\"backlog_replenished\",\n+                extra={\"count\": count},\n+            )\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n@@ -261,23 +272,11 @@ class DevOrchestrator:\n                 pass\n             print(\"Invalid. Try again.\")\n \n-\n # --------------------------------------------------------------------------- #\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n-    CONFIG = dict(\n-        backlog_path=\"dev_backlog.json\",\n-        template_file=\"dev_templates.json\",\n-        src_root=\"cadence\",\n-        ruleset_file=None,\n-        repo_dir=\".\",\n-        record_file=\"dev_record.json\",\n-    )\n-    orch = DevOrchestrator(CONFIG)\n-\n     import argparse\n-\n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n@@ -288,6 +287,14 @@ if __name__ == \"__main__\":\n         help=\"Number of micro-tasks to auto-generate when backlog is empty.\",\n     )\n     args = parser.parse_args()\n-\n-    orch.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n\\ No newline at end of file\n+    CONFIG = dict(\n+        backlog_path=\"dev_backlog.json\",\n+        template_file=\"dev_templates.json\",\n+        src_root=\"cadence\",\n+        ruleset_file=None,\n+        repo_dir=\".\",\n+        record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=args.backlog_autoreplenish_count\n+    )\n+    orch = DevOrchestrator(CONFIG)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n"
        },
        "extra": {
          "review": {
            "pass": true,
            "comments": ""
          }
        }
      },
      {
        "state": "failed_git_apply",
        "timestamp": "2025-06-22T06:24:32.386201+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "diff --git aa/src/cadence/dev/orchestrator.py ba/src/cadence/dev/orchestrator.py.after\nindex bbffce2..a58dbf1 100644\n--- aa/src/cadence/dev/orchestrator.py\n+++ ba/src/cadence/dev/orchestrator.py.after\n@@ -2,59 +2,70 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n-\n-from .backlog import BacklogManager\n-from .generator import TaskGenerator\n-from .executor import TaskExecutor, PatchBuildError\n-from .reviewer import TaskReviewer\n-from .shell import ShellRunner, ShellCommandError\n-from .record import TaskRecord, TaskRecordError\n-\n+import os\n import sys\n-from typing import Any, Dict, Optional\n-\n+import tempfile\n+from typing import Any, Dict, Optional, List\n+\n+from cadence.dev.backlog import BacklogManager\n+from cadence.dev.generator import TaskGenerator\n+from cadence.dev.record import TaskRecord\n+from cadence.dev.shell import ShellRunner\n+from cadence.dev.executor import TaskExecutor, PatchBuildError\n+from cadence.dev.reviewer import TaskReviewer\n+from cadence.dev.shell import ShellCommandError\n+from cadence.dev.record import TaskRecordError\n \n class DevOrchestrator:\n-    def __init__(self, config: dict):\n-        self.backlog = BacklogManager(config[\"backlog_path\"])\n+    def __init__(self, config: dict, *, backlog: Optional[BacklogManager] = None):\n+        self.config: dict = config\n+        self.backlog: BacklogManager = backlog or BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n-        # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n-        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n-        # ADD the 3-line attribute directly below this comment:\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n     def _ensure_backlog(self, count: Optional[int] = None) -> None:\n-        \"\"\"\n-        If no open tasks exist, generate *count* micro-tasks (default:\n-        self.backlog_autoreplenish_count) and record a snapshot\n-        ``state=\"backlog_replenished\"``.\n-        \"\"\"\n-        if self.backlog.list_items(\"open\"):\n-            return                                      # already populated\n-\n-        n = count if count is not None else self.backlog_autoreplenish_count\n-        for t in self.generator.generate_tasks(mode=\"micro\", count=n):\n-            self.backlog.add_item(t)\n-\n-        self._record(\n-            {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n-            state=\"backlog_replenished\",\n-            extra={\"count\": n},\n-        )\n+        \"\"\"Auto-populate microtask backlog if empty.\"\"\"\n+        mode = \"micro\"\n+        count = count if count is not None else self.backlog_autoreplenish_count\n+        open_items = list(self.backlog.list_items(\"open\"))\n+        if not open_items:\n+            tasks = self.generator.generate_tasks(mode=mode, count=count)\n+            for task in tasks:\n+                self.backlog.add_item(task)\n+            self.record.save(\n+                {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n+                state=\"backlog_replenished\",\n+                extra={\"count\": count},\n+            )\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n@@ -261,23 +272,11 @@ class DevOrchestrator:\n                 pass\n             print(\"Invalid. Try again.\")\n \n-\n # --------------------------------------------------------------------------- #\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n-    CONFIG = dict(\n-        backlog_path=\"dev_backlog.json\",\n-        template_file=\"dev_templates.json\",\n-        src_root=\"cadence\",\n-        ruleset_file=None,\n-        repo_dir=\".\",\n-        record_file=\"dev_record.json\",\n-    )\n-    orch = DevOrchestrator(CONFIG)\n-\n     import argparse\n-\n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n@@ -288,6 +287,14 @@ if __name__ == \"__main__\":\n         help=\"Number of micro-tasks to auto-generate when backlog is empty.\",\n     )\n     args = parser.parse_args()\n-\n-    orch.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n\\ No newline at end of file\n+    CONFIG = dict(\n+        backlog_path=\"dev_backlog.json\",\n+        template_file=\"dev_templates.json\",\n+        src_root=\"cadence\",\n+        ruleset_file=None,\n+        repo_dir=\".\",\n+        record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=args.backlog_autoreplenish_count\n+    )\n+    orch = DevOrchestrator(CONFIG)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n"
        },
        "extra": {
          "error": "Patch pre-check failed: error: corrupt patch at line 153",
          "output": "error: corrupt patch at line 153",
          "cmd": "git apply --check /var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpvjhrszrq.patch"
        }
      },
      {
        "state": "failed_patch_apply",
        "timestamp": "2025-06-22T06:24:32.387778+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "diff --git aa/src/cadence/dev/orchestrator.py ba/src/cadence/dev/orchestrator.py.after\nindex bbffce2..a58dbf1 100644\n--- aa/src/cadence/dev/orchestrator.py\n+++ ba/src/cadence/dev/orchestrator.py.after\n@@ -2,59 +2,70 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n-\n-from .backlog import BacklogManager\n-from .generator import TaskGenerator\n-from .executor import TaskExecutor, PatchBuildError\n-from .reviewer import TaskReviewer\n-from .shell import ShellRunner, ShellCommandError\n-from .record import TaskRecord, TaskRecordError\n-\n+import os\n import sys\n-from typing import Any, Dict, Optional\n-\n+import tempfile\n+from typing import Any, Dict, Optional, List\n+\n+from cadence.dev.backlog import BacklogManager\n+from cadence.dev.generator import TaskGenerator\n+from cadence.dev.record import TaskRecord\n+from cadence.dev.shell import ShellRunner\n+from cadence.dev.executor import TaskExecutor, PatchBuildError\n+from cadence.dev.reviewer import TaskReviewer\n+from cadence.dev.shell import ShellCommandError\n+from cadence.dev.record import TaskRecordError\n \n class DevOrchestrator:\n-    def __init__(self, config: dict):\n-        self.backlog = BacklogManager(config[\"backlog_path\"])\n+    def __init__(self, config: dict, *, backlog: Optional[BacklogManager] = None):\n+        self.config: dict = config\n+        self.backlog: BacklogManager = backlog or BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n-        # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n-        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n-        # ADD the 3-line attribute directly below this comment:\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n     def _ensure_backlog(self, count: Optional[int] = None) -> None:\n-        \"\"\"\n-        If no open tasks exist, generate *count* micro-tasks (default:\n-        self.backlog_autoreplenish_count) and record a snapshot\n-        ``state=\"backlog_replenished\"``.\n-        \"\"\"\n-        if self.backlog.list_items(\"open\"):\n-            return                                      # already populated\n-\n-        n = count if count is not None else self.backlog_autoreplenish_count\n-        for t in self.generator.generate_tasks(mode=\"micro\", count=n):\n-            self.backlog.add_item(t)\n-\n-        self._record(\n-            {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n-            state=\"backlog_replenished\",\n-            extra={\"count\": n},\n-        )\n+        \"\"\"Auto-populate microtask backlog if empty.\"\"\"\n+        mode = \"micro\"\n+        count = count if count is not None else self.backlog_autoreplenish_count\n+        open_items = list(self.backlog.list_items(\"open\"))\n+        if not open_items:\n+            tasks = self.generator.generate_tasks(mode=mode, count=count)\n+            for task in tasks:\n+                self.backlog.add_item(task)\n+            self.record.save(\n+                {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n+                state=\"backlog_replenished\",\n+                extra={\"count\": count},\n+            )\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n@@ -261,23 +272,11 @@ class DevOrchestrator:\n                 pass\n             print(\"Invalid. Try again.\")\n \n-\n # --------------------------------------------------------------------------- #\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n-    CONFIG = dict(\n-        backlog_path=\"dev_backlog.json\",\n-        template_file=\"dev_templates.json\",\n-        src_root=\"cadence\",\n-        ruleset_file=None,\n-        repo_dir=\".\",\n-        record_file=\"dev_record.json\",\n-    )\n-    orch = DevOrchestrator(CONFIG)\n-\n     import argparse\n-\n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n@@ -288,6 +287,14 @@ if __name__ == \"__main__\":\n         help=\"Number of micro-tasks to auto-generate when backlog is empty.\",\n     )\n     args = parser.parse_args()\n-\n-    orch.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n\\ No newline at end of file\n+    CONFIG = dict(\n+        backlog_path=\"dev_backlog.json\",\n+        template_file=\"dev_templates.json\",\n+        src_root=\"cadence\",\n+        ruleset_file=None,\n+        repo_dir=\".\",\n+        record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=args.backlog_autoreplenish_count\n+    )\n+    orch = DevOrchestrator(CONFIG)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n"
        },
        "extra": {
          "error": "Patch pre-check failed: error: corrupt patch at line 153"
        }
      },
      {
        "state": "build_patch",
        "timestamp": "2025-06-22T06:36:02.939163+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "diff --git a/var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpmvo7vcsa/repo/src/cadence/dev/orchestrator.py b/var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpmvo7vcsa/repo/src/cadence/dev/orchestrator.py.after\nindex bbffce2..a58dbf1 100644\n--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,59 +2,70 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n-\n-from .backlog import BacklogManager\n-from .generator import TaskGenerator\n-from .executor import TaskExecutor, PatchBuildError\n-from .reviewer import TaskReviewer\n-from .shell import ShellRunner, ShellCommandError\n-from .record import TaskRecord, TaskRecordError\n-\n+import os\n import sys\n-from typing import Any, Dict, Optional\n-\n+import tempfile\n+from typing import Any, Dict, Optional, List\n+\n+from cadence.dev.backlog import BacklogManager\n+from cadence.dev.generator import TaskGenerator\n+from cadence.dev.record import TaskRecord\n+from cadence.dev.shell import ShellRunner\n+from cadence.dev.executor import TaskExecutor, PatchBuildError\n+from cadence.dev.reviewer import TaskReviewer\n+from cadence.dev.shell import ShellCommandError\n+from cadence.dev.record import TaskRecordError\n \n class DevOrchestrator:\n-    def __init__(self, config: dict):\n-        self.backlog = BacklogManager(config[\"backlog_path\"])\n+    def __init__(self, config: dict, *, backlog: Optional[BacklogManager] = None):\n+        self.config: dict = config\n+        self.backlog: BacklogManager = backlog or BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n-        # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n-        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n-        # ADD the 3-line attribute directly below this comment:\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n     def _ensure_backlog(self, count: Optional[int] = None) -> None:\n-        \"\"\"\n-        If no open tasks exist, generate *count* micro-tasks (default:\n-        self.backlog_autoreplenish_count) and record a snapshot\n-        ``state=\"backlog_replenished\"``.\n-        \"\"\"\n-        if self.backlog.list_items(\"open\"):\n-            return                                      # already populated\n-\n-        n = count if count is not None else self.backlog_autoreplenish_count\n-        for t in self.generator.generate_tasks(mode=\"micro\", count=n):\n-            self.backlog.add_item(t)\n-\n-        self._record(\n-            {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n-            state=\"backlog_replenished\",\n-            extra={\"count\": n},\n-        )\n+        \"\"\"Auto-populate microtask backlog if empty.\"\"\"\n+        mode = \"micro\"\n+        count = count if count is not None else self.backlog_autoreplenish_count\n+        open_items = list(self.backlog.list_items(\"open\"))\n+        if not open_items:\n+            tasks = self.generator.generate_tasks(mode=mode, count=count)\n+            for task in tasks:\n+                self.backlog.add_item(task)\n+            self.record.save(\n+                {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n+                state=\"backlog_replenished\",\n+                extra={\"count\": count},\n+            )\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n@@ -261,23 +272,11 @@ class DevOrchestrator:\n                 pass\n             print(\"Invalid. Try again.\")\n \n-\n # --------------------------------------------------------------------------- #\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n-    CONFIG = dict(\n-        backlog_path=\"dev_backlog.json\",\n-        template_file=\"dev_templates.json\",\n-        src_root=\"cadence\",\n-        ruleset_file=None,\n-        repo_dir=\".\",\n-        record_file=\"dev_record.json\",\n-    )\n-    orch = DevOrchestrator(CONFIG)\n-\n     import argparse\n-\n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n@@ -288,6 +287,14 @@ if __name__ == \"__main__\":\n         help=\"Number of micro-tasks to auto-generate when backlog is empty.\",\n     )\n     args = parser.parse_args()\n-\n-    orch.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n\\ No newline at end of file\n+    CONFIG = dict(\n+        backlog_path=\"dev_backlog.json\",\n+        template_file=\"dev_templates.json\",\n+        src_root=\"cadence\",\n+        ruleset_file=None,\n+        repo_dir=\".\",\n+        record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=args.backlog_autoreplenish_count\n+    )\n+    orch = DevOrchestrator(CONFIG)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n"
        },
        "extra": {}
      },
      {
        "state": "patch_built",
        "timestamp": "2025-06-22T06:36:02.941188+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "diff --git a/var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpmvo7vcsa/repo/src/cadence/dev/orchestrator.py b/var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpmvo7vcsa/repo/src/cadence/dev/orchestrator.py.after\nindex bbffce2..a58dbf1 100644\n--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,59 +2,70 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n-\n-from .backlog import BacklogManager\n-from .generator import TaskGenerator\n-from .executor import TaskExecutor, PatchBuildError\n-from .reviewer import TaskReviewer\n-from .shell import ShellRunner, ShellCommandError\n-from .record import TaskRecord, TaskRecordError\n-\n+import os\n import sys\n-from typing import Any, Dict, Optional\n-\n+import tempfile\n+from typing import Any, Dict, Optional, List\n+\n+from cadence.dev.backlog import BacklogManager\n+from cadence.dev.generator import TaskGenerator\n+from cadence.dev.record import TaskRecord\n+from cadence.dev.shell import ShellRunner\n+from cadence.dev.executor import TaskExecutor, PatchBuildError\n+from cadence.dev.reviewer import TaskReviewer\n+from cadence.dev.shell import ShellCommandError\n+from cadence.dev.record import TaskRecordError\n \n class DevOrchestrator:\n-    def __init__(self, config: dict):\n-        self.backlog = BacklogManager(config[\"backlog_path\"])\n+    def __init__(self, config: dict, *, backlog: Optional[BacklogManager] = None):\n+        self.config: dict = config\n+        self.backlog: BacklogManager = backlog or BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n-        # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n-        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n-        # ADD the 3-line attribute directly below this comment:\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n     def _ensure_backlog(self, count: Optional[int] = None) -> None:\n-        \"\"\"\n-        If no open tasks exist, generate *count* micro-tasks (default:\n-        self.backlog_autoreplenish_count) and record a snapshot\n-        ``state=\"backlog_replenished\"``.\n-        \"\"\"\n-        if self.backlog.list_items(\"open\"):\n-            return                                      # already populated\n-\n-        n = count if count is not None else self.backlog_autoreplenish_count\n-        for t in self.generator.generate_tasks(mode=\"micro\", count=n):\n-            self.backlog.add_item(t)\n-\n-        self._record(\n-            {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n-            state=\"backlog_replenished\",\n-            extra={\"count\": n},\n-        )\n+        \"\"\"Auto-populate microtask backlog if empty.\"\"\"\n+        mode = \"micro\"\n+        count = count if count is not None else self.backlog_autoreplenish_count\n+        open_items = list(self.backlog.list_items(\"open\"))\n+        if not open_items:\n+            tasks = self.generator.generate_tasks(mode=mode, count=count)\n+            for task in tasks:\n+                self.backlog.add_item(task)\n+            self.record.save(\n+                {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n+                state=\"backlog_replenished\",\n+                extra={\"count\": count},\n+            )\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n@@ -261,23 +272,11 @@ class DevOrchestrator:\n                 pass\n             print(\"Invalid. Try again.\")\n \n-\n # --------------------------------------------------------------------------- #\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n-    CONFIG = dict(\n-        backlog_path=\"dev_backlog.json\",\n-        template_file=\"dev_templates.json\",\n-        src_root=\"cadence\",\n-        ruleset_file=None,\n-        repo_dir=\".\",\n-        record_file=\"dev_record.json\",\n-    )\n-    orch = DevOrchestrator(CONFIG)\n-\n     import argparse\n-\n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n@@ -288,6 +287,14 @@ if __name__ == \"__main__\":\n         help=\"Number of micro-tasks to auto-generate when backlog is empty.\",\n     )\n     args = parser.parse_args()\n-\n-    orch.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n\\ No newline at end of file\n+    CONFIG = dict(\n+        backlog_path=\"dev_backlog.json\",\n+        template_file=\"dev_templates.json\",\n+        src_root=\"cadence\",\n+        ruleset_file=None,\n+        repo_dir=\".\",\n+        record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=args.backlog_autoreplenish_count\n+    )\n+    orch = DevOrchestrator(CONFIG)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n"
        },
        "extra": {
          "patch": "diff --git a/var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpmvo7vcsa/repo/src/cadence/dev/orchestrator.py b/var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpmvo7vcsa/repo/src/cadence/dev/orchestrator.py.after\nindex bbffce2..a58dbf1 100644\n--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,59 +2,70 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n-\n-from .backlog import BacklogManager\n-from .generator import TaskGenerator\n-from .executor import TaskExecutor, PatchBuildError\n-from .reviewer import TaskReviewer\n-from .shell import ShellRunner, ShellCommandError\n-from .record import TaskRecord, TaskRecordError\n-\n+import os\n import sys\n-from typing import Any, Dict, Optional\n-\n+import tempfile\n+from typing import Any, Dict, Optional, List\n+\n+from cadence.dev.backlog import BacklogManager\n+from cadence.dev.generator import TaskGenerator\n+from cadence.dev.record import TaskRecord\n+from cadence.dev.shell import ShellRunner\n+from cadence.dev.executor import TaskExecutor, PatchBuildError\n+from cadence.dev.reviewer import TaskReviewer\n+from cadence.dev.shell import ShellCommandError\n+from cadence.dev.record import TaskRecordError\n \n class DevOrchestrator:\n-    def __init__(self, config: dict):\n-        self.backlog = BacklogManager(config[\"backlog_path\"])\n+    def __init__(self, config: dict, *, backlog: Optional[BacklogManager] = None):\n+        self.config: dict = config\n+        self.backlog: BacklogManager = backlog or BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n-        # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n-        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n-        # ADD the 3-line attribute directly below this comment:\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n     def _ensure_backlog(self, count: Optional[int] = None) -> None:\n-        \"\"\"\n-        If no open tasks exist, generate *count* micro-tasks (default:\n-        self.backlog_autoreplenish_count) and record a snapshot\n-        ``state=\"backlog_replenished\"``.\n-        \"\"\"\n-        if self.backlog.list_items(\"open\"):\n-            return                                      # already populated\n-\n-        n = count if count is not None else self.backlog_autoreplenish_count\n-        for t in self.generator.generate_tasks(mode=\"micro\", count=n):\n-            self.backlog.add_item(t)\n-\n-        self._record(\n-            {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n-            state=\"backlog_replenished\",\n-            extra={\"count\": n},\n-        )\n+        \"\"\"Auto-populate microtask backlog if empty.\"\"\"\n+        mode = \"micro\"\n+        count = count if count is not None else self.backlog_autoreplenish_count\n+        open_items = list(self.backlog.list_items(\"open\"))\n+        if not open_items:\n+            tasks = self.generator.generate_tasks(mode=mode, count=count)\n+            for task in tasks:\n+                self.backlog.add_item(task)\n+            self.record.save(\n+                {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n+                state=\"backlog_replenished\",\n+                extra={\"count\": count},\n+            )\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n@@ -261,23 +272,11 @@ class DevOrchestrator:\n                 pass\n             print(\"Invalid. Try again.\")\n \n-\n # --------------------------------------------------------------------------- #\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n-    CONFIG = dict(\n-        backlog_path=\"dev_backlog.json\",\n-        template_file=\"dev_templates.json\",\n-        src_root=\"cadence\",\n-        ruleset_file=None,\n-        repo_dir=\".\",\n-        record_file=\"dev_record.json\",\n-    )\n-    orch = DevOrchestrator(CONFIG)\n-\n     import argparse\n-\n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n@@ -288,6 +287,14 @@ if __name__ == \"__main__\":\n         help=\"Number of micro-tasks to auto-generate when backlog is empty.\",\n     )\n     args = parser.parse_args()\n-\n-    orch.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n\\ No newline at end of file\n+    CONFIG = dict(\n+        backlog_path=\"dev_backlog.json\",\n+        template_file=\"dev_templates.json\",\n+        src_root=\"cadence\",\n+        ruleset_file=None,\n+        repo_dir=\".\",\n+        record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=args.backlog_autoreplenish_count\n+    )\n+    orch = DevOrchestrator(CONFIG)\n+    orch.cli_entry(args.command or \"show\", id=args.id)"
        }
      },
      {
        "state": "patch_reviewed",
        "timestamp": "2025-06-22T06:36:02.942633+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "diff --git a/var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpmvo7vcsa/repo/src/cadence/dev/orchestrator.py b/var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpmvo7vcsa/repo/src/cadence/dev/orchestrator.py.after\nindex bbffce2..a58dbf1 100644\n--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,59 +2,70 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n-\n-from .backlog import BacklogManager\n-from .generator import TaskGenerator\n-from .executor import TaskExecutor, PatchBuildError\n-from .reviewer import TaskReviewer\n-from .shell import ShellRunner, ShellCommandError\n-from .record import TaskRecord, TaskRecordError\n-\n+import os\n import sys\n-from typing import Any, Dict, Optional\n-\n+import tempfile\n+from typing import Any, Dict, Optional, List\n+\n+from cadence.dev.backlog import BacklogManager\n+from cadence.dev.generator import TaskGenerator\n+from cadence.dev.record import TaskRecord\n+from cadence.dev.shell import ShellRunner\n+from cadence.dev.executor import TaskExecutor, PatchBuildError\n+from cadence.dev.reviewer import TaskReviewer\n+from cadence.dev.shell import ShellCommandError\n+from cadence.dev.record import TaskRecordError\n \n class DevOrchestrator:\n-    def __init__(self, config: dict):\n-        self.backlog = BacklogManager(config[\"backlog_path\"])\n+    def __init__(self, config: dict, *, backlog: Optional[BacklogManager] = None):\n+        self.config: dict = config\n+        self.backlog: BacklogManager = backlog or BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n-        # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n-        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n-        # ADD the 3-line attribute directly below this comment:\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n     def _ensure_backlog(self, count: Optional[int] = None) -> None:\n-        \"\"\"\n-        If no open tasks exist, generate *count* micro-tasks (default:\n-        self.backlog_autoreplenish_count) and record a snapshot\n-        ``state=\"backlog_replenished\"``.\n-        \"\"\"\n-        if self.backlog.list_items(\"open\"):\n-            return                                      # already populated\n-\n-        n = count if count is not None else self.backlog_autoreplenish_count\n-        for t in self.generator.generate_tasks(mode=\"micro\", count=n):\n-            self.backlog.add_item(t)\n-\n-        self._record(\n-            {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n-            state=\"backlog_replenished\",\n-            extra={\"count\": n},\n-        )\n+        \"\"\"Auto-populate microtask backlog if empty.\"\"\"\n+        mode = \"micro\"\n+        count = count if count is not None else self.backlog_autoreplenish_count\n+        open_items = list(self.backlog.list_items(\"open\"))\n+        if not open_items:\n+            tasks = self.generator.generate_tasks(mode=mode, count=count)\n+            for task in tasks:\n+                self.backlog.add_item(task)\n+            self.record.save(\n+                {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n+                state=\"backlog_replenished\",\n+                extra={\"count\": count},\n+            )\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n@@ -261,23 +272,11 @@ class DevOrchestrator:\n                 pass\n             print(\"Invalid. Try again.\")\n \n-\n # --------------------------------------------------------------------------- #\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n-    CONFIG = dict(\n-        backlog_path=\"dev_backlog.json\",\n-        template_file=\"dev_templates.json\",\n-        src_root=\"cadence\",\n-        ruleset_file=None,\n-        repo_dir=\".\",\n-        record_file=\"dev_record.json\",\n-    )\n-    orch = DevOrchestrator(CONFIG)\n-\n     import argparse\n-\n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n@@ -288,6 +287,14 @@ if __name__ == \"__main__\":\n         help=\"Number of micro-tasks to auto-generate when backlog is empty.\",\n     )\n     args = parser.parse_args()\n-\n-    orch.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n\\ No newline at end of file\n+    CONFIG = dict(\n+        backlog_path=\"dev_backlog.json\",\n+        template_file=\"dev_templates.json\",\n+        src_root=\"cadence\",\n+        ruleset_file=None,\n+        repo_dir=\".\",\n+        record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=args.backlog_autoreplenish_count\n+    )\n+    orch = DevOrchestrator(CONFIG)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n"
        },
        "extra": {
          "review": {
            "pass": true,
            "comments": ""
          }
        }
      },
      {
        "state": "failed_git_apply",
        "timestamp": "2025-06-22T06:36:02.953860+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "diff --git a/var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpmvo7vcsa/repo/src/cadence/dev/orchestrator.py b/var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpmvo7vcsa/repo/src/cadence/dev/orchestrator.py.after\nindex bbffce2..a58dbf1 100644\n--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,59 +2,70 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n-\n-from .backlog import BacklogManager\n-from .generator import TaskGenerator\n-from .executor import TaskExecutor, PatchBuildError\n-from .reviewer import TaskReviewer\n-from .shell import ShellRunner, ShellCommandError\n-from .record import TaskRecord, TaskRecordError\n-\n+import os\n import sys\n-from typing import Any, Dict, Optional\n-\n+import tempfile\n+from typing import Any, Dict, Optional, List\n+\n+from cadence.dev.backlog import BacklogManager\n+from cadence.dev.generator import TaskGenerator\n+from cadence.dev.record import TaskRecord\n+from cadence.dev.shell import ShellRunner\n+from cadence.dev.executor import TaskExecutor, PatchBuildError\n+from cadence.dev.reviewer import TaskReviewer\n+from cadence.dev.shell import ShellCommandError\n+from cadence.dev.record import TaskRecordError\n \n class DevOrchestrator:\n-    def __init__(self, config: dict):\n-        self.backlog = BacklogManager(config[\"backlog_path\"])\n+    def __init__(self, config: dict, *, backlog: Optional[BacklogManager] = None):\n+        self.config: dict = config\n+        self.backlog: BacklogManager = backlog or BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n-        # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n-        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n-        # ADD the 3-line attribute directly below this comment:\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n     def _ensure_backlog(self, count: Optional[int] = None) -> None:\n-        \"\"\"\n-        If no open tasks exist, generate *count* micro-tasks (default:\n-        self.backlog_autoreplenish_count) and record a snapshot\n-        ``state=\"backlog_replenished\"``.\n-        \"\"\"\n-        if self.backlog.list_items(\"open\"):\n-            return                                      # already populated\n-\n-        n = count if count is not None else self.backlog_autoreplenish_count\n-        for t in self.generator.generate_tasks(mode=\"micro\", count=n):\n-            self.backlog.add_item(t)\n-\n-        self._record(\n-            {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n-            state=\"backlog_replenished\",\n-            extra={\"count\": n},\n-        )\n+        \"\"\"Auto-populate microtask backlog if empty.\"\"\"\n+        mode = \"micro\"\n+        count = count if count is not None else self.backlog_autoreplenish_count\n+        open_items = list(self.backlog.list_items(\"open\"))\n+        if not open_items:\n+            tasks = self.generator.generate_tasks(mode=mode, count=count)\n+            for task in tasks:\n+                self.backlog.add_item(task)\n+            self.record.save(\n+                {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n+                state=\"backlog_replenished\",\n+                extra={\"count\": count},\n+            )\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n@@ -261,23 +272,11 @@ class DevOrchestrator:\n                 pass\n             print(\"Invalid. Try again.\")\n \n-\n # --------------------------------------------------------------------------- #\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n-    CONFIG = dict(\n-        backlog_path=\"dev_backlog.json\",\n-        template_file=\"dev_templates.json\",\n-        src_root=\"cadence\",\n-        ruleset_file=None,\n-        repo_dir=\".\",\n-        record_file=\"dev_record.json\",\n-    )\n-    orch = DevOrchestrator(CONFIG)\n-\n     import argparse\n-\n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n@@ -288,6 +287,14 @@ if __name__ == \"__main__\":\n         help=\"Number of micro-tasks to auto-generate when backlog is empty.\",\n     )\n     args = parser.parse_args()\n-\n-    orch.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n\\ No newline at end of file\n+    CONFIG = dict(\n+        backlog_path=\"dev_backlog.json\",\n+        template_file=\"dev_templates.json\",\n+        src_root=\"cadence\",\n+        ruleset_file=None,\n+        repo_dir=\".\",\n+        record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=args.backlog_autoreplenish_count\n+    )\n+    orch = DevOrchestrator(CONFIG)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n"
        },
        "extra": {
          "error": "Patch pre-check failed: error: corrupt patch at line 153",
          "output": "error: corrupt patch at line 153",
          "cmd": "git apply --check /var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpn5w34i7y.patch"
        }
      },
      {
        "state": "failed_patch_apply",
        "timestamp": "2025-06-22T06:36:02.955650+00:00",
        "task": {
          "title": "TASK-1 Auto-replenish backlog",
          "description": "Title: Auto-replenish backlog when empty\nGoal: Keep the pipeline perpetually flowing without human babysitting.\nImplementation Steps:\n\n1. Add\u00a0**`DevOrchestrator._ensure_backlog()`**\u00a0\u2022 If\u00a0**`self.backlog.list_items(\"open\")`**\u00a0is empty, call\u00a0**`TaskGenerator.generate_tasks(mode=\"micro\", count=<N>)`**\u00a0(N default = 3; expose CLI flag).\u00a0\u2022 Persist the newly generated tasks with\u00a0**`BacklogManager.add_item`**.\u00a0\u2022 Record snapshot:\u00a0**`state=\"backlog_replenished\"`**, extra={\"count\": N}.\n2. Call\u00a0**`_ensure_backlog()`**\u00a0at the very top of\u00a0**`run_task_cycle()`**.\n3. Unit test: run an orchestrator in a temp repo with an empty backlog, assert it auto-populates.\n\nAcceptance: **`run_task_cycle(interactive=False)`** no longer raises **`RuntimeError`** when no tasks exist.\n",
          "status": "open",
          "id": "ba002f7b-742f-4dce-911f-175c455bd673",
          "type": "micro",
          "created_at": "2025-06-21T23:48:17.392877",
          "patch": "diff --git a/var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpmvo7vcsa/repo/src/cadence/dev/orchestrator.py b/var/folders/dc/0h9f2ldj29z_b8h9dbxrs2cw0000gn/T/tmpmvo7vcsa/repo/src/cadence/dev/orchestrator.py.after\nindex bbffce2..a58dbf1 100644\n--- a/src/cadence/dev/orchestrator.py\n+++ b/src/cadence/dev/orchestrator.py\n@@ -2,59 +2,70 @@\n \"\"\"\n Cadence DevOrchestrator\n -----------------------\n-Now wires ShellRunner with TaskRecord and attaches the *current* task\n-before any shell operation so that ShellRunner can persist failures.\n+Key improvements (2025-06-21)\n+1.  **Auto-replenish Backlog** \u2013 `run_task_cycle()` now guarantees that\n+    at least *N* open micro-tasks exist by invoking the private helper\n+    `_ensure_backlog()` at the very beginning of every cycle.  When the\n+    backlog is empty the orchestrator calls\n+    `TaskGenerator.generate_tasks()` (default `count = 3`) and persists\n+    those tasks via `BacklogManager.add_item()`.  A state snapshot\n+    `\"backlog_replenished\"` is recorded so that TaskRecord maintains an\n+    immutable audit trail.\n+\n+2.  **Configurable replenish count** \u2013 the constructor consumes an\n+    optional `backlog_autoreplenish_count` key and the CLI wrapper\n+    exposes the `--backlog-autoreplenish-count` flag.\n+\n+3.  **Shell-Runner failure persistence** \u2013 wires ShellRunner with\n+    TaskRecord and attaches the *current* task before any shell\n+    operation so that ShellRunner can persist failures.\n \"\"\"\n \n from __future__ import annotations\n-\n-from .backlog import BacklogManager\n-from .generator import TaskGenerator\n-from .executor import TaskExecutor, PatchBuildError\n-from .reviewer import TaskReviewer\n-from .shell import ShellRunner, ShellCommandError\n-from .record import TaskRecord, TaskRecordError\n-\n+import os\n import sys\n-from typing import Any, Dict, Optional\n-\n+import tempfile\n+from typing import Any, Dict, Optional, List\n+\n+from cadence.dev.backlog import BacklogManager\n+from cadence.dev.generator import TaskGenerator\n+from cadence.dev.record import TaskRecord\n+from cadence.dev.shell import ShellRunner\n+from cadence.dev.executor import TaskExecutor, PatchBuildError\n+from cadence.dev.reviewer import TaskReviewer\n+from cadence.dev.shell import ShellCommandError\n+from cadence.dev.record import TaskRecordError\n \n class DevOrchestrator:\n-    def __init__(self, config: dict):\n-        self.backlog = BacklogManager(config[\"backlog_path\"])\n+    def __init__(self, config: dict, *, backlog: Optional[BacklogManager] = None):\n+        self.config: dict = config\n+        self.backlog: BacklogManager = backlog or BacklogManager(config[\"backlog_path\"])\n         self.generator = TaskGenerator(config.get(\"template_file\"))\n         self.record = TaskRecord(config[\"record_file\"])\n-        # ShellRunner now receives TaskRecord so it can self-record failures\n         self.shell = ShellRunner(config[\"repo_dir\"], task_record=self.record)\n         self.executor = TaskExecutor(config[\"src_root\"])\n         self.reviewer = TaskReviewer(config.get(\"ruleset_file\"))\n-        # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n-        # ADD the 3-line attribute directly below this comment:\n         self.backlog_autoreplenish_count: int = config.get(\n             \"backlog_autoreplenish_count\", 3\n         )\n-        \n+\n     # ------------------------------------------------------------------ #\n     # Back-log auto-replenishment\n     # ------------------------------------------------------------------ #\n     def _ensure_backlog(self, count: Optional[int] = None) -> None:\n-        \"\"\"\n-        If no open tasks exist, generate *count* micro-tasks (default:\n-        self.backlog_autoreplenish_count) and record a snapshot\n-        ``state=\"backlog_replenished\"``.\n-        \"\"\"\n-        if self.backlog.list_items(\"open\"):\n-            return                                      # already populated\n-\n-        n = count if count is not None else self.backlog_autoreplenish_count\n-        for t in self.generator.generate_tasks(mode=\"micro\", count=n):\n-            self.backlog.add_item(t)\n-\n-        self._record(\n-            {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n-            state=\"backlog_replenished\",\n-            extra={\"count\": n},\n-        )\n+        \"\"\"Auto-populate microtask backlog if empty.\"\"\"\n+        mode = \"micro\"\n+        count = count if count is not None else self.backlog_autoreplenish_count\n+        open_items = list(self.backlog.list_items(\"open\"))\n+        if not open_items:\n+            tasks = self.generator.generate_tasks(mode=mode, count=count)\n+            for task in tasks:\n+                self.backlog.add_item(task)\n+            self.record.save(\n+                {\"id\": \"auto-backlog-replenish\", \"title\": \"Auto-replenish\"},\n+                state=\"backlog_replenished\",\n+                extra={\"count\": count},\n+            )\n \n     # ------------------------------------------------------------------ #\n     # Internal helper \u2013 ALWAYS log, never raise\n@@ -261,23 +272,11 @@ class DevOrchestrator:\n                 pass\n             print(\"Invalid. Try again.\")\n \n-\n # --------------------------------------------------------------------------- #\n # Stand-alone execution helper\n # --------------------------------------------------------------------------- #\n if __name__ == \"__main__\":\n-    CONFIG = dict(\n-        backlog_path=\"dev_backlog.json\",\n-        template_file=\"dev_templates.json\",\n-        src_root=\"cadence\",\n-        ruleset_file=None,\n-        repo_dir=\".\",\n-        record_file=\"dev_record.json\",\n-    )\n-    orch = DevOrchestrator(CONFIG)\n-\n     import argparse\n-\n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"command\", nargs=\"?\", help=\"show|start|evaluate|done\")\n     parser.add_argument(\"--id\", default=None, help=\"Task id to use\")\n@@ -288,6 +287,14 @@ if __name__ == \"__main__\":\n         help=\"Number of micro-tasks to auto-generate when backlog is empty.\",\n     )\n     args = parser.parse_args()\n-\n-    orch.backlog_autoreplenish_count = args.backlog_autoreplenish_count\n-    orch.cli_entry(args.command or \"show\", id=args.id)\n\\ No newline at end of file\n+    CONFIG = dict(\n+        backlog_path=\"dev_backlog.json\",\n+        template_file=\"dev_templates.json\",\n+        src_root=\"cadence\",\n+        ruleset_file=None,\n+        repo_dir=\".\",\n+        record_file=\"dev_record.json\",\n+        backlog_autoreplenish_count=args.backlog_autoreplenish_count\n+    )\n+    orch = DevOrchestrator(CONFIG)\n+    orch.cli_entry(args.command or \"show\", id=args.id)\n"
        },
        "extra": {
          "error": "Patch pre-check failed: error: corrupt patch at line 153"
        }
      }
    ],
    "iterations": []
  }
]